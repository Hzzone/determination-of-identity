I1021 01:01:08.772212 2633249728 caffe.cpp:211] Use CPU.
I1021 01:01:08.773586 2633249728 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0
snapshot: 5000
snapshot_prefix: "/Volumes/Hzzone/model/lenet_siamese_train"
solver_mode: CPU
net: "./lenet_siamese_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1021 01:01:08.774394 2633249728 solver.cpp:87] Creating training net from net file: ./lenet_siamese_train_test.prototxt
I1021 01:01:08.774785 2633249728 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer pair_data
I1021 01:01:08.774813 2633249728 net.cpp:51] Initializing net from parameters: 
name: "lenet_siamese_train_test"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/Users/HZzone/Desktop/determination-data/siamese_train_lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 250
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "pool2_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "ip2_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "ip2_p"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip2_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I1021 01:01:08.775032 2633249728 layer_factory.hpp:77] Creating layer pair_data
I1021 01:01:08.775277 2633249728 db_lmdb.cpp:35] Opened lmdb /Users/HZzone/Desktop/determination-data/siamese_train_lmdb
I1021 01:01:08.775332 2633249728 net.cpp:84] Creating Layer pair_data
I1021 01:01:08.775343 2633249728 net.cpp:380] pair_data -> pair_data
I1021 01:01:08.775362 2633249728 net.cpp:380] pair_data -> sim
I1021 01:01:09.154115 2633249728 data_layer.cpp:45] output data size: 20,500,227,227
tcmalloc: large alloc 2061164544 bytes == 0xe9e833c000 @  0x7fff941a8282 0x7fff941a7200 0x10aa5e69e 0x10aa5e480 0x10aa5e60e 0x10a9ad3f9 0x10aa33d66 0x10aa32abe 0x10aa4b508 0x10aa4a8e1 0x10aa4a5e5 0x10aa58ea6 0x10aa5e1a2 0x10a95736f 0x10a95699d 0x10a959517 0x7fff94026235 0x4
tcmalloc: large alloc 2061164544 bytes == 0xea630ea000 @  0x7fff941a8282 0x7fff941a7200 0x10aa5e69e 0x10aa5e480 0x10aa5e60e 0x10a9ad3f9 0x10aa33d66 0x10aa32abe 0x10aa4b508 0x10aa4a8e1 0x10aa4a5e5 0x10aa58ea6 0x10aa5e1a2 0x10a95736f 0x10a95699d 0x10a959517 0x7fff94026235 0x4
tcmalloc: large alloc 2061164544 bytes == 0xeadde98000 @  0x7fff941a8282 0x7fff941a7200 0x10aa5e69e 0x10aa5e480 0x10aa5e60e 0x10a9ad3f9 0x10aa33d66 0x10aa32abe 0x10aa4b508 0x10aa4a8e1 0x10aa4a5e5 0x10aa58ea6 0x10aa5e1a2 0x10a95736f 0x10a95699d 0x10a959517 0x7fff94026235 0x4
tcmalloc: large alloc 2061164544 bytes == 0xeb58c46000 @  0x7fff941a8282 0x7fff941a7200 0x10aa5e69e 0x10aa5e480 0x10aa5e60e 0x10a9ad3f9 0x10aa33d66 0x10aa32abe 0x10aa4b508 0x10aa4a8e1 0x10aa4a5e5 0x10aa58ea6 0x10aa5e1a2 0x10a95736f 0x10a95699d 0x10a959517 0x7fff94026235 0x4
I1021 01:01:15.216737 2633249728 net.cpp:122] Setting up pair_data
I1021 01:01:15.216773 2633249728 net.cpp:129] Top shape: 20 500 227 227 (515290000)
I1021 01:01:15.216789 2633249728 net.cpp:129] Top shape: 20 (20)
I1021 01:01:15.216794 2633249728 net.cpp:137] Memory required for data: 2061160080
I1021 01:01:15.216802 2633249728 layer_factory.hpp:77] Creating layer slice_pair
I1021 01:01:15.216814 2633249728 net.cpp:84] Creating Layer slice_pair
I1021 01:01:15.216820 2633249728 net.cpp:406] slice_pair <- pair_data
I1021 01:01:15.216826 2633249728 net.cpp:380] slice_pair -> data
I1021 01:01:15.216836 2633249728 net.cpp:380] slice_pair -> data_p
I1021 01:01:15.216848 2633249728 net.cpp:122] Setting up slice_pair
I1021 01:01:15.216855 2633249728 net.cpp:129] Top shape: 20 250 227 227 (257645000)
I1021 01:01:15.216861 2633249728 net.cpp:129] Top shape: 20 250 227 227 (257645000)
I1021 01:01:15.216866 2633249728 net.cpp:137] Memory required for data: 4122320080
I1021 01:01:15.216871 2633249728 layer_factory.hpp:77] Creating layer conv1
I1021 01:01:15.216883 2633249728 net.cpp:84] Creating Layer conv1
I1021 01:01:15.216902 2633249728 net.cpp:406] conv1 <- data
I1021 01:01:15.216910 2633249728 net.cpp:380] conv1 -> conv1
I1021 01:01:15.221089 2633249728 net.cpp:122] Setting up conv1
I1021 01:01:15.221139 2633249728 net.cpp:129] Top shape: 20 20 223 223 (19891600)
I1021 01:01:15.221156 2633249728 net.cpp:137] Memory required for data: 4201886480
I1021 01:01:15.221174 2633249728 layer_factory.hpp:77] Creating layer pool1
I1021 01:01:15.221189 2633249728 net.cpp:84] Creating Layer pool1
I1021 01:01:15.221199 2633249728 net.cpp:406] pool1 <- conv1
I1021 01:01:15.221212 2633249728 net.cpp:380] pool1 -> pool1
I1021 01:01:15.221235 2633249728 net.cpp:122] Setting up pool1
I1021 01:01:15.221246 2633249728 net.cpp:129] Top shape: 20 20 112 112 (5017600)
I1021 01:01:15.221257 2633249728 net.cpp:137] Memory required for data: 4221956880
I1021 01:01:15.221267 2633249728 layer_factory.hpp:77] Creating layer conv2
I1021 01:01:15.221284 2633249728 net.cpp:84] Creating Layer conv2
I1021 01:01:15.221297 2633249728 net.cpp:406] conv2 <- pool1
I1021 01:01:15.221309 2633249728 net.cpp:380] conv2 -> conv2
I1021 01:01:15.221734 2633249728 net.cpp:122] Setting up conv2
I1021 01:01:15.222673 2633249728 net.cpp:129] Top shape: 20 50 108 108 (11664000)
I1021 01:01:15.222694 2633249728 net.cpp:137] Memory required for data: 4268612880
I1021 01:01:15.222707 2633249728 layer_factory.hpp:77] Creating layer pool2
I1021 01:01:15.222734 2633249728 net.cpp:84] Creating Layer pool2
I1021 01:01:15.222753 2633249728 net.cpp:406] pool2 <- conv2
I1021 01:01:15.222761 2633249728 net.cpp:380] pool2 -> pool2
I1021 01:01:15.222771 2633249728 net.cpp:122] Setting up pool2
I1021 01:01:15.222777 2633249728 net.cpp:129] Top shape: 20 50 54 54 (2916000)
I1021 01:01:15.222784 2633249728 net.cpp:137] Memory required for data: 4280276880
I1021 01:01:15.222789 2633249728 layer_factory.hpp:77] Creating layer ip1
I1021 01:01:15.222796 2633249728 net.cpp:84] Creating Layer ip1
I1021 01:01:15.222801 2633249728 net.cpp:406] ip1 <- pool2
I1021 01:01:15.222807 2633249728 net.cpp:380] ip1 -> ip1
I1021 01:01:16.294000 2633249728 net.cpp:122] Setting up ip1
I1021 01:01:16.294044 2633249728 net.cpp:129] Top shape: 20 500 (10000)
I1021 01:01:16.294070 2633249728 net.cpp:137] Memory required for data: 4280316880
I1021 01:01:16.294087 2633249728 layer_factory.hpp:77] Creating layer relu1
I1021 01:01:16.294127 2633249728 net.cpp:84] Creating Layer relu1
I1021 01:01:16.294139 2633249728 net.cpp:406] relu1 <- ip1
I1021 01:01:16.294148 2633249728 net.cpp:367] relu1 -> ip1 (in-place)
I1021 01:01:16.294157 2633249728 net.cpp:122] Setting up relu1
I1021 01:01:16.294162 2633249728 net.cpp:129] Top shape: 20 500 (10000)
I1021 01:01:16.294167 2633249728 net.cpp:137] Memory required for data: 4280356880
I1021 01:01:16.294173 2633249728 layer_factory.hpp:77] Creating layer ip2
I1021 01:01:16.294188 2633249728 net.cpp:84] Creating Layer ip2
I1021 01:01:16.294194 2633249728 net.cpp:406] ip2 <- ip1
I1021 01:01:16.294200 2633249728 net.cpp:380] ip2 -> ip2
I1021 01:01:16.294344 2633249728 net.cpp:122] Setting up ip2
I1021 01:01:16.294361 2633249728 net.cpp:129] Top shape: 20 10 (200)
I1021 01:01:16.294399 2633249728 net.cpp:137] Memory required for data: 4280357680
I1021 01:01:16.294414 2633249728 layer_factory.hpp:77] Creating layer feat
I1021 01:01:16.294430 2633249728 net.cpp:84] Creating Layer feat
I1021 01:01:16.294440 2633249728 net.cpp:406] feat <- ip2
I1021 01:01:16.294452 2633249728 net.cpp:380] feat -> feat
I1021 01:01:16.294476 2633249728 net.cpp:122] Setting up feat
I1021 01:01:16.294486 2633249728 net.cpp:129] Top shape: 20 10 (200)
I1021 01:01:16.294497 2633249728 net.cpp:137] Memory required for data: 4280358480
I1021 01:01:16.294507 2633249728 layer_factory.hpp:77] Creating layer conv1_p
I1021 01:01:16.294520 2633249728 net.cpp:84] Creating Layer conv1_p
I1021 01:01:16.294530 2633249728 net.cpp:406] conv1_p <- data_p
I1021 01:01:16.294543 2633249728 net.cpp:380] conv1_p -> conv1_p
I1021 01:01:16.297055 2633249728 net.cpp:122] Setting up conv1_p
I1021 01:01:16.297089 2633249728 net.cpp:129] Top shape: 20 20 223 223 (19891600)
I1021 01:01:16.297127 2633249728 net.cpp:137] Memory required for data: 4359924880
I1021 01:01:16.297140 2633249728 net.cpp:465] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I1021 01:01:16.297152 2633249728 net.cpp:465] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I1021 01:01:16.297158 2633249728 layer_factory.hpp:77] Creating layer pool1_p
I1021 01:01:16.297168 2633249728 net.cpp:84] Creating Layer pool1_p
I1021 01:01:16.297173 2633249728 net.cpp:406] pool1_p <- conv1_p
I1021 01:01:16.297180 2633249728 net.cpp:380] pool1_p -> pool1_p
I1021 01:01:16.297194 2633249728 net.cpp:122] Setting up pool1_p
I1021 01:01:16.297205 2633249728 net.cpp:129] Top shape: 20 20 112 112 (5017600)
I1021 01:01:16.297219 2633249728 net.cpp:137] Memory required for data: 4379995280
I1021 01:01:16.297227 2633249728 layer_factory.hpp:77] Creating layer conv2_p
I1021 01:01:16.297245 2633249728 net.cpp:84] Creating Layer conv2_p
I1021 01:01:16.297250 2633249728 net.cpp:406] conv2_p <- pool1_p
I1021 01:01:16.297260 2633249728 net.cpp:380] conv2_p -> conv2_p
I1021 01:01:16.297616 2633249728 net.cpp:122] Setting up conv2_p
I1021 01:01:16.297653 2633249728 net.cpp:129] Top shape: 20 50 108 108 (11664000)
I1021 01:01:16.297662 2633249728 net.cpp:137] Memory required for data: 4426651280
I1021 01:01:16.297667 2633249728 net.cpp:465] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I1021 01:01:16.297673 2633249728 net.cpp:465] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I1021 01:01:16.297678 2633249728 layer_factory.hpp:77] Creating layer pool2_p
I1021 01:01:16.297685 2633249728 net.cpp:84] Creating Layer pool2_p
I1021 01:01:16.297690 2633249728 net.cpp:406] pool2_p <- conv2_p
I1021 01:01:16.297700 2633249728 net.cpp:380] pool2_p -> pool2_p
I1021 01:01:16.297714 2633249728 net.cpp:122] Setting up pool2_p
I1021 01:01:16.297724 2633249728 net.cpp:129] Top shape: 20 50 54 54 (2916000)
I1021 01:01:16.297735 2633249728 net.cpp:137] Memory required for data: 4438315280
I1021 01:01:16.297744 2633249728 layer_factory.hpp:77] Creating layer ip1_p
I1021 01:01:16.297758 2633249728 net.cpp:84] Creating Layer ip1_p
I1021 01:01:16.297766 2633249728 net.cpp:406] ip1_p <- pool2_p
I1021 01:01:16.297772 2633249728 net.cpp:380] ip1_p -> ip1_p
I1021 01:01:17.481972 2633249728 net.cpp:122] Setting up ip1_p
I1021 01:01:17.482003 2633249728 net.cpp:129] Top shape: 20 500 (10000)
I1021 01:01:17.482012 2633249728 net.cpp:137] Memory required for data: 4438355280
I1021 01:01:17.482019 2633249728 net.cpp:465] Sharing parameters 'ip1_w' owned by layer 'ip1', param index 0
I1021 01:01:17.482026 2633249728 net.cpp:465] Sharing parameters 'ip1_b' owned by layer 'ip1', param index 1
I1021 01:01:17.482031 2633249728 layer_factory.hpp:77] Creating layer relu1_p
I1021 01:01:17.482041 2633249728 net.cpp:84] Creating Layer relu1_p
I1021 01:01:17.482048 2633249728 net.cpp:406] relu1_p <- ip1_p
I1021 01:01:17.482054 2633249728 net.cpp:367] relu1_p -> ip1_p (in-place)
I1021 01:01:17.482085 2633249728 net.cpp:122] Setting up relu1_p
I1021 01:01:17.482101 2633249728 net.cpp:129] Top shape: 20 500 (10000)
I1021 01:01:17.482112 2633249728 net.cpp:137] Memory required for data: 4438395280
I1021 01:01:17.482123 2633249728 layer_factory.hpp:77] Creating layer ip2_p
I1021 01:01:17.482141 2633249728 net.cpp:84] Creating Layer ip2_p
I1021 01:01:17.482153 2633249728 net.cpp:406] ip2_p <- ip1_p
I1021 01:01:17.482167 2633249728 net.cpp:380] ip2_p -> ip2_p
I1021 01:01:17.482267 2633249728 net.cpp:122] Setting up ip2_p
I1021 01:01:17.482280 2633249728 net.cpp:129] Top shape: 20 10 (200)
I1021 01:01:17.482290 2633249728 net.cpp:137] Memory required for data: 4438396080
I1021 01:01:17.482301 2633249728 net.cpp:465] Sharing parameters 'ip2_w' owned by layer 'ip2', param index 0
I1021 01:01:17.482312 2633249728 net.cpp:465] Sharing parameters 'ip2_b' owned by layer 'ip2', param index 1
I1021 01:01:17.482321 2633249728 layer_factory.hpp:77] Creating layer feat_p
I1021 01:01:17.482336 2633249728 net.cpp:84] Creating Layer feat_p
I1021 01:01:17.483407 2633249728 net.cpp:406] feat_p <- ip2_p
I1021 01:01:17.483436 2633249728 net.cpp:380] feat_p -> feat_p
I1021 01:01:17.483466 2633249728 net.cpp:122] Setting up feat_p
I1021 01:01:17.483474 2633249728 net.cpp:129] Top shape: 20 10 (200)
I1021 01:01:17.483484 2633249728 net.cpp:137] Memory required for data: 4438396880
I1021 01:01:17.483490 2633249728 net.cpp:465] Sharing parameters 'feat_w' owned by layer 'feat', param index 0
I1021 01:01:17.483496 2633249728 net.cpp:465] Sharing parameters 'feat_b' owned by layer 'feat', param index 1
I1021 01:01:17.483502 2633249728 layer_factory.hpp:77] Creating layer loss
I1021 01:01:17.483521 2633249728 net.cpp:84] Creating Layer loss
I1021 01:01:17.483536 2633249728 net.cpp:406] loss <- feat
I1021 01:01:17.483548 2633249728 net.cpp:406] loss <- feat_p
I1021 01:01:17.483558 2633249728 net.cpp:406] loss <- sim
I1021 01:01:17.483572 2633249728 net.cpp:380] loss -> loss
I1021 01:01:17.483589 2633249728 net.cpp:122] Setting up loss
I1021 01:01:17.483599 2633249728 net.cpp:129] Top shape: (1)
I1021 01:01:17.483610 2633249728 net.cpp:132]     with loss weight 1
I1021 01:01:17.483655 2633249728 net.cpp:137] Memory required for data: 4438396884
I1021 01:01:17.483665 2633249728 net.cpp:198] loss needs backward computation.
I1021 01:01:17.483675 2633249728 net.cpp:198] feat_p needs backward computation.
I1021 01:01:17.483685 2633249728 net.cpp:198] ip2_p needs backward computation.
I1021 01:01:17.483693 2633249728 net.cpp:198] relu1_p needs backward computation.
I1021 01:01:17.483698 2633249728 net.cpp:198] ip1_p needs backward computation.
I1021 01:01:17.483703 2633249728 net.cpp:198] pool2_p needs backward computation.
I1021 01:01:17.483707 2633249728 net.cpp:198] conv2_p needs backward computation.
I1021 01:01:17.483712 2633249728 net.cpp:198] pool1_p needs backward computation.
I1021 01:01:17.483717 2633249728 net.cpp:198] conv1_p needs backward computation.
I1021 01:01:17.483721 2633249728 net.cpp:198] feat needs backward computation.
I1021 01:01:17.483726 2633249728 net.cpp:198] ip2 needs backward computation.
I1021 01:01:17.483731 2633249728 net.cpp:198] relu1 needs backward computation.
I1021 01:01:17.483736 2633249728 net.cpp:198] ip1 needs backward computation.
I1021 01:01:17.483741 2633249728 net.cpp:198] pool2 needs backward computation.
I1021 01:01:17.483745 2633249728 net.cpp:198] conv2 needs backward computation.
I1021 01:01:17.483749 2633249728 net.cpp:198] pool1 needs backward computation.
I1021 01:01:17.483754 2633249728 net.cpp:198] conv1 needs backward computation.
I1021 01:01:17.483759 2633249728 net.cpp:200] slice_pair does not need backward computation.
I1021 01:01:17.483764 2633249728 net.cpp:200] pair_data does not need backward computation.
I1021 01:01:17.483770 2633249728 net.cpp:242] This network produces output loss
I1021 01:01:17.524204 2633249728 net.cpp:255] Network initialization done.
I1021 01:01:17.525172 2633249728 solver.cpp:172] Creating test net (#0) specified by net file: ./lenet_siamese_train_test.prototxt
I1021 01:01:17.525269 2633249728 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer pair_data
I1021 01:01:17.525301 2633249728 net.cpp:51] Initializing net from parameters: 
name: "lenet_siamese_train_test"
state {
  phase: TEST
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TEST
  }
  data_param {
    source: "/Users/HZzone/Desktop/determination-data/siamese_test_lmdb"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 250
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "pool2_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "ip2_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "ip2_p"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip2_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I1021 01:01:17.525699 2633249728 layer_factory.hpp:77] Creating layer pair_data
I1021 01:01:17.526893 2633249728 db_lmdb.cpp:35] Opened lmdb /Users/HZzone/Desktop/determination-data/siamese_test_lmdb
I1021 01:01:17.527237 2633249728 net.cpp:84] Creating Layer pair_data
I1021 01:01:17.527319 2633249728 net.cpp:380] pair_data -> pair_data
I1021 01:01:17.527391 2633249728 net.cpp:380] pair_data -> sim
I1021 01:01:19.691061 2633249728 data_layer.cpp:45] output data size: 10,500,227,227
I1021 01:01:25.086889 2633249728 net.cpp:122] Setting up pair_data
I1021 01:01:25.087216 2633249728 net.cpp:129] Top shape: 10 500 227 227 (257645000)
I1021 01:01:25.087306 2633249728 net.cpp:129] Top shape: 10 (10)
I1021 01:01:25.087335 2633249728 net.cpp:137] Memory required for data: 1030580040
I1021 01:01:25.087368 2633249728 layer_factory.hpp:77] Creating layer slice_pair
I1021 01:01:25.087622 2633249728 net.cpp:84] Creating Layer slice_pair
I1021 01:01:25.087680 2633249728 net.cpp:406] slice_pair <- pair_data
I1021 01:01:25.088093 2633249728 net.cpp:380] slice_pair -> data
I1021 01:01:25.088484 2633249728 net.cpp:380] slice_pair -> data_p
I1021 01:01:25.088891 2633249728 net.cpp:122] Setting up slice_pair
I1021 01:01:25.088963 2633249728 net.cpp:129] Top shape: 10 250 227 227 (128822500)
I1021 01:01:25.088992 2633249728 net.cpp:129] Top shape: 10 250 227 227 (128822500)
I1021 01:01:25.089283 2633249728 net.cpp:137] Memory required for data: 2061160040
I1021 01:01:25.089319 2633249728 layer_factory.hpp:77] Creating layer conv1
I1021 01:01:25.089370 2633249728 net.cpp:84] Creating Layer conv1
I1021 01:01:25.089385 2633249728 net.cpp:406] conv1 <- data
I1021 01:01:25.089429 2633249728 net.cpp:380] conv1 -> conv1
I1021 01:01:25.091323 2633249728 net.cpp:122] Setting up conv1
I1021 01:01:25.091398 2633249728 net.cpp:129] Top shape: 10 20 223 223 (9945800)
I1021 01:01:25.091423 2633249728 net.cpp:137] Memory required for data: 2100943240
I1021 01:01:25.091434 2633249728 layer_factory.hpp:77] Creating layer pool1
I1021 01:01:25.091450 2633249728 net.cpp:84] Creating Layer pool1
I1021 01:01:25.091459 2633249728 net.cpp:406] pool1 <- conv1
I1021 01:01:25.091465 2633249728 net.cpp:380] pool1 -> pool1
I1021 01:01:25.091529 2633249728 net.cpp:122] Setting up pool1
I1021 01:01:25.091562 2633249728 net.cpp:129] Top shape: 10 20 112 112 (2508800)
I1021 01:01:25.091581 2633249728 net.cpp:137] Memory required for data: 2110978440
I1021 01:01:25.091599 2633249728 layer_factory.hpp:77] Creating layer conv2
I1021 01:01:25.092865 2633249728 net.cpp:84] Creating Layer conv2
I1021 01:01:25.092972 2633249728 net.cpp:406] conv2 <- pool1
I1021 01:01:25.093020 2633249728 net.cpp:380] conv2 -> conv2
I1021 01:01:25.093607 2633249728 net.cpp:122] Setting up conv2
I1021 01:01:25.093636 2633249728 net.cpp:129] Top shape: 10 50 108 108 (5832000)
I1021 01:01:25.093650 2633249728 net.cpp:137] Memory required for data: 2134306440
I1021 01:01:25.093668 2633249728 layer_factory.hpp:77] Creating layer pool2
I1021 01:01:25.093694 2633249728 net.cpp:84] Creating Layer pool2
I1021 01:01:25.093703 2633249728 net.cpp:406] pool2 <- conv2
I1021 01:01:25.093717 2633249728 net.cpp:380] pool2 -> pool2
I1021 01:01:25.093735 2633249728 net.cpp:122] Setting up pool2
I1021 01:01:25.093760 2633249728 net.cpp:129] Top shape: 10 50 54 54 (1458000)
I1021 01:01:25.093838 2633249728 net.cpp:137] Memory required for data: 2140138440
I1021 01:01:25.093853 2633249728 layer_factory.hpp:77] Creating layer ip1
I1021 01:01:25.093897 2633249728 net.cpp:84] Creating Layer ip1
I1021 01:01:25.093922 2633249728 net.cpp:406] ip1 <- pool2
I1021 01:01:25.093953 2633249728 net.cpp:380] ip1 -> ip1
I1021 01:01:26.303846 2633249728 net.cpp:122] Setting up ip1
I1021 01:01:26.303920 2633249728 net.cpp:129] Top shape: 10 500 (5000)
I1021 01:01:26.303941 2633249728 net.cpp:137] Memory required for data: 2140158440
I1021 01:01:26.303963 2633249728 layer_factory.hpp:77] Creating layer relu1
I1021 01:01:26.304015 2633249728 net.cpp:84] Creating Layer relu1
I1021 01:01:26.304028 2633249728 net.cpp:406] relu1 <- ip1
I1021 01:01:26.304044 2633249728 net.cpp:367] relu1 -> ip1 (in-place)
I1021 01:01:26.304100 2633249728 net.cpp:122] Setting up relu1
I1021 01:01:26.304113 2633249728 net.cpp:129] Top shape: 10 500 (5000)
I1021 01:01:26.304126 2633249728 net.cpp:137] Memory required for data: 2140178440
I1021 01:01:26.304155 2633249728 layer_factory.hpp:77] Creating layer ip2
I1021 01:01:26.304244 2633249728 net.cpp:84] Creating Layer ip2
I1021 01:01:26.304263 2633249728 net.cpp:406] ip2 <- ip1
I1021 01:01:26.304277 2633249728 net.cpp:380] ip2 -> ip2
I1021 01:01:26.304391 2633249728 net.cpp:122] Setting up ip2
I1021 01:01:26.304422 2633249728 net.cpp:129] Top shape: 10 10 (100)
I1021 01:01:26.304433 2633249728 net.cpp:137] Memory required for data: 2140178840
I1021 01:01:26.304445 2633249728 layer_factory.hpp:77] Creating layer feat
I1021 01:01:26.304461 2633249728 net.cpp:84] Creating Layer feat
I1021 01:01:26.304471 2633249728 net.cpp:406] feat <- ip2
I1021 01:01:26.304479 2633249728 net.cpp:380] feat -> feat
I1021 01:01:26.304497 2633249728 net.cpp:122] Setting up feat
I1021 01:01:26.304502 2633249728 net.cpp:129] Top shape: 10 10 (100)
I1021 01:01:26.304534 2633249728 net.cpp:137] Memory required for data: 2140179240
I1021 01:01:26.304553 2633249728 layer_factory.hpp:77] Creating layer conv1_p
I1021 01:01:26.304567 2633249728 net.cpp:84] Creating Layer conv1_p
I1021 01:01:26.304576 2633249728 net.cpp:406] conv1_p <- data_p
I1021 01:01:26.304605 2633249728 net.cpp:380] conv1_p -> conv1_p
I1021 01:01:26.306586 2633249728 net.cpp:122] Setting up conv1_p
I1021 01:01:26.306627 2633249728 net.cpp:129] Top shape: 10 20 223 223 (9945800)
I1021 01:01:26.306643 2633249728 net.cpp:137] Memory required for data: 2179962440
I1021 01:01:26.306658 2633249728 net.cpp:465] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I1021 01:01:26.306668 2633249728 net.cpp:465] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I1021 01:01:26.306675 2633249728 layer_factory.hpp:77] Creating layer pool1_p
I1021 01:01:26.306685 2633249728 net.cpp:84] Creating Layer pool1_p
I1021 01:01:26.306690 2633249728 net.cpp:406] pool1_p <- conv1_p
I1021 01:01:26.306701 2633249728 net.cpp:380] pool1_p -> pool1_p
I1021 01:01:26.306717 2633249728 net.cpp:122] Setting up pool1_p
I1021 01:01:26.306727 2633249728 net.cpp:129] Top shape: 10 20 112 112 (2508800)
I1021 01:01:26.306738 2633249728 net.cpp:137] Memory required for data: 2189997640
I1021 01:01:26.306749 2633249728 layer_factory.hpp:77] Creating layer conv2_p
I1021 01:01:26.306783 2633249728 net.cpp:84] Creating Layer conv2_p
I1021 01:01:26.306794 2633249728 net.cpp:406] conv2_p <- pool1_p
I1021 01:01:26.306807 2633249728 net.cpp:380] conv2_p -> conv2_p
I1021 01:01:26.307238 2633249728 net.cpp:122] Setting up conv2_p
I1021 01:01:26.307252 2633249728 net.cpp:129] Top shape: 10 50 108 108 (5832000)
I1021 01:01:26.307260 2633249728 net.cpp:137] Memory required for data: 2213325640
I1021 01:01:26.307265 2633249728 net.cpp:465] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I1021 01:01:26.307274 2633249728 net.cpp:465] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I1021 01:01:26.307286 2633249728 layer_factory.hpp:77] Creating layer pool2_p
I1021 01:01:26.307314 2633249728 net.cpp:84] Creating Layer pool2_p
I1021 01:01:26.307324 2633249728 net.cpp:406] pool2_p <- conv2_p
I1021 01:01:26.307348 2633249728 net.cpp:380] pool2_p -> pool2_p
I1021 01:01:26.307363 2633249728 net.cpp:122] Setting up pool2_p
I1021 01:01:26.307374 2633249728 net.cpp:129] Top shape: 10 50 54 54 (1458000)
I1021 01:01:26.307385 2633249728 net.cpp:137] Memory required for data: 2219157640
I1021 01:01:26.307394 2633249728 layer_factory.hpp:77] Creating layer ip1_p
I1021 01:01:26.307407 2633249728 net.cpp:84] Creating Layer ip1_p
I1021 01:01:26.307415 2633249728 net.cpp:406] ip1_p <- pool2_p
I1021 01:01:26.307446 2633249728 net.cpp:380] ip1_p -> ip1_p
I1021 01:01:27.546658 2633249728 net.cpp:122] Setting up ip1_p
I1021 01:01:27.546711 2633249728 net.cpp:129] Top shape: 10 500 (5000)
I1021 01:01:27.546720 2633249728 net.cpp:137] Memory required for data: 2219177640
I1021 01:01:27.546731 2633249728 net.cpp:465] Sharing parameters 'ip1_w' owned by layer 'ip1', param index 0
I1021 01:01:27.546737 2633249728 net.cpp:465] Sharing parameters 'ip1_b' owned by layer 'ip1', param index 1
I1021 01:01:27.546774 2633249728 layer_factory.hpp:77] Creating layer relu1_p
I1021 01:01:27.546787 2633249728 net.cpp:84] Creating Layer relu1_p
I1021 01:01:27.546792 2633249728 net.cpp:406] relu1_p <- ip1_p
I1021 01:01:27.546799 2633249728 net.cpp:367] relu1_p -> ip1_p (in-place)
I1021 01:01:27.546808 2633249728 net.cpp:122] Setting up relu1_p
I1021 01:01:27.546813 2633249728 net.cpp:129] Top shape: 10 500 (5000)
I1021 01:01:27.546847 2633249728 net.cpp:137] Memory required for data: 2219197640
I1021 01:01:27.546854 2633249728 layer_factory.hpp:77] Creating layer ip2_p
I1021 01:01:27.546895 2633249728 net.cpp:84] Creating Layer ip2_p
I1021 01:01:27.546916 2633249728 net.cpp:406] ip2_p <- ip1_p
I1021 01:01:27.546939 2633249728 net.cpp:380] ip2_p -> ip2_p
I1021 01:01:27.548471 2633249728 net.cpp:122] Setting up ip2_p
I1021 01:01:27.548527 2633249728 net.cpp:129] Top shape: 10 10 (100)
I1021 01:01:27.548543 2633249728 net.cpp:137] Memory required for data: 2219198040
I1021 01:01:27.548578 2633249728 net.cpp:465] Sharing parameters 'ip2_w' owned by layer 'ip2', param index 0
I1021 01:01:27.548611 2633249728 net.cpp:465] Sharing parameters 'ip2_b' owned by layer 'ip2', param index 1
I1021 01:01:27.548622 2633249728 layer_factory.hpp:77] Creating layer feat_p
I1021 01:01:27.548636 2633249728 net.cpp:84] Creating Layer feat_p
I1021 01:01:27.548645 2633249728 net.cpp:406] feat_p <- ip2_p
I1021 01:01:27.548657 2633249728 net.cpp:380] feat_p -> feat_p
I1021 01:01:27.548750 2633249728 net.cpp:122] Setting up feat_p
I1021 01:01:27.548791 2633249728 net.cpp:129] Top shape: 10 10 (100)
I1021 01:01:27.548816 2633249728 net.cpp:137] Memory required for data: 2219198440
I1021 01:01:27.548826 2633249728 net.cpp:465] Sharing parameters 'feat_w' owned by layer 'feat', param index 0
I1021 01:01:27.548836 2633249728 net.cpp:465] Sharing parameters 'feat_b' owned by layer 'feat', param index 1
I1021 01:01:27.548846 2633249728 layer_factory.hpp:77] Creating layer loss
I1021 01:01:27.548876 2633249728 net.cpp:84] Creating Layer loss
I1021 01:01:27.548887 2633249728 net.cpp:406] loss <- feat
I1021 01:01:27.548895 2633249728 net.cpp:406] loss <- feat_p
I1021 01:01:27.548904 2633249728 net.cpp:406] loss <- sim
I1021 01:01:27.548914 2633249728 net.cpp:380] loss -> loss
I1021 01:01:27.548951 2633249728 net.cpp:122] Setting up loss
I1021 01:01:27.548961 2633249728 net.cpp:129] Top shape: (1)
I1021 01:01:27.548971 2633249728 net.cpp:132]     with loss weight 1
I1021 01:01:27.548996 2633249728 net.cpp:137] Memory required for data: 2219198444
I1021 01:01:27.549005 2633249728 net.cpp:198] loss needs backward computation.
I1021 01:01:27.549015 2633249728 net.cpp:198] feat_p needs backward computation.
I1021 01:01:27.549024 2633249728 net.cpp:198] ip2_p needs backward computation.
I1021 01:01:27.549032 2633249728 net.cpp:198] relu1_p needs backward computation.
I1021 01:01:27.549041 2633249728 net.cpp:198] ip1_p needs backward computation.
I1021 01:01:27.549049 2633249728 net.cpp:198] pool2_p needs backward computation.
I1021 01:01:27.549058 2633249728 net.cpp:198] conv2_p needs backward computation.
I1021 01:01:27.549067 2633249728 net.cpp:198] pool1_p needs backward computation.
I1021 01:01:27.549075 2633249728 net.cpp:198] conv1_p needs backward computation.
I1021 01:01:27.549083 2633249728 net.cpp:198] feat needs backward computation.
I1021 01:01:27.549093 2633249728 net.cpp:198] ip2 needs backward computation.
I1021 01:01:27.549100 2633249728 net.cpp:198] relu1 needs backward computation.
I1021 01:01:27.549108 2633249728 net.cpp:198] ip1 needs backward computation.
I1021 01:01:27.549118 2633249728 net.cpp:198] pool2 needs backward computation.
I1021 01:01:27.549125 2633249728 net.cpp:198] conv2 needs backward computation.
I1021 01:01:27.549134 2633249728 net.cpp:198] pool1 needs backward computation.
I1021 01:01:27.549165 2633249728 net.cpp:198] conv1 needs backward computation.
I1021 01:01:27.549177 2633249728 net.cpp:200] slice_pair does not need backward computation.
I1021 01:01:27.549199 2633249728 net.cpp:200] pair_data does not need backward computation.
I1021 01:01:27.549209 2633249728 net.cpp:242] This network produces output loss
I1021 01:01:27.577097 2633249728 net.cpp:255] Network initialization done.
I1021 01:01:27.577316 2633249728 solver.cpp:56] Solver scaffolding done.
I1021 01:01:27.578210 2633249728 caffe.cpp:248] Starting Optimization
I1021 01:01:27.578280 2633249728 solver.cpp:272] Solving lenet_siamese_train_test
I1021 01:01:27.578294 2633249728 solver.cpp:273] Learning Rate Policy: inv
I1021 01:01:27.659744 2633249728 solver.cpp:330] Iteration 0, Testing net (#0)
I1021 01:01:27.687813 2633249728 blocking_queue.cpp:49] Waiting for data
I1021 01:01:29.983855 137904128 data_layer.cpp:73] Restarting data prefetching from start.
I1021 01:01:46.178617 137904128 data_layer.cpp:73] Restarting data prefetching from start.
I1021 01:02:03.621924 138440704 data_layer.cpp:73] Restarting data prefetching from start.
I1021 01:02:22.398665 137904128 data_layer.cpp:73] Restarting data prefetching from start.
