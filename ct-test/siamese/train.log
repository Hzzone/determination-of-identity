I1109 18:09:06.133183 26228 caffe.cpp:218] Using GPUs 0
I1109 18:09:06.189919 26228 caffe.cpp:223] GPU 0: GeForce GTX 1080 Ti
I1109 18:09:06.750432 26228 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.0001
display: 20
max_iter: 10000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
stepsize: 3000
snapshot: 100
snapshot_prefix: "./c3d_lenet"
solver_mode: GPU
device_id: 0
net: "./3d_lenet_siamese.prototxt"
train_state {
  level: 0
  stage: ""
}
I1109 18:09:06.750674 26228 solver.cpp:87] Creating training net from net file: ./3d_lenet_siamese.prototxt
I1109 18:09:06.752995 26228 net.cpp:51] Initializing net from parameters: 
name: "C3D-UCF101Net"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "pair_data"
  type: "HDF5Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "./train.txt"
    batch_size: 3
    shuffle: true
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 2
    slice_point: 40
  }
}
layer {
  name: "conv1a"
  type: "Convolution3D"
  bottom: "data"
  top: "conv1a"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "Pooling3D"
  bottom: "conv1a"
  top: "pool1"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 1
    temporal_stride: 1
  }
}
layer {
  name: "conv2a"
  type: "Convolution3D"
  bottom: "pool1"
  top: "conv2a"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "Pooling3D"
  bottom: "conv2a"
  top: "pool2"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "conv3a"
  type: "Convolution3D"
  bottom: "pool2"
  top: "conv3a"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "Pooling3D"
  bottom: "conv3a"
  top: "pool3"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "conv4a"
  type: "Convolution3D"
  bottom: "pool3"
  top: "conv4a"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "Pooling3D"
  bottom: "conv4a"
  top: "pool4"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "conv5a"
  type: "Convolution3D"
  bottom: "pool4"
  top: "conv5a"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "Pooling3D"
  bottom: "conv5a"
  top: "pool5"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    name: "fc8_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 101
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a_p"
  type: "Convolution3D"
  bottom: "data_p"
  top: "conv1a_p"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu1a_p"
  type: "ReLU"
  bottom: "conv1a_p"
  top: "conv1a_p"
}
layer {
  name: "pool1_p"
  type: "Pooling3D"
  bottom: "conv1a_p"
  top: "pool1_p"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 1
    temporal_stride: 1
  }
}
layer {
  name: "conv2a_p"
  type: "Convolution3D"
  bottom: "pool1_p"
  top: "conv2a_p"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu2a_p"
  type: "ReLU"
  bottom: "conv2a_p"
  top: "conv2a_p"
}
layer {
  name: "pool2_p"
  type: "Pooling3D"
  bottom: "conv2a_p"
  top: "pool2_p"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "conv3a_p"
  type: "Convolution3D"
  bottom: "pool2_p"
  top: "conv3a_p"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu3a_p"
  type: "ReLU"
  bottom: "conv3a_p"
  top: "conv3a_p"
}
layer {
  name: "pool3_p"
  type: "Pooling3D"
  bottom: "conv3a_p"
  top: "pool3_p"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "conv4a_p"
  type: "Convolution3D"
  bottom: "pool3_p"
  top: "conv4a_p"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu4a_p"
  type: "ReLU"
  bottom: "conv4a_p"
  top: "conv4a_p"
}
layer {
  name: "pool4_p"
  type: "Pooling3D"
  bottom: "conv4a_p"
  top: "pool4_p"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "conv5a_p"
  type: "Convolution3D"
  bottom: "pool4_p"
  top: "conv5a_p"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu5a_p"
  type: "ReLU"
  bottom: "conv5a_p"
  top: "conv5a_p"
}
layer {
  name: "pool5_p"
  type: "Pooling3D"
  bottom: "conv5a_p"
  top: "pool5_p"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "fc6_p"
  type: "InnerProduct"
  bottom: "pool5_p"
  top: "fc6_p"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_p"
  type: "ReLU"
  bottom: "fc6_p"
  top: "fc6_p"
}
layer {
  name: "drop6_p"
  type: "Dropout"
  bottom: "fc6_p"
  top: "fc6_p"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_p"
  type: "InnerProduct"
  bottom: "fc6_p"
  top: "fc7_p"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_p"
  type: "ReLU"
  bottom: "fc7_p"
  top: "fc7_p"
}
layer {
  name: "drop7_p"
  type: "Dropout"
  bottom: "fc7_p"
  top: "fc7_p"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_p"
  type: "InnerProduct"
  bottom: "fc7_p"
  top: "fc8_p"
  param {
    name: "fc8_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 101
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "fc8"
  bottom: "fc8_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I1109 18:09:06.754060 26228 layer_factory.hpp:77] Creating layer pair_data
I1109 18:09:06.754273 26228 net.cpp:84] Creating Layer pair_data
I1109 18:09:06.754287 26228 net.cpp:380] pair_data -> pair_data
I1109 18:09:06.754330 26228 net.cpp:380] pair_data -> sim
I1109 18:09:06.754349 26228 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: ./train.txt
I1109 18:09:06.754485 26228 hdf5_data_layer.cpp:93] Number of HDF5 files: 166
I1109 18:09:06.784088 26228 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1109 18:09:06.798125 26228 net.cpp:122] Setting up pair_data
I1109 18:09:06.798168 26228 net.cpp:129] Top shape: 3 1 80 120 120 (3456000)
I1109 18:09:06.798177 26228 net.cpp:129] Top shape: 3 (3)
I1109 18:09:06.798182 26228 net.cpp:137] Memory required for data: 13824012
I1109 18:09:06.798194 26228 layer_factory.hpp:77] Creating layer slice_pair
I1109 18:09:06.798213 26228 net.cpp:84] Creating Layer slice_pair
I1109 18:09:06.798224 26228 net.cpp:406] slice_pair <- pair_data
I1109 18:09:06.798254 26228 net.cpp:380] slice_pair -> data
I1109 18:09:06.798272 26228 net.cpp:380] slice_pair -> data_p
I1109 18:09:06.798317 26228 net.cpp:122] Setting up slice_pair
I1109 18:09:06.798327 26228 net.cpp:129] Top shape: 3 1 40 120 120 (1728000)
I1109 18:09:06.798336 26228 net.cpp:129] Top shape: 3 1 40 120 120 (1728000)
I1109 18:09:06.798339 26228 net.cpp:137] Memory required for data: 27648012
I1109 18:09:06.798344 26228 layer_factory.hpp:77] Creating layer conv1a
I1109 18:09:06.798357 26228 net.cpp:84] Creating Layer conv1a
I1109 18:09:06.798364 26228 net.cpp:406] conv1a <- data
I1109 18:09:06.798372 26228 net.cpp:380] conv1a -> conv1a
I1109 18:09:06.802484 26228 net.cpp:122] Setting up conv1a
I1109 18:09:06.802534 26228 net.cpp:129] Top shape: 3 64 40 120 120 (110592000)
I1109 18:09:06.802541 26228 net.cpp:137] Memory required for data: 470016012
I1109 18:09:06.802570 26228 layer_factory.hpp:77] Creating layer relu1a
I1109 18:09:06.802584 26228 net.cpp:84] Creating Layer relu1a
I1109 18:09:06.802592 26228 net.cpp:406] relu1a <- conv1a
I1109 18:09:06.802599 26228 net.cpp:367] relu1a -> conv1a (in-place)
I1109 18:09:06.802613 26228 net.cpp:122] Setting up relu1a
I1109 18:09:06.802620 26228 net.cpp:129] Top shape: 3 64 40 120 120 (110592000)
I1109 18:09:06.802624 26228 net.cpp:137] Memory required for data: 912384012
I1109 18:09:06.802628 26228 layer_factory.hpp:77] Creating layer pool1
I1109 18:09:06.802637 26228 net.cpp:84] Creating Layer pool1
I1109 18:09:06.802642 26228 net.cpp:406] pool1 <- conv1a
I1109 18:09:06.802649 26228 net.cpp:380] pool1 -> pool1
I1109 18:09:06.802721 26228 net.cpp:122] Setting up pool1
I1109 18:09:06.802731 26228 net.cpp:129] Top shape: 3 64 40 60 60 (27648000)
I1109 18:09:06.802734 26228 net.cpp:137] Memory required for data: 1022976012
I1109 18:09:06.802738 26228 layer_factory.hpp:77] Creating layer conv2a
I1109 18:09:06.802748 26228 net.cpp:84] Creating Layer conv2a
I1109 18:09:06.802753 26228 net.cpp:406] conv2a <- pool1
I1109 18:09:06.802760 26228 net.cpp:380] conv2a -> conv2a
I1109 18:09:06.806962 26228 net.cpp:122] Setting up conv2a
I1109 18:09:06.806998 26228 net.cpp:129] Top shape: 3 128 40 60 60 (55296000)
I1109 18:09:06.807003 26228 net.cpp:137] Memory required for data: 1244160012
I1109 18:09:06.807024 26228 layer_factory.hpp:77] Creating layer relu2a
I1109 18:09:06.807035 26228 net.cpp:84] Creating Layer relu2a
I1109 18:09:06.807041 26228 net.cpp:406] relu2a <- conv2a
I1109 18:09:06.807050 26228 net.cpp:367] relu2a -> conv2a (in-place)
I1109 18:09:06.807062 26228 net.cpp:122] Setting up relu2a
I1109 18:09:06.807070 26228 net.cpp:129] Top shape: 3 128 40 60 60 (55296000)
I1109 18:09:06.807073 26228 net.cpp:137] Memory required for data: 1465344012
I1109 18:09:06.807076 26228 layer_factory.hpp:77] Creating layer pool2
I1109 18:09:06.807085 26228 net.cpp:84] Creating Layer pool2
I1109 18:09:06.807090 26228 net.cpp:406] pool2 <- conv2a
I1109 18:09:06.807096 26228 net.cpp:380] pool2 -> pool2
I1109 18:09:06.807121 26228 net.cpp:122] Setting up pool2
I1109 18:09:06.807149 26228 net.cpp:129] Top shape: 3 128 20 30 30 (6912000)
I1109 18:09:06.807154 26228 net.cpp:137] Memory required for data: 1492992012
I1109 18:09:06.807157 26228 layer_factory.hpp:77] Creating layer conv3a
I1109 18:09:06.807168 26228 net.cpp:84] Creating Layer conv3a
I1109 18:09:06.807202 26228 net.cpp:406] conv3a <- pool2
I1109 18:09:06.807210 26228 net.cpp:380] conv3a -> conv3a
I1109 18:09:06.821012 26228 net.cpp:122] Setting up conv3a
I1109 18:09:06.821064 26228 net.cpp:129] Top shape: 3 256 20 30 30 (13824000)
I1109 18:09:06.821070 26228 net.cpp:137] Memory required for data: 1548288012
I1109 18:09:06.821096 26228 layer_factory.hpp:77] Creating layer relu3a
I1109 18:09:06.821110 26228 net.cpp:84] Creating Layer relu3a
I1109 18:09:06.821116 26228 net.cpp:406] relu3a <- conv3a
I1109 18:09:06.821126 26228 net.cpp:367] relu3a -> conv3a (in-place)
I1109 18:09:06.821139 26228 net.cpp:122] Setting up relu3a
I1109 18:09:06.821147 26228 net.cpp:129] Top shape: 3 256 20 30 30 (13824000)
I1109 18:09:06.821151 26228 net.cpp:137] Memory required for data: 1603584012
I1109 18:09:06.821157 26228 layer_factory.hpp:77] Creating layer pool3
I1109 18:09:06.821166 26228 net.cpp:84] Creating Layer pool3
I1109 18:09:06.821171 26228 net.cpp:406] pool3 <- conv3a
I1109 18:09:06.821178 26228 net.cpp:380] pool3 -> pool3
I1109 18:09:06.821218 26228 net.cpp:122] Setting up pool3
I1109 18:09:06.821249 26228 net.cpp:129] Top shape: 3 256 10 15 15 (1728000)
I1109 18:09:06.821254 26228 net.cpp:137] Memory required for data: 1610496012
I1109 18:09:06.821259 26228 layer_factory.hpp:77] Creating layer conv4a
I1109 18:09:06.821270 26228 net.cpp:84] Creating Layer conv4a
I1109 18:09:06.821274 26228 net.cpp:406] conv4a <- pool3
I1109 18:09:06.821283 26228 net.cpp:380] conv4a -> conv4a
I1109 18:09:06.845576 26228 net.cpp:122] Setting up conv4a
I1109 18:09:06.845613 26228 net.cpp:129] Top shape: 3 256 10 15 15 (1728000)
I1109 18:09:06.845618 26228 net.cpp:137] Memory required for data: 1617408012
I1109 18:09:06.845634 26228 layer_factory.hpp:77] Creating layer relu4a
I1109 18:09:06.845648 26228 net.cpp:84] Creating Layer relu4a
I1109 18:09:06.845654 26228 net.cpp:406] relu4a <- conv4a
I1109 18:09:06.845664 26228 net.cpp:367] relu4a -> conv4a (in-place)
I1109 18:09:06.845674 26228 net.cpp:122] Setting up relu4a
I1109 18:09:06.845680 26228 net.cpp:129] Top shape: 3 256 10 15 15 (1728000)
I1109 18:09:06.845685 26228 net.cpp:137] Memory required for data: 1624320012
I1109 18:09:06.845688 26228 layer_factory.hpp:77] Creating layer pool4
I1109 18:09:06.845696 26228 net.cpp:84] Creating Layer pool4
I1109 18:09:06.845701 26228 net.cpp:406] pool4 <- conv4a
I1109 18:09:06.845707 26228 net.cpp:380] pool4 -> pool4
I1109 18:09:06.845726 26228 net.cpp:122] Setting up pool4
I1109 18:09:06.845778 26228 net.cpp:129] Top shape: 3 256 5 8 8 (245760)
I1109 18:09:06.845782 26228 net.cpp:137] Memory required for data: 1625303052
I1109 18:09:06.845787 26228 layer_factory.hpp:77] Creating layer conv5a
I1109 18:09:06.845798 26228 net.cpp:84] Creating Layer conv5a
I1109 18:09:06.845801 26228 net.cpp:406] conv5a <- pool4
I1109 18:09:06.845808 26228 net.cpp:380] conv5a -> conv5a
I1109 18:09:06.871039 26228 net.cpp:122] Setting up conv5a
I1109 18:09:06.871089 26228 net.cpp:129] Top shape: 3 256 5 8 8 (245760)
I1109 18:09:06.871094 26228 net.cpp:137] Memory required for data: 1626286092
I1109 18:09:06.871121 26228 layer_factory.hpp:77] Creating layer relu5a
I1109 18:09:06.871135 26228 net.cpp:84] Creating Layer relu5a
I1109 18:09:06.871141 26228 net.cpp:406] relu5a <- conv5a
I1109 18:09:06.871151 26228 net.cpp:367] relu5a -> conv5a (in-place)
I1109 18:09:06.871165 26228 net.cpp:122] Setting up relu5a
I1109 18:09:06.871171 26228 net.cpp:129] Top shape: 3 256 5 8 8 (245760)
I1109 18:09:06.871176 26228 net.cpp:137] Memory required for data: 1627269132
I1109 18:09:06.871181 26228 layer_factory.hpp:77] Creating layer pool5
I1109 18:09:06.871192 26228 net.cpp:84] Creating Layer pool5
I1109 18:09:06.871227 26228 net.cpp:406] pool5 <- conv5a
I1109 18:09:06.871233 26228 net.cpp:380] pool5 -> pool5
I1109 18:09:06.871273 26228 net.cpp:122] Setting up pool5
I1109 18:09:06.871281 26228 net.cpp:129] Top shape: 3 256 3 4 4 (36864)
I1109 18:09:06.871285 26228 net.cpp:137] Memory required for data: 1627416588
I1109 18:09:06.871321 26228 layer_factory.hpp:77] Creating layer fc6
I1109 18:09:06.871332 26228 net.cpp:84] Creating Layer fc6
I1109 18:09:06.871336 26228 net.cpp:406] fc6 <- pool5
I1109 18:09:06.871343 26228 net.cpp:380] fc6 -> fc6
I1109 18:09:07.202775 26228 net.cpp:122] Setting up fc6
I1109 18:09:07.202816 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.202821 26228 net.cpp:137] Memory required for data: 1627441164
I1109 18:09:07.202838 26228 layer_factory.hpp:77] Creating layer relu6
I1109 18:09:07.202854 26228 net.cpp:84] Creating Layer relu6
I1109 18:09:07.202860 26228 net.cpp:406] relu6 <- fc6
I1109 18:09:07.202870 26228 net.cpp:367] relu6 -> fc6 (in-place)
I1109 18:09:07.202880 26228 net.cpp:122] Setting up relu6
I1109 18:09:07.202886 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.202890 26228 net.cpp:137] Memory required for data: 1627465740
I1109 18:09:07.202895 26228 layer_factory.hpp:77] Creating layer drop6
I1109 18:09:07.202904 26228 net.cpp:84] Creating Layer drop6
I1109 18:09:07.202909 26228 net.cpp:406] drop6 <- fc6
I1109 18:09:07.202916 26228 net.cpp:367] drop6 -> fc6 (in-place)
I1109 18:09:07.202942 26228 net.cpp:122] Setting up drop6
I1109 18:09:07.202976 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.202980 26228 net.cpp:137] Memory required for data: 1627490316
I1109 18:09:07.202986 26228 layer_factory.hpp:77] Creating layer fc7
I1109 18:09:07.202996 26228 net.cpp:84] Creating Layer fc7
I1109 18:09:07.203002 26228 net.cpp:406] fc7 <- fc6
I1109 18:09:07.203011 26228 net.cpp:380] fc7 -> fc7
I1109 18:09:07.258339 26228 net.cpp:122] Setting up fc7
I1109 18:09:07.258375 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.258381 26228 net.cpp:137] Memory required for data: 1627514892
I1109 18:09:07.258399 26228 layer_factory.hpp:77] Creating layer relu7
I1109 18:09:07.258414 26228 net.cpp:84] Creating Layer relu7
I1109 18:09:07.258422 26228 net.cpp:406] relu7 <- fc7
I1109 18:09:07.258432 26228 net.cpp:367] relu7 -> fc7 (in-place)
I1109 18:09:07.258443 26228 net.cpp:122] Setting up relu7
I1109 18:09:07.258450 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.258453 26228 net.cpp:137] Memory required for data: 1627539468
I1109 18:09:07.258458 26228 layer_factory.hpp:77] Creating layer drop7
I1109 18:09:07.258466 26228 net.cpp:84] Creating Layer drop7
I1109 18:09:07.258472 26228 net.cpp:406] drop7 <- fc7
I1109 18:09:07.258479 26228 net.cpp:367] drop7 -> fc7 (in-place)
I1109 18:09:07.258502 26228 net.cpp:122] Setting up drop7
I1109 18:09:07.258518 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.258523 26228 net.cpp:137] Memory required for data: 1627564044
I1109 18:09:07.258528 26228 layer_factory.hpp:77] Creating layer fc8
I1109 18:09:07.258538 26228 net.cpp:84] Creating Layer fc8
I1109 18:09:07.258546 26228 net.cpp:406] fc8 <- fc7
I1109 18:09:07.258554 26228 net.cpp:380] fc8 -> fc8
I1109 18:09:07.262495 26228 net.cpp:122] Setting up fc8
I1109 18:09:07.262527 26228 net.cpp:129] Top shape: 3 101 (303)
I1109 18:09:07.262532 26228 net.cpp:137] Memory required for data: 1627565256
I1109 18:09:07.262549 26228 layer_factory.hpp:77] Creating layer conv1a_p
I1109 18:09:07.262565 26228 net.cpp:84] Creating Layer conv1a_p
I1109 18:09:07.262578 26228 net.cpp:406] conv1a_p <- data_p
I1109 18:09:07.262589 26228 net.cpp:380] conv1a_p -> conv1a_p
I1109 18:09:07.265089 26228 net.cpp:122] Setting up conv1a_p
I1109 18:09:07.265137 26228 net.cpp:129] Top shape: 3 64 40 120 120 (110592000)
I1109 18:09:07.265144 26228 net.cpp:137] Memory required for data: 2069933256
I1109 18:09:07.265168 26228 net.cpp:465] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I1109 18:09:07.265179 26228 net.cpp:465] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I1109 18:09:07.265185 26228 layer_factory.hpp:77] Creating layer relu1a_p
I1109 18:09:07.265200 26228 net.cpp:84] Creating Layer relu1a_p
I1109 18:09:07.265239 26228 net.cpp:406] relu1a_p <- conv1a_p
I1109 18:09:07.265250 26228 net.cpp:367] relu1a_p -> conv1a_p (in-place)
I1109 18:09:07.265265 26228 net.cpp:122] Setting up relu1a_p
I1109 18:09:07.265291 26228 net.cpp:129] Top shape: 3 64 40 120 120 (110592000)
I1109 18:09:07.265296 26228 net.cpp:137] Memory required for data: 2512301256
I1109 18:09:07.265301 26228 layer_factory.hpp:77] Creating layer pool1_p
I1109 18:09:07.265311 26228 net.cpp:84] Creating Layer pool1_p
I1109 18:09:07.265321 26228 net.cpp:406] pool1_p <- conv1a_p
I1109 18:09:07.265328 26228 net.cpp:380] pool1_p -> pool1_p
I1109 18:09:07.265396 26228 net.cpp:122] Setting up pool1_p
I1109 18:09:07.265404 26228 net.cpp:129] Top shape: 3 64 40 60 60 (27648000)
I1109 18:09:07.265409 26228 net.cpp:137] Memory required for data: 2622893256
I1109 18:09:07.265414 26228 layer_factory.hpp:77] Creating layer conv2a_p
I1109 18:09:07.265425 26228 net.cpp:84] Creating Layer conv2a_p
I1109 18:09:07.265455 26228 net.cpp:406] conv2a_p <- pool1_p
I1109 18:09:07.265466 26228 net.cpp:380] conv2a_p -> conv2a_p
I1109 18:09:07.268446 26228 net.cpp:122] Setting up conv2a_p
I1109 18:09:07.268474 26228 net.cpp:129] Top shape: 3 128 40 60 60 (55296000)
I1109 18:09:07.268482 26228 net.cpp:137] Memory required for data: 2844077256
I1109 18:09:07.268491 26228 net.cpp:465] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I1109 18:09:07.268502 26228 net.cpp:465] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I1109 18:09:07.268508 26228 layer_factory.hpp:77] Creating layer relu2a_p
I1109 18:09:07.268519 26228 net.cpp:84] Creating Layer relu2a_p
I1109 18:09:07.268524 26228 net.cpp:406] relu2a_p <- conv2a_p
I1109 18:09:07.268533 26228 net.cpp:367] relu2a_p -> conv2a_p (in-place)
I1109 18:09:07.268543 26228 net.cpp:122] Setting up relu2a_p
I1109 18:09:07.268550 26228 net.cpp:129] Top shape: 3 128 40 60 60 (55296000)
I1109 18:09:07.268555 26228 net.cpp:137] Memory required for data: 3065261256
I1109 18:09:07.268559 26228 layer_factory.hpp:77] Creating layer pool2_p
I1109 18:09:07.268568 26228 net.cpp:84] Creating Layer pool2_p
I1109 18:09:07.268573 26228 net.cpp:406] pool2_p <- conv2a_p
I1109 18:09:07.268580 26228 net.cpp:380] pool2_p -> pool2_p
I1109 18:09:07.268610 26228 net.cpp:122] Setting up pool2_p
I1109 18:09:07.268633 26228 net.cpp:129] Top shape: 3 128 20 30 30 (6912000)
I1109 18:09:07.268638 26228 net.cpp:137] Memory required for data: 3092909256
I1109 18:09:07.268643 26228 layer_factory.hpp:77] Creating layer conv3a_p
I1109 18:09:07.268652 26228 net.cpp:84] Creating Layer conv3a_p
I1109 18:09:07.268657 26228 net.cpp:406] conv3a_p <- pool2_p
I1109 18:09:07.268666 26228 net.cpp:380] conv3a_p -> conv3a_p
I1109 18:09:07.281047 26228 net.cpp:122] Setting up conv3a_p
I1109 18:09:07.281082 26228 net.cpp:129] Top shape: 3 256 20 30 30 (13824000)
I1109 18:09:07.281087 26228 net.cpp:137] Memory required for data: 3148205256
I1109 18:09:07.281100 26228 net.cpp:465] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I1109 18:09:07.281111 26228 net.cpp:465] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I1109 18:09:07.281118 26228 layer_factory.hpp:77] Creating layer relu3a_p
I1109 18:09:07.281132 26228 net.cpp:84] Creating Layer relu3a_p
I1109 18:09:07.281139 26228 net.cpp:406] relu3a_p <- conv3a_p
I1109 18:09:07.281149 26228 net.cpp:367] relu3a_p -> conv3a_p (in-place)
I1109 18:09:07.281160 26228 net.cpp:122] Setting up relu3a_p
I1109 18:09:07.281168 26228 net.cpp:129] Top shape: 3 256 20 30 30 (13824000)
I1109 18:09:07.281173 26228 net.cpp:137] Memory required for data: 3203501256
I1109 18:09:07.281177 26228 layer_factory.hpp:77] Creating layer pool3_p
I1109 18:09:07.281193 26228 net.cpp:84] Creating Layer pool3_p
I1109 18:09:07.281198 26228 net.cpp:406] pool3_p <- conv3a_p
I1109 18:09:07.281205 26228 net.cpp:380] pool3_p -> pool3_p
I1109 18:09:07.281229 26228 net.cpp:122] Setting up pool3_p
I1109 18:09:07.281237 26228 net.cpp:129] Top shape: 3 256 10 15 15 (1728000)
I1109 18:09:07.281241 26228 net.cpp:137] Memory required for data: 3210413256
I1109 18:09:07.281246 26228 layer_factory.hpp:77] Creating layer conv4a_p
I1109 18:09:07.281256 26228 net.cpp:84] Creating Layer conv4a_p
I1109 18:09:07.281306 26228 net.cpp:406] conv4a_p <- pool3_p
I1109 18:09:07.281314 26228 net.cpp:380] conv4a_p -> conv4a_p
I1109 18:09:07.305845 26228 net.cpp:122] Setting up conv4a_p
I1109 18:09:07.305886 26228 net.cpp:129] Top shape: 3 256 10 15 15 (1728000)
I1109 18:09:07.305891 26228 net.cpp:137] Memory required for data: 3217325256
I1109 18:09:07.305903 26228 net.cpp:465] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I1109 18:09:07.305912 26228 net.cpp:465] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I1109 18:09:07.305919 26228 layer_factory.hpp:77] Creating layer relu4a_p
I1109 18:09:07.305945 26228 net.cpp:84] Creating Layer relu4a_p
I1109 18:09:07.305953 26228 net.cpp:406] relu4a_p <- conv4a_p
I1109 18:09:07.305963 26228 net.cpp:367] relu4a_p -> conv4a_p (in-place)
I1109 18:09:07.305975 26228 net.cpp:122] Setting up relu4a_p
I1109 18:09:07.305982 26228 net.cpp:129] Top shape: 3 256 10 15 15 (1728000)
I1109 18:09:07.305986 26228 net.cpp:137] Memory required for data: 3224237256
I1109 18:09:07.305991 26228 layer_factory.hpp:77] Creating layer pool4_p
I1109 18:09:07.306000 26228 net.cpp:84] Creating Layer pool4_p
I1109 18:09:07.306005 26228 net.cpp:406] pool4_p <- conv4a_p
I1109 18:09:07.306011 26228 net.cpp:380] pool4_p -> pool4_p
I1109 18:09:07.306035 26228 net.cpp:122] Setting up pool4_p
I1109 18:09:07.306043 26228 net.cpp:129] Top shape: 3 256 5 8 8 (245760)
I1109 18:09:07.306047 26228 net.cpp:137] Memory required for data: 3225220296
I1109 18:09:07.306051 26228 layer_factory.hpp:77] Creating layer conv5a_p
I1109 18:09:07.306062 26228 net.cpp:84] Creating Layer conv5a_p
I1109 18:09:07.306067 26228 net.cpp:406] conv5a_p <- pool4_p
I1109 18:09:07.306077 26228 net.cpp:380] conv5a_p -> conv5a_p
I1109 18:09:07.330044 26228 net.cpp:122] Setting up conv5a_p
I1109 18:09:07.330082 26228 net.cpp:129] Top shape: 3 256 5 8 8 (245760)
I1109 18:09:07.330088 26228 net.cpp:137] Memory required for data: 3226203336
I1109 18:09:07.330103 26228 net.cpp:465] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I1109 18:09:07.330112 26228 net.cpp:465] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I1109 18:09:07.330118 26228 layer_factory.hpp:77] Creating layer relu5a_p
I1109 18:09:07.330132 26228 net.cpp:84] Creating Layer relu5a_p
I1109 18:09:07.330137 26228 net.cpp:406] relu5a_p <- conv5a_p
I1109 18:09:07.330147 26228 net.cpp:367] relu5a_p -> conv5a_p (in-place)
I1109 18:09:07.330159 26228 net.cpp:122] Setting up relu5a_p
I1109 18:09:07.330166 26228 net.cpp:129] Top shape: 3 256 5 8 8 (245760)
I1109 18:09:07.330171 26228 net.cpp:137] Memory required for data: 3227186376
I1109 18:09:07.330175 26228 layer_factory.hpp:77] Creating layer pool5_p
I1109 18:09:07.330185 26228 net.cpp:84] Creating Layer pool5_p
I1109 18:09:07.330189 26228 net.cpp:406] pool5_p <- conv5a_p
I1109 18:09:07.330196 26228 net.cpp:380] pool5_p -> pool5_p
I1109 18:09:07.330243 26228 net.cpp:122] Setting up pool5_p
I1109 18:09:07.330252 26228 net.cpp:129] Top shape: 3 256 3 4 4 (36864)
I1109 18:09:07.330257 26228 net.cpp:137] Memory required for data: 3227333832
I1109 18:09:07.330261 26228 layer_factory.hpp:77] Creating layer fc6_p
I1109 18:09:07.330272 26228 net.cpp:84] Creating Layer fc6_p
I1109 18:09:07.330277 26228 net.cpp:406] fc6_p <- pool5_p
I1109 18:09:07.330286 26228 net.cpp:380] fc6_p -> fc6_p
I1109 18:09:07.657975 26228 net.cpp:122] Setting up fc6_p
I1109 18:09:07.658015 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.658020 26228 net.cpp:137] Memory required for data: 3227358408
I1109 18:09:07.658031 26228 net.cpp:465] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I1109 18:09:07.658041 26228 net.cpp:465] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I1109 18:09:07.658047 26228 layer_factory.hpp:77] Creating layer relu6_p
I1109 18:09:07.658061 26228 net.cpp:84] Creating Layer relu6_p
I1109 18:09:07.658102 26228 net.cpp:406] relu6_p <- fc6_p
I1109 18:09:07.658112 26228 net.cpp:367] relu6_p -> fc6_p (in-place)
I1109 18:09:07.658140 26228 net.cpp:122] Setting up relu6_p
I1109 18:09:07.658149 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.658152 26228 net.cpp:137] Memory required for data: 3227382984
I1109 18:09:07.658157 26228 layer_factory.hpp:77] Creating layer drop6_p
I1109 18:09:07.658166 26228 net.cpp:84] Creating Layer drop6_p
I1109 18:09:07.658172 26228 net.cpp:406] drop6_p <- fc6_p
I1109 18:09:07.658179 26228 net.cpp:367] drop6_p -> fc6_p (in-place)
I1109 18:09:07.658205 26228 net.cpp:122] Setting up drop6_p
I1109 18:09:07.658212 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.658217 26228 net.cpp:137] Memory required for data: 3227407560
I1109 18:09:07.658221 26228 layer_factory.hpp:77] Creating layer fc7_p
I1109 18:09:07.658231 26228 net.cpp:84] Creating Layer fc7_p
I1109 18:09:07.658237 26228 net.cpp:406] fc7_p <- fc6_p
I1109 18:09:07.658246 26228 net.cpp:380] fc7_p -> fc7_p
I1109 18:09:07.713840 26228 net.cpp:122] Setting up fc7_p
I1109 18:09:07.713872 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.713877 26228 net.cpp:137] Memory required for data: 3227432136
I1109 18:09:07.713891 26228 net.cpp:465] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I1109 18:09:07.713899 26228 net.cpp:465] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I1109 18:09:07.713908 26228 layer_factory.hpp:77] Creating layer relu7_p
I1109 18:09:07.713922 26228 net.cpp:84] Creating Layer relu7_p
I1109 18:09:07.713929 26228 net.cpp:406] relu7_p <- fc7_p
I1109 18:09:07.713953 26228 net.cpp:367] relu7_p -> fc7_p (in-place)
I1109 18:09:07.713965 26228 net.cpp:122] Setting up relu7_p
I1109 18:09:07.713971 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.713976 26228 net.cpp:137] Memory required for data: 3227456712
I1109 18:09:07.713980 26228 layer_factory.hpp:77] Creating layer drop7_p
I1109 18:09:07.713990 26228 net.cpp:84] Creating Layer drop7_p
I1109 18:09:07.713999 26228 net.cpp:406] drop7_p <- fc7_p
I1109 18:09:07.714006 26228 net.cpp:367] drop7_p -> fc7_p (in-place)
I1109 18:09:07.714031 26228 net.cpp:122] Setting up drop7_p
I1109 18:09:07.714040 26228 net.cpp:129] Top shape: 3 2048 (6144)
I1109 18:09:07.714043 26228 net.cpp:137] Memory required for data: 3227481288
I1109 18:09:07.714048 26228 layer_factory.hpp:77] Creating layer fc8_p
I1109 18:09:07.714058 26228 net.cpp:84] Creating Layer fc8_p
I1109 18:09:07.714066 26228 net.cpp:406] fc8_p <- fc7_p
I1109 18:09:07.714073 26228 net.cpp:380] fc8_p -> fc8_p
I1109 18:09:07.717968 26228 net.cpp:122] Setting up fc8_p
I1109 18:09:07.718004 26228 net.cpp:129] Top shape: 3 101 (303)
I1109 18:09:07.718009 26228 net.cpp:137] Memory required for data: 3227482500
I1109 18:09:07.718022 26228 net.cpp:465] Sharing parameters 'fc8_w' owned by layer 'fc8', param index 0
I1109 18:09:07.718030 26228 net.cpp:465] Sharing parameters 'fc8_b' owned by layer 'fc8', param index 1
I1109 18:09:07.718036 26228 layer_factory.hpp:77] Creating layer loss
I1109 18:09:07.718051 26228 net.cpp:84] Creating Layer loss
I1109 18:09:07.718057 26228 net.cpp:406] loss <- fc8
I1109 18:09:07.718065 26228 net.cpp:406] loss <- fc8_p
I1109 18:09:07.718071 26228 net.cpp:406] loss <- sim
I1109 18:09:07.718082 26228 net.cpp:380] loss -> loss
I1109 18:09:07.718194 26228 net.cpp:122] Setting up loss
I1109 18:09:07.718204 26228 net.cpp:129] Top shape: (1)
I1109 18:09:07.718209 26228 net.cpp:132]     with loss weight 1
I1109 18:09:07.718247 26228 net.cpp:137] Memory required for data: 3227482504
I1109 18:09:07.718253 26228 net.cpp:198] loss needs backward computation.
I1109 18:09:07.718260 26228 net.cpp:198] fc8_p needs backward computation.
I1109 18:09:07.718264 26228 net.cpp:198] drop7_p needs backward computation.
I1109 18:09:07.718269 26228 net.cpp:198] relu7_p needs backward computation.
I1109 18:09:07.718274 26228 net.cpp:198] fc7_p needs backward computation.
I1109 18:09:07.718279 26228 net.cpp:198] drop6_p needs backward computation.
I1109 18:09:07.718283 26228 net.cpp:198] relu6_p needs backward computation.
I1109 18:09:07.718288 26228 net.cpp:198] fc6_p needs backward computation.
I1109 18:09:07.718315 26228 net.cpp:198] pool5_p needs backward computation.
I1109 18:09:07.718322 26228 net.cpp:198] relu5a_p needs backward computation.
I1109 18:09:07.718327 26228 net.cpp:198] conv5a_p needs backward computation.
I1109 18:09:07.718333 26228 net.cpp:198] pool4_p needs backward computation.
I1109 18:09:07.718338 26228 net.cpp:198] relu4a_p needs backward computation.
I1109 18:09:07.718343 26228 net.cpp:198] conv4a_p needs backward computation.
I1109 18:09:07.718348 26228 net.cpp:198] pool3_p needs backward computation.
I1109 18:09:07.718353 26228 net.cpp:198] relu3a_p needs backward computation.
I1109 18:09:07.718358 26228 net.cpp:198] conv3a_p needs backward computation.
I1109 18:09:07.718364 26228 net.cpp:198] pool2_p needs backward computation.
I1109 18:09:07.718369 26228 net.cpp:198] relu2a_p needs backward computation.
I1109 18:09:07.718374 26228 net.cpp:198] conv2a_p needs backward computation.
I1109 18:09:07.718379 26228 net.cpp:198] pool1_p needs backward computation.
I1109 18:09:07.718384 26228 net.cpp:198] relu1a_p needs backward computation.
I1109 18:09:07.718389 26228 net.cpp:198] conv1a_p needs backward computation.
I1109 18:09:07.718394 26228 net.cpp:198] fc8 needs backward computation.
I1109 18:09:07.718400 26228 net.cpp:198] drop7 needs backward computation.
I1109 18:09:07.718405 26228 net.cpp:198] relu7 needs backward computation.
I1109 18:09:07.718415 26228 net.cpp:198] fc7 needs backward computation.
I1109 18:09:07.718420 26228 net.cpp:198] drop6 needs backward computation.
I1109 18:09:07.718425 26228 net.cpp:198] relu6 needs backward computation.
I1109 18:09:07.718430 26228 net.cpp:198] fc6 needs backward computation.
I1109 18:09:07.718436 26228 net.cpp:198] pool5 needs backward computation.
I1109 18:09:07.718441 26228 net.cpp:198] relu5a needs backward computation.
I1109 18:09:07.718446 26228 net.cpp:198] conv5a needs backward computation.
I1109 18:09:07.718452 26228 net.cpp:198] pool4 needs backward computation.
I1109 18:09:07.718458 26228 net.cpp:198] relu4a needs backward computation.
I1109 18:09:07.718462 26228 net.cpp:198] conv4a needs backward computation.
I1109 18:09:07.718468 26228 net.cpp:198] pool3 needs backward computation.
I1109 18:09:07.718473 26228 net.cpp:198] relu3a needs backward computation.
I1109 18:09:07.718478 26228 net.cpp:198] conv3a needs backward computation.
I1109 18:09:07.718483 26228 net.cpp:198] pool2 needs backward computation.
I1109 18:09:07.718488 26228 net.cpp:198] relu2a needs backward computation.
I1109 18:09:07.718494 26228 net.cpp:198] conv2a needs backward computation.
I1109 18:09:07.718500 26228 net.cpp:198] pool1 needs backward computation.
I1109 18:09:07.718506 26228 net.cpp:198] relu1a needs backward computation.
I1109 18:09:07.718510 26228 net.cpp:198] conv1a needs backward computation.
I1109 18:09:07.718516 26228 net.cpp:200] slice_pair does not need backward computation.
I1109 18:09:07.718523 26228 net.cpp:200] pair_data does not need backward computation.
I1109 18:09:07.718528 26228 net.cpp:242] This network produces output loss
I1109 18:09:07.742516 26228 net.cpp:255] Network initialization done.
I1109 18:09:07.742717 26228 solver.cpp:56] Solver scaffolding done.
I1109 18:09:07.743429 26228 caffe.cpp:248] Starting Optimization
I1109 18:09:07.743438 26228 solver.cpp:273] Solving C3D-UCF101Net
I1109 18:09:07.743443 26228 solver.cpp:274] Learning Rate Policy: step
I1109 18:09:08.613747 26228 solver.cpp:219] Iteration 0 (0 iter/s, 0.869464s/20 iters), loss = 30.6581
I1109 18:09:08.613901 26228 solver.cpp:238]     Train net output #0: loss = 30.6581 (* 1 = 30.6581 loss)
I1109 18:09:08.613960 26228 sgd_solver.cpp:105] Iteration 0, lr = 0.0001
I1109 18:09:24.609827 26228 solver.cpp:219] Iteration 20 (1.25006 iter/s, 15.9992s/20 iters), loss = 10.3342
I1109 18:09:24.609901 26228 solver.cpp:238]     Train net output #0: loss = 10.3342 (* 1 = 10.3342 loss)
I1109 18:09:24.609915 26228 sgd_solver.cpp:105] Iteration 20, lr = 0.0001
I1109 18:09:40.638221 26228 solver.cpp:219] Iteration 40 (1.24754 iter/s, 16.0315s/20 iters), loss = 2.3391
I1109 18:09:40.638514 26228 solver.cpp:238]     Train net output #0: loss = 2.3391 (* 1 = 2.3391 loss)
I1109 18:09:40.638527 26228 sgd_solver.cpp:105] Iteration 40, lr = 0.0001
I1109 18:09:56.802876 26228 solver.cpp:219] Iteration 60 (1.23705 iter/s, 16.1675s/20 iters), loss = 0.470726
I1109 18:09:56.802953 26228 solver.cpp:238]     Train net output #0: loss = 0.470726 (* 1 = 0.470726 loss)
I1109 18:09:56.802964 26228 sgd_solver.cpp:105] Iteration 60, lr = 0.0001
I1109 18:10:12.825075 26228 solver.cpp:219] Iteration 80 (1.24804 iter/s, 16.0252s/20 iters), loss = 0.506714
I1109 18:10:12.825261 26228 solver.cpp:238]     Train net output #0: loss = 0.506714 (* 1 = 0.506714 loss)
I1109 18:10:12.825281 26228 sgd_solver.cpp:105] Iteration 80, lr = 0.0001
I1109 18:10:27.258514 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_100.caffemodel
I1109 18:10:29.058365 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_100.solverstate
I1109 18:10:30.148613 26228 solver.cpp:219] Iteration 100 (1.1543 iter/s, 17.3265s/20 iters), loss = 0.0956979
I1109 18:10:30.148690 26228 solver.cpp:238]     Train net output #0: loss = 0.0956978 (* 1 = 0.0956978 loss)
I1109 18:10:30.148702 26228 sgd_solver.cpp:105] Iteration 100, lr = 0.0001
I1109 18:10:45.989264 26228 solver.cpp:219] Iteration 120 (1.26236 iter/s, 15.8434s/20 iters), loss = 0.157506
I1109 18:10:45.989420 26228 solver.cpp:238]     Train net output #0: loss = 0.157506 (* 1 = 0.157506 loss)
I1109 18:10:45.989434 26228 sgd_solver.cpp:105] Iteration 120, lr = 0.0001
I1109 18:11:02.000274 26228 solver.cpp:219] Iteration 140 (1.24896 iter/s, 16.0134s/20 iters), loss = 0.105258
I1109 18:11:02.000352 26228 solver.cpp:238]     Train net output #0: loss = 0.105257 (* 1 = 0.105257 loss)
I1109 18:11:02.000363 26228 sgd_solver.cpp:105] Iteration 140, lr = 0.0001
I1109 18:11:18.161406 26228 solver.cpp:219] Iteration 160 (1.23734 iter/s, 16.1638s/20 iters), loss = 0.158596
I1109 18:11:18.161554 26228 solver.cpp:238]     Train net output #0: loss = 0.158596 (* 1 = 0.158596 loss)
I1109 18:11:18.161566 26228 sgd_solver.cpp:105] Iteration 160, lr = 0.0001
I1109 18:11:34.307112 26228 solver.cpp:219] Iteration 180 (1.23853 iter/s, 16.1482s/20 iters), loss = 0.101
I1109 18:11:34.307184 26228 solver.cpp:238]     Train net output #0: loss = 0.100999 (* 1 = 0.100999 loss)
I1109 18:11:34.307196 26228 sgd_solver.cpp:105] Iteration 180, lr = 0.0001
I1109 18:11:49.003978 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_200.caffemodel
I1109 18:11:50.739951 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_200.solverstate
I1109 18:11:51.848482 26228 solver.cpp:219] Iteration 200 (1.13999 iter/s, 17.5441s/20 iters), loss = 0.10966
I1109 18:11:51.848559 26228 solver.cpp:238]     Train net output #0: loss = 0.10966 (* 1 = 0.10966 loss)
I1109 18:11:51.848572 26228 sgd_solver.cpp:105] Iteration 200, lr = 0.0001
I1109 18:12:07.982532 26228 solver.cpp:219] Iteration 220 (1.23943 iter/s, 16.1364s/20 iters), loss = 0.158436
I1109 18:12:07.982614 26228 solver.cpp:238]     Train net output #0: loss = 0.158435 (* 1 = 0.158435 loss)
I1109 18:12:07.982625 26228 sgd_solver.cpp:105] Iteration 220, lr = 0.0001
I1109 18:12:24.085736 26228 solver.cpp:219] Iteration 240 (1.24181 iter/s, 16.1055s/20 iters), loss = 0.140467
I1109 18:12:24.085881 26228 solver.cpp:238]     Train net output #0: loss = 0.140467 (* 1 = 0.140467 loss)
I1109 18:12:24.085896 26228 sgd_solver.cpp:105] Iteration 240, lr = 0.0001
I1109 18:12:40.303217 26228 solver.cpp:219] Iteration 260 (1.23307 iter/s, 16.2197s/20 iters), loss = 0.125016
I1109 18:12:40.303295 26228 solver.cpp:238]     Train net output #0: loss = 0.125016 (* 1 = 0.125016 loss)
I1109 18:12:40.303308 26228 sgd_solver.cpp:105] Iteration 260, lr = 0.0001
I1109 18:12:56.435804 26228 solver.cpp:219] Iteration 280 (1.23956 iter/s, 16.1348s/20 iters), loss = 0.110095
I1109 18:12:56.436007 26228 solver.cpp:238]     Train net output #0: loss = 0.110095 (* 1 = 0.110095 loss)
I1109 18:12:56.436022 26228 sgd_solver.cpp:105] Iteration 280, lr = 0.0001
I1109 18:13:10.976655 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_300.caffemodel
I1109 18:13:12.701093 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_300.solverstate
I1109 18:13:13.806726 26228 solver.cpp:219] Iteration 300 (1.15121 iter/s, 17.3731s/20 iters), loss = 0.103369
I1109 18:13:13.806802 26228 solver.cpp:238]     Train net output #0: loss = 0.103369 (* 1 = 0.103369 loss)
I1109 18:13:13.806815 26228 sgd_solver.cpp:105] Iteration 300, lr = 0.0001
I1109 18:13:29.529382 26228 solver.cpp:219] Iteration 320 (1.27189 iter/s, 15.7247s/20 iters), loss = 0.140004
I1109 18:13:29.529528 26228 solver.cpp:238]     Train net output #0: loss = 0.140004 (* 1 = 0.140004 loss)
I1109 18:13:29.529556 26228 sgd_solver.cpp:105] Iteration 320, lr = 0.0001
I1109 18:13:45.965768 26228 solver.cpp:219] Iteration 340 (1.21667 iter/s, 16.4383s/20 iters), loss = 0.0776261
I1109 18:13:45.965858 26228 solver.cpp:238]     Train net output #0: loss = 0.0776259 (* 1 = 0.0776259 loss)
I1109 18:13:45.965873 26228 sgd_solver.cpp:105] Iteration 340, lr = 0.0001
I1109 18:14:02.570574 26228 solver.cpp:219] Iteration 360 (1.20433 iter/s, 16.6068s/20 iters), loss = 0.18501
I1109 18:14:02.570709 26228 solver.cpp:238]     Train net output #0: loss = 0.18501 (* 1 = 0.18501 loss)
I1109 18:14:02.570721 26228 sgd_solver.cpp:105] Iteration 360, lr = 0.0001
I1109 18:14:18.901688 26228 solver.cpp:219] Iteration 380 (1.22452 iter/s, 16.333s/20 iters), loss = 0.182337
I1109 18:14:18.901753 26228 solver.cpp:238]     Train net output #0: loss = 0.182336 (* 1 = 0.182336 loss)
I1109 18:14:18.901764 26228 sgd_solver.cpp:105] Iteration 380, lr = 0.0001
I1109 18:14:33.112747 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_400.caffemodel
I1109 18:14:34.826378 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_400.solverstate
I1109 18:14:35.881343 26228 solver.cpp:219] Iteration 400 (1.17775 iter/s, 16.9816s/20 iters), loss = 0.122245
I1109 18:14:35.881425 26228 solver.cpp:238]     Train net output #0: loss = 0.122245 (* 1 = 0.122245 loss)
I1109 18:14:35.881438 26228 sgd_solver.cpp:105] Iteration 400, lr = 0.0001
I1109 18:14:51.640316 26228 solver.cpp:219] Iteration 420 (1.26898 iter/s, 15.7607s/20 iters), loss = 0.104514
I1109 18:14:51.640427 26228 solver.cpp:238]     Train net output #0: loss = 0.104514 (* 1 = 0.104514 loss)
I1109 18:14:51.640441 26228 sgd_solver.cpp:105] Iteration 420, lr = 0.0001
I1109 18:15:07.645836 26228 solver.cpp:219] Iteration 440 (1.24946 iter/s, 16.007s/20 iters), loss = 0.14607
I1109 18:15:07.645980 26228 solver.cpp:238]     Train net output #0: loss = 0.14607 (* 1 = 0.14607 loss)
I1109 18:15:07.645992 26228 sgd_solver.cpp:105] Iteration 440, lr = 0.0001
I1109 18:15:23.394887 26228 solver.cpp:219] Iteration 460 (1.26979 iter/s, 15.7506s/20 iters), loss = 0.110281
I1109 18:15:23.394963 26228 solver.cpp:238]     Train net output #0: loss = 0.110281 (* 1 = 0.110281 loss)
I1109 18:15:23.394974 26228 sgd_solver.cpp:105] Iteration 460, lr = 0.0001
I1109 18:15:40.043378 26228 solver.cpp:219] Iteration 480 (1.20119 iter/s, 16.6502s/20 iters), loss = 0.068966
I1109 18:15:40.043514 26228 solver.cpp:238]     Train net output #0: loss = 0.0689659 (* 1 = 0.0689659 loss)
I1109 18:15:40.043525 26228 sgd_solver.cpp:105] Iteration 480, lr = 0.0001
I1109 18:15:55.309731 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_500.caffemodel
I1109 18:15:57.170070 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_500.solverstate
I1109 18:15:58.319576 26228 solver.cpp:219] Iteration 500 (1.09422 iter/s, 18.2779s/20 iters), loss = 0.0707952
I1109 18:15:58.319658 26228 solver.cpp:238]     Train net output #0: loss = 0.0707951 (* 1 = 0.0707951 loss)
I1109 18:15:58.319671 26228 sgd_solver.cpp:105] Iteration 500, lr = 0.0001
I1109 18:16:15.246662 26228 solver.cpp:219] Iteration 520 (1.18143 iter/s, 16.9287s/20 iters), loss = 0.13531
I1109 18:16:15.246886 26228 solver.cpp:238]     Train net output #0: loss = 0.13531 (* 1 = 0.13531 loss)
I1109 18:16:15.246899 26228 sgd_solver.cpp:105] Iteration 520, lr = 0.0001
I1109 18:16:32.299432 26228 solver.cpp:219] Iteration 540 (1.17274 iter/s, 17.0541s/20 iters), loss = 0.129435
I1109 18:16:32.299510 26228 solver.cpp:238]     Train net output #0: loss = 0.129434 (* 1 = 0.129434 loss)
I1109 18:16:32.299520 26228 sgd_solver.cpp:105] Iteration 540, lr = 0.0001
I1109 18:16:48.023828 26228 solver.cpp:219] Iteration 560 (1.2718 iter/s, 15.7258s/20 iters), loss = 0.207059
I1109 18:16:48.023973 26228 solver.cpp:238]     Train net output #0: loss = 0.207059 (* 1 = 0.207059 loss)
I1109 18:16:48.024001 26228 sgd_solver.cpp:105] Iteration 560, lr = 0.0001
I1109 18:17:04.152770 26228 solver.cpp:219] Iteration 580 (1.23991 iter/s, 16.1303s/20 iters), loss = 0.116805
I1109 18:17:04.152844 26228 solver.cpp:238]     Train net output #0: loss = 0.116805 (* 1 = 0.116805 loss)
I1109 18:17:04.152856 26228 sgd_solver.cpp:105] Iteration 580, lr = 0.0001
I1109 18:17:18.673544 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_600.caffemodel
I1109 18:17:20.416558 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_600.solverstate
I1109 18:17:21.496106 26228 solver.cpp:219] Iteration 600 (1.15308 iter/s, 17.3448s/20 iters), loss = 0.0829166
I1109 18:17:21.496188 26228 solver.cpp:238]     Train net output #0: loss = 0.0829164 (* 1 = 0.0829164 loss)
I1109 18:17:21.496199 26228 sgd_solver.cpp:105] Iteration 600, lr = 0.0001
I1109 18:17:37.585978 26228 solver.cpp:219] Iteration 620 (1.24292 iter/s, 16.0912s/20 iters), loss = 0.154414
I1109 18:17:37.586051 26228 solver.cpp:238]     Train net output #0: loss = 0.154413 (* 1 = 0.154413 loss)
I1109 18:17:37.586062 26228 sgd_solver.cpp:105] Iteration 620, lr = 0.0001
I1109 18:17:53.538274 26228 solver.cpp:219] Iteration 640 (1.25364 iter/s, 15.9535s/20 iters), loss = 0.0901025
I1109 18:17:53.538410 26228 solver.cpp:238]     Train net output #0: loss = 0.0901023 (* 1 = 0.0901023 loss)
I1109 18:17:53.538421 26228 sgd_solver.cpp:105] Iteration 640, lr = 0.0001
I1109 18:18:09.492990 26228 solver.cpp:219] Iteration 660 (1.25346 iter/s, 15.9559s/20 iters), loss = 0.117844
I1109 18:18:09.493065 26228 solver.cpp:238]     Train net output #0: loss = 0.117844 (* 1 = 0.117844 loss)
I1109 18:18:09.493077 26228 sgd_solver.cpp:105] Iteration 660, lr = 0.0001
I1109 18:18:25.388809 26228 solver.cpp:219] Iteration 680 (1.2581 iter/s, 15.897s/20 iters), loss = 0.214996
I1109 18:18:25.388948 26228 solver.cpp:238]     Train net output #0: loss = 0.214995 (* 1 = 0.214995 loss)
I1109 18:18:25.388980 26228 sgd_solver.cpp:105] Iteration 680, lr = 0.0001
I1109 18:18:40.319149 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_700.caffemodel
I1109 18:18:41.993990 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_700.solverstate
I1109 18:18:43.047571 26228 solver.cpp:219] Iteration 700 (1.1325 iter/s, 17.66s/20 iters), loss = 0.0978061
I1109 18:18:43.047646 26228 solver.cpp:238]     Train net output #0: loss = 0.0978059 (* 1 = 0.0978059 loss)
I1109 18:18:43.047657 26228 sgd_solver.cpp:105] Iteration 700, lr = 0.0001
I1109 18:18:58.913553 26228 solver.cpp:219] Iteration 720 (1.26047 iter/s, 15.8671s/20 iters), loss = 0.11481
I1109 18:18:58.913717 26228 solver.cpp:238]     Train net output #0: loss = 0.11481 (* 1 = 0.11481 loss)
I1109 18:18:58.913744 26228 sgd_solver.cpp:105] Iteration 720, lr = 0.0001
I1109 18:19:15.505184 26228 solver.cpp:219] Iteration 740 (1.20536 iter/s, 16.5926s/20 iters), loss = 0.123928
I1109 18:19:15.505264 26228 solver.cpp:238]     Train net output #0: loss = 0.123928 (* 1 = 0.123928 loss)
I1109 18:19:15.505275 26228 sgd_solver.cpp:105] Iteration 740, lr = 0.0001
I1109 18:19:31.428964 26228 solver.cpp:219] Iteration 760 (1.2559 iter/s, 15.9248s/20 iters), loss = 0.0920312
I1109 18:19:31.429162 26228 solver.cpp:238]     Train net output #0: loss = 0.0920311 (* 1 = 0.0920311 loss)
I1109 18:19:31.429173 26228 sgd_solver.cpp:105] Iteration 760, lr = 0.0001
I1109 18:19:47.245682 26228 solver.cpp:219] Iteration 780 (1.26441 iter/s, 15.8176s/20 iters), loss = 0.0830937
I1109 18:19:47.245754 26228 solver.cpp:238]     Train net output #0: loss = 0.0830936 (* 1 = 0.0830936 loss)
I1109 18:19:47.245766 26228 sgd_solver.cpp:105] Iteration 780, lr = 0.0001
I1109 18:20:01.667577 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_800.caffemodel
I1109 18:20:03.404057 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_800.solverstate
I1109 18:20:04.484311 26228 solver.cpp:219] Iteration 800 (1.16011 iter/s, 17.2397s/20 iters), loss = 0.132428
I1109 18:20:04.484388 26228 solver.cpp:238]     Train net output #0: loss = 0.132428 (* 1 = 0.132428 loss)
I1109 18:20:04.484400 26228 sgd_solver.cpp:105] Iteration 800, lr = 0.0001
I1109 18:20:20.273533 26228 solver.cpp:219] Iteration 820 (1.26661 iter/s, 15.7902s/20 iters), loss = 0.154343
I1109 18:20:20.273612 26228 solver.cpp:238]     Train net output #0: loss = 0.154343 (* 1 = 0.154343 loss)
I1109 18:20:20.273624 26228 sgd_solver.cpp:105] Iteration 820, lr = 0.0001
I1109 18:20:36.057690 26228 solver.cpp:219] Iteration 840 (1.26702 iter/s, 15.7851s/20 iters), loss = 0.216801
I1109 18:20:36.057806 26228 solver.cpp:238]     Train net output #0: loss = 0.2168 (* 1 = 0.2168 loss)
I1109 18:20:36.057817 26228 sgd_solver.cpp:105] Iteration 840, lr = 0.0001
I1109 18:20:51.623692 26228 solver.cpp:219] Iteration 860 (1.28478 iter/s, 15.5668s/20 iters), loss = 0.16896
I1109 18:20:51.623771 26228 solver.cpp:238]     Train net output #0: loss = 0.168959 (* 1 = 0.168959 loss)
I1109 18:20:51.623783 26228 sgd_solver.cpp:105] Iteration 860, lr = 0.0001
I1109 18:21:07.334466 26228 solver.cpp:219] Iteration 880 (1.27294 iter/s, 15.7116s/20 iters), loss = 0.165105
I1109 18:21:07.334611 26228 solver.cpp:238]     Train net output #0: loss = 0.165105 (* 1 = 0.165105 loss)
I1109 18:21:07.334625 26228 sgd_solver.cpp:105] Iteration 880, lr = 0.0001
I1109 18:21:21.862418 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_900.caffemodel
I1109 18:21:23.619375 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_900.solverstate
I1109 18:21:24.690390 26228 solver.cpp:219] Iteration 900 (1.15229 iter/s, 17.3568s/20 iters), loss = 0.0919894
I1109 18:21:24.690462 26228 solver.cpp:238]     Train net output #0: loss = 0.0919893 (* 1 = 0.0919893 loss)
I1109 18:21:24.690474 26228 sgd_solver.cpp:105] Iteration 900, lr = 0.0001
I1109 18:21:40.541424 26228 solver.cpp:219] Iteration 920 (1.26168 iter/s, 15.8519s/20 iters), loss = 0.101168
I1109 18:21:40.541568 26228 solver.cpp:238]     Train net output #0: loss = 0.101168 (* 1 = 0.101168 loss)
I1109 18:21:40.541577 26228 sgd_solver.cpp:105] Iteration 920, lr = 0.0001
I1109 18:21:56.133095 26228 solver.cpp:219] Iteration 940 (1.28268 iter/s, 15.5924s/20 iters), loss = 0.236337
I1109 18:21:56.133164 26228 solver.cpp:238]     Train net output #0: loss = 0.236337 (* 1 = 0.236337 loss)
I1109 18:21:56.133177 26228 sgd_solver.cpp:105] Iteration 940, lr = 0.0001
I1109 18:22:11.994963 26228 solver.cpp:219] Iteration 960 (1.26082 iter/s, 15.8627s/20 iters), loss = 0.141714
I1109 18:22:11.995105 26228 solver.cpp:238]     Train net output #0: loss = 0.141714 (* 1 = 0.141714 loss)
I1109 18:22:11.995117 26228 sgd_solver.cpp:105] Iteration 960, lr = 0.0001
I1109 18:22:27.830080 26228 solver.cpp:219] Iteration 980 (1.26296 iter/s, 15.8358s/20 iters), loss = 0.103439
I1109 18:22:27.830144 26228 solver.cpp:238]     Train net output #0: loss = 0.103439 (* 1 = 0.103439 loss)
I1109 18:22:27.830157 26228 sgd_solver.cpp:105] Iteration 980, lr = 0.0001
I1109 18:22:42.274869 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1000.caffemodel
I1109 18:22:44.000627 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1000.solverstate
I1109 18:22:45.070847 26228 solver.cpp:219] Iteration 1000 (1.15999 iter/s, 17.2416s/20 iters), loss = 0.134783
I1109 18:22:45.070932 26228 solver.cpp:238]     Train net output #0: loss = 0.134783 (* 1 = 0.134783 loss)
I1109 18:22:45.070945 26228 sgd_solver.cpp:105] Iteration 1000, lr = 0.0001
I1109 18:23:00.969739 26228 solver.cpp:219] Iteration 1020 (1.25789 iter/s, 15.8996s/20 iters), loss = 0.0947494
I1109 18:23:00.969813 26228 solver.cpp:238]     Train net output #0: loss = 0.0947492 (* 1 = 0.0947492 loss)
I1109 18:23:00.969825 26228 sgd_solver.cpp:105] Iteration 1020, lr = 0.0001
I1109 18:23:16.681975 26228 solver.cpp:219] Iteration 1040 (1.27284 iter/s, 15.7129s/20 iters), loss = 0.115422
I1109 18:23:16.682163 26228 solver.cpp:238]     Train net output #0: loss = 0.115421 (* 1 = 0.115421 loss)
I1109 18:23:16.682181 26228 sgd_solver.cpp:105] Iteration 1040, lr = 0.0001
I1109 18:23:32.461711 26228 solver.cpp:219] Iteration 1060 (1.2674 iter/s, 15.7803s/20 iters), loss = 0.136934
I1109 18:23:32.461786 26228 solver.cpp:238]     Train net output #0: loss = 0.136934 (* 1 = 0.136934 loss)
I1109 18:23:32.461798 26228 sgd_solver.cpp:105] Iteration 1060, lr = 0.0001
I1109 18:23:48.178035 26228 solver.cpp:219] Iteration 1080 (1.27251 iter/s, 15.717s/20 iters), loss = 0.157426
I1109 18:23:48.178166 26228 solver.cpp:238]     Train net output #0: loss = 0.157426 (* 1 = 0.157426 loss)
I1109 18:23:48.178179 26228 sgd_solver.cpp:105] Iteration 1080, lr = 0.0001
I1109 18:24:02.438551 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1100.caffemodel
I1109 18:24:04.166023 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1100.solverstate
I1109 18:24:05.225534 26228 solver.cpp:219] Iteration 1100 (1.17315 iter/s, 17.0481s/20 iters), loss = 0.112619
I1109 18:24:05.225608 26228 solver.cpp:238]     Train net output #0: loss = 0.112618 (* 1 = 0.112618 loss)
I1109 18:24:05.225620 26228 sgd_solver.cpp:105] Iteration 1100, lr = 0.0001
I1109 18:24:20.909991 26228 solver.cpp:219] Iteration 1120 (1.2751 iter/s, 15.6851s/20 iters), loss = 0.138582
I1109 18:24:20.910164 26228 solver.cpp:238]     Train net output #0: loss = 0.138582 (* 1 = 0.138582 loss)
I1109 18:24:20.910177 26228 sgd_solver.cpp:105] Iteration 1120, lr = 0.0001
I1109 18:24:36.737915 26228 solver.cpp:219] Iteration 1140 (1.26355 iter/s, 15.8284s/20 iters), loss = 0.112682
I1109 18:24:36.738000 26228 solver.cpp:238]     Train net output #0: loss = 0.112682 (* 1 = 0.112682 loss)
I1109 18:24:36.738013 26228 sgd_solver.cpp:105] Iteration 1140, lr = 0.0001
I1109 18:24:53.604495 26228 solver.cpp:219] Iteration 1160 (1.18574 iter/s, 16.8671s/20 iters), loss = 0.106629
I1109 18:24:53.604635 26228 solver.cpp:238]     Train net output #0: loss = 0.106629 (* 1 = 0.106629 loss)
I1109 18:24:53.604648 26228 sgd_solver.cpp:105] Iteration 1160, lr = 0.0001
I1109 18:25:10.173833 26228 solver.cpp:219] Iteration 1180 (1.20701 iter/s, 16.5698s/20 iters), loss = 0.162717
I1109 18:25:10.173908 26228 solver.cpp:238]     Train net output #0: loss = 0.162717 (* 1 = 0.162717 loss)
I1109 18:25:10.173923 26228 sgd_solver.cpp:105] Iteration 1180, lr = 0.0001
I1109 18:25:25.239140 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1200.caffemodel
I1109 18:25:27.030113 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1200.solverstate
I1109 18:25:28.152542 26228 solver.cpp:219] Iteration 1200 (1.11239 iter/s, 17.9794s/20 iters), loss = 0.0808103
I1109 18:25:28.152619 26228 solver.cpp:238]     Train net output #0: loss = 0.0808102 (* 1 = 0.0808102 loss)
I1109 18:25:28.152633 26228 sgd_solver.cpp:105] Iteration 1200, lr = 0.0001
I1109 18:25:44.146754 26228 solver.cpp:219] Iteration 1220 (1.25041 iter/s, 15.9947s/20 iters), loss = 0.157618
I1109 18:25:44.146836 26228 solver.cpp:238]     Train net output #0: loss = 0.157618 (* 1 = 0.157618 loss)
I1109 18:25:44.146847 26228 sgd_solver.cpp:105] Iteration 1220, lr = 0.0001
I1109 18:25:59.937666 26228 solver.cpp:219] Iteration 1240 (1.26651 iter/s, 15.7914s/20 iters), loss = 0.117585
I1109 18:25:59.937906 26228 solver.cpp:238]     Train net output #0: loss = 0.117585 (* 1 = 0.117585 loss)
I1109 18:25:59.937935 26228 sgd_solver.cpp:105] Iteration 1240, lr = 0.0001
I1109 18:26:15.653496 26228 solver.cpp:219] Iteration 1260 (1.27257 iter/s, 15.7162s/20 iters), loss = 0.146353
I1109 18:26:15.653578 26228 solver.cpp:238]     Train net output #0: loss = 0.146353 (* 1 = 0.146353 loss)
I1109 18:26:15.653591 26228 sgd_solver.cpp:105] Iteration 1260, lr = 0.0001
I1109 18:26:31.321199 26228 solver.cpp:219] Iteration 1280 (1.27647 iter/s, 15.6682s/20 iters), loss = 0.175678
I1109 18:26:31.321332 26228 solver.cpp:238]     Train net output #0: loss = 0.175678 (* 1 = 0.175678 loss)
I1109 18:26:31.321346 26228 sgd_solver.cpp:105] Iteration 1280, lr = 0.0001
I1109 18:26:45.768127 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1300.caffemodel
I1109 18:26:47.601164 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1300.solverstate
I1109 18:26:48.708925 26228 solver.cpp:219] Iteration 1300 (1.1502 iter/s, 17.3882s/20 iters), loss = 0.182298
I1109 18:26:48.708999 26228 solver.cpp:238]     Train net output #0: loss = 0.182297 (* 1 = 0.182297 loss)
I1109 18:26:48.709012 26228 sgd_solver.cpp:105] Iteration 1300, lr = 0.0001
I1109 18:27:04.633503 26228 solver.cpp:219] Iteration 1320 (1.25588 iter/s, 15.9251s/20 iters), loss = 0.155665
I1109 18:27:04.633647 26228 solver.cpp:238]     Train net output #0: loss = 0.155665 (* 1 = 0.155665 loss)
I1109 18:27:04.633662 26228 sgd_solver.cpp:105] Iteration 1320, lr = 0.0001
I1109 18:27:20.348148 26228 solver.cpp:219] Iteration 1340 (1.27267 iter/s, 15.715s/20 iters), loss = 0.123154
I1109 18:27:20.348228 26228 solver.cpp:238]     Train net output #0: loss = 0.123154 (* 1 = 0.123154 loss)
I1109 18:27:20.348240 26228 sgd_solver.cpp:105] Iteration 1340, lr = 0.0001
I1109 18:27:36.401983 26228 solver.cpp:219] Iteration 1360 (1.24577 iter/s, 16.0543s/20 iters), loss = 0.109259
I1109 18:27:36.402127 26228 solver.cpp:238]     Train net output #0: loss = 0.109258 (* 1 = 0.109258 loss)
I1109 18:27:36.402139 26228 sgd_solver.cpp:105] Iteration 1360, lr = 0.0001
I1109 18:27:52.522589 26228 solver.cpp:219] Iteration 1380 (1.24062 iter/s, 16.121s/20 iters), loss = 0.131554
I1109 18:27:52.522665 26228 solver.cpp:238]     Train net output #0: loss = 0.131554 (* 1 = 0.131554 loss)
I1109 18:27:52.522676 26228 sgd_solver.cpp:105] Iteration 1380, lr = 0.0001
I1109 18:28:07.075212 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1400.caffemodel
I1109 18:28:08.790424 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1400.solverstate
I1109 18:28:09.882619 26228 solver.cpp:219] Iteration 1400 (1.15204 iter/s, 17.3605s/20 iters), loss = 0.175838
I1109 18:28:09.882694 26228 solver.cpp:238]     Train net output #0: loss = 0.175838 (* 1 = 0.175838 loss)
I1109 18:28:09.882706 26228 sgd_solver.cpp:105] Iteration 1400, lr = 0.0001
I1109 18:28:25.743078 26228 solver.cpp:219] Iteration 1420 (1.26096 iter/s, 15.8609s/20 iters), loss = 0.170231
I1109 18:28:25.743157 26228 solver.cpp:238]     Train net output #0: loss = 0.170231 (* 1 = 0.170231 loss)
I1109 18:28:25.743170 26228 sgd_solver.cpp:105] Iteration 1420, lr = 0.0001
I1109 18:28:42.255266 26228 solver.cpp:219] Iteration 1440 (1.2112 iter/s, 16.5126s/20 iters), loss = 0.107876
I1109 18:28:42.255425 26228 solver.cpp:238]     Train net output #0: loss = 0.107876 (* 1 = 0.107876 loss)
I1109 18:28:42.255439 26228 sgd_solver.cpp:105] Iteration 1440, lr = 0.0001
I1109 18:28:58.842422 26228 solver.cpp:219] Iteration 1460 (1.20574 iter/s, 16.5873s/20 iters), loss = 0.17942
I1109 18:28:58.842495 26228 solver.cpp:238]     Train net output #0: loss = 0.17942 (* 1 = 0.17942 loss)
I1109 18:28:58.842506 26228 sgd_solver.cpp:105] Iteration 1460, lr = 0.0001
I1109 18:29:15.406829 26228 solver.cpp:219] Iteration 1480 (1.20738 iter/s, 16.5648s/20 iters), loss = 0.135509
I1109 18:29:15.407021 26228 solver.cpp:238]     Train net output #0: loss = 0.135509 (* 1 = 0.135509 loss)
I1109 18:29:15.407035 26228 sgd_solver.cpp:105] Iteration 1480, lr = 0.0001
I1109 18:29:30.643771 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1500.caffemodel
I1109 18:29:32.469416 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1500.solverstate
I1109 18:29:33.624387 26228 solver.cpp:219] Iteration 1500 (1.09782 iter/s, 18.2179s/20 iters), loss = 0.123396
I1109 18:29:33.624466 26228 solver.cpp:238]     Train net output #0: loss = 0.123396 (* 1 = 0.123396 loss)
I1109 18:29:33.624478 26228 sgd_solver.cpp:105] Iteration 1500, lr = 0.0001
I1109 18:29:50.357606 26228 solver.cpp:219] Iteration 1520 (1.1952 iter/s, 16.7336s/20 iters), loss = 0.170256
I1109 18:29:50.357755 26228 solver.cpp:238]     Train net output #0: loss = 0.170256 (* 1 = 0.170256 loss)
I1109 18:29:50.357795 26228 sgd_solver.cpp:105] Iteration 1520, lr = 0.0001
I1109 18:30:06.819511 26228 solver.cpp:219] Iteration 1540 (1.2149 iter/s, 16.4622s/20 iters), loss = 0.120798
I1109 18:30:06.819588 26228 solver.cpp:238]     Train net output #0: loss = 0.120798 (* 1 = 0.120798 loss)
I1109 18:30:06.819602 26228 sgd_solver.cpp:105] Iteration 1540, lr = 0.0001
I1109 18:30:23.326407 26228 solver.cpp:219] Iteration 1560 (1.21159 iter/s, 16.5072s/20 iters), loss = 0.127636
I1109 18:30:23.326531 26228 solver.cpp:238]     Train net output #0: loss = 0.127636 (* 1 = 0.127636 loss)
I1109 18:30:23.326567 26228 sgd_solver.cpp:105] Iteration 1560, lr = 0.0001
I1109 18:30:39.696470 26228 solver.cpp:219] Iteration 1580 (1.22172 iter/s, 16.3704s/20 iters), loss = 0.141321
I1109 18:30:39.696549 26228 solver.cpp:238]     Train net output #0: loss = 0.141321 (* 1 = 0.141321 loss)
I1109 18:30:39.696563 26228 sgd_solver.cpp:105] Iteration 1580, lr = 0.0001
I1109 18:30:53.841958 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1600.caffemodel
I1109 18:30:55.609036 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1600.solverstate
I1109 18:30:56.684296 26228 solver.cpp:219] Iteration 1600 (1.1773 iter/s, 16.9881s/20 iters), loss = 0.0834164
I1109 18:30:56.684370 26228 solver.cpp:238]     Train net output #0: loss = 0.0834163 (* 1 = 0.0834163 loss)
I1109 18:30:56.684381 26228 sgd_solver.cpp:105] Iteration 1600, lr = 0.0001
I1109 18:31:12.232378 26228 solver.cpp:219] Iteration 1620 (1.28631 iter/s, 15.5484s/20 iters), loss = 0.166533
I1109 18:31:12.232450 26228 solver.cpp:238]     Train net output #0: loss = 0.166533 (* 1 = 0.166533 loss)
I1109 18:31:12.232461 26228 sgd_solver.cpp:105] Iteration 1620, lr = 0.0001
I1109 18:31:27.913431 26228 solver.cpp:219] Iteration 1640 (1.2754 iter/s, 15.6814s/20 iters), loss = 0.0943183
I1109 18:31:27.913583 26228 solver.cpp:238]     Train net output #0: loss = 0.0943182 (* 1 = 0.0943182 loss)
I1109 18:31:27.913594 26228 sgd_solver.cpp:105] Iteration 1640, lr = 0.0001
I1109 18:31:43.385463 26228 solver.cpp:219] Iteration 1660 (1.29264 iter/s, 15.4723s/20 iters), loss = 0.145421
I1109 18:31:43.385540 26228 solver.cpp:238]     Train net output #0: loss = 0.145421 (* 1 = 0.145421 loss)
I1109 18:31:43.385550 26228 sgd_solver.cpp:105] Iteration 1660, lr = 0.0001
I1109 18:31:59.006813 26228 solver.cpp:219] Iteration 1680 (1.28027 iter/s, 15.6217s/20 iters), loss = 0.118393
I1109 18:31:59.006944 26228 solver.cpp:238]     Train net output #0: loss = 0.118393 (* 1 = 0.118393 loss)
I1109 18:31:59.006955 26228 sgd_solver.cpp:105] Iteration 1680, lr = 0.0001
I1109 18:32:13.094867 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1700.caffemodel
I1109 18:32:14.878571 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1700.solverstate
I1109 18:32:15.947880 26228 solver.cpp:219] Iteration 1700 (1.18054 iter/s, 16.9413s/20 iters), loss = 0.113504
I1109 18:32:15.947960 26228 solver.cpp:238]     Train net output #0: loss = 0.113503 (* 1 = 0.113503 loss)
I1109 18:32:15.947973 26228 sgd_solver.cpp:105] Iteration 1700, lr = 0.0001
I1109 18:32:31.423857 26228 solver.cpp:219] Iteration 1720 (1.2923 iter/s, 15.4763s/20 iters), loss = 0.144189
I1109 18:32:31.424064 26228 solver.cpp:238]     Train net output #0: loss = 0.144189 (* 1 = 0.144189 loss)
I1109 18:32:31.424132 26228 sgd_solver.cpp:105] Iteration 1720, lr = 0.0001
I1109 18:32:46.864217 26228 solver.cpp:219] Iteration 1740 (1.29529 iter/s, 15.4405s/20 iters), loss = 0.131662
I1109 18:32:46.864290 26228 solver.cpp:238]     Train net output #0: loss = 0.131662 (* 1 = 0.131662 loss)
I1109 18:32:46.864303 26228 sgd_solver.cpp:105] Iteration 1740, lr = 0.0001
I1109 18:33:02.353483 26228 solver.cpp:219] Iteration 1760 (1.29119 iter/s, 15.4895s/20 iters), loss = 0.188399
I1109 18:33:02.353624 26228 solver.cpp:238]     Train net output #0: loss = 0.188399 (* 1 = 0.188399 loss)
I1109 18:33:02.353636 26228 sgd_solver.cpp:105] Iteration 1760, lr = 0.0001
I1109 18:33:17.815963 26228 solver.cpp:219] Iteration 1780 (1.29344 iter/s, 15.4627s/20 iters), loss = 0.114087
I1109 18:33:17.816040 26228 solver.cpp:238]     Train net output #0: loss = 0.114087 (* 1 = 0.114087 loss)
I1109 18:33:17.816052 26228 sgd_solver.cpp:105] Iteration 1780, lr = 0.0001
I1109 18:33:31.927495 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1800.caffemodel
I1109 18:33:33.686628 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1800.solverstate
I1109 18:33:34.761873 26228 solver.cpp:219] Iteration 1800 (1.18021 iter/s, 16.9462s/20 iters), loss = 0.0907761
I1109 18:33:34.761951 26228 solver.cpp:238]     Train net output #0: loss = 0.090776 (* 1 = 0.090776 loss)
I1109 18:33:34.761963 26228 sgd_solver.cpp:105] Iteration 1800, lr = 0.0001
I1109 18:33:50.264925 26228 solver.cpp:219] Iteration 1820 (1.29005 iter/s, 15.5033s/20 iters), loss = 0.129653
I1109 18:33:50.265002 26228 solver.cpp:238]     Train net output #0: loss = 0.129653 (* 1 = 0.129653 loss)
I1109 18:33:50.265013 26228 sgd_solver.cpp:105] Iteration 1820, lr = 0.0001
I1109 18:34:05.805034 26228 solver.cpp:219] Iteration 1840 (1.28697 iter/s, 15.5403s/20 iters), loss = 0.128888
I1109 18:34:05.805171 26228 solver.cpp:238]     Train net output #0: loss = 0.128888 (* 1 = 0.128888 loss)
I1109 18:34:05.805186 26228 sgd_solver.cpp:105] Iteration 1840, lr = 0.0001
I1109 18:34:21.637115 26228 solver.cpp:219] Iteration 1860 (1.26324 iter/s, 15.8323s/20 iters), loss = 0.122639
I1109 18:34:21.637194 26228 solver.cpp:238]     Train net output #0: loss = 0.122639 (* 1 = 0.122639 loss)
I1109 18:34:21.637207 26228 sgd_solver.cpp:105] Iteration 1860, lr = 0.0001
I1109 18:34:37.836854 26228 solver.cpp:219] Iteration 1880 (1.23457 iter/s, 16.2s/20 iters), loss = 0.132434
I1109 18:34:37.837124 26228 solver.cpp:238]     Train net output #0: loss = 0.132434 (* 1 = 0.132434 loss)
I1109 18:34:37.837137 26228 sgd_solver.cpp:105] Iteration 1880, lr = 0.0001
I1109 18:34:52.394212 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_1900.caffemodel
I1109 18:34:54.115653 26228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./c3d_lenet_iter_1900.solverstate
I1109 18:34:55.186774 26228 solver.cpp:219] Iteration 1900 (1.15281 iter/s, 17.3489s/20 iters), loss = 0.19091
I1109 18:34:55.186852 26228 solver.cpp:238]     Train net output #0: loss = 0.190909 (* 1 = 0.190909 loss)
I1109 18:34:55.186866 26228 sgd_solver.cpp:105] Iteration 1900, lr = 0.0001
I1109 18:35:10.848748 26228 solver.cpp:219] Iteration 1920 (1.27696 iter/s, 15.6622s/20 iters), loss = 0.0990468
I1109 18:35:10.848887 26228 solver.cpp:238]     Train net output #0: loss = 0.0990467 (* 1 = 0.0990467 loss)
I1109 18:35:10.848899 26228 sgd_solver.cpp:105] Iteration 1920, lr = 0.0001
I1109 18:35:26.383900 26228 solver.cpp:219] Iteration 1940 (1.28739 iter/s, 15.5353s/20 iters), loss = 0.144734
I1109 18:35:26.383975 26228 solver.cpp:238]     Train net output #0: loss = 0.144734 (* 1 = 0.144734 loss)
I1109 18:35:26.383987 26228 sgd_solver.cpp:105] Iteration 1940, lr = 0.0001
I1109 18:35:41.823993 26228 solver.cpp:219] Iteration 1960 (1.29531 iter/s, 15.4403s/20 iters), loss = 0.094479
I1109 18:35:41.824192 26228 solver.cpp:238]     Train net output #0: loss = 0.0944789 (* 1 = 0.0944789 loss)
I1109 18:35:41.824204 26228 sgd_solver.cpp:105] Iteration 1960, lr = 0.0001
I1109 18:35:57.331645 26228 solver.cpp:219] Iteration 1980 (1.28968 iter/s, 15.5077s/20 iters), loss = 0.127149
I1109 18:35:57.331713 26228 solver.cpp:238]     Train net output #0: loss = 0.127148 (* 1 = 0.127148 loss)
I1109 18:35:57.331724 26228 sgd_solver.cpp:105] Iteration 1980, lr = 0.0001
I1109 18:36:11.410882 26228 solver.cpp:448] Snapshotting to binary proto file ./c3d_lenet_iter_2000.caffemodel
