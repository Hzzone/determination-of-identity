I1119 11:06:20.307341  8943 caffe.cpp:218] Using GPUs 0
I1119 11:06:20.359812  8943 caffe.cpp:223] GPU 0: GeForce GTX 1080 Ti
I1119 11:06:20.934123  8943 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.001
display: 20
max_iter: 10000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3000
snapshot: 100
snapshot_prefix: "/home/hzzone/1tb/id-model/classification/3d/3d_alexnet/3d_classification_alexnet_train"
solver_mode: GPU
device_id: 0
net: "./train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I1119 11:06:20.934412  8943 solver.cpp:87] Creating training net from net file: ./train_val.prototxt
I1119 11:06:20.936210  8943 net.cpp:51] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "../train.txt"
    batch_size: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution3D"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling3D"
  bottom: "conv1"
  top: "pool1"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution3D"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling3D"
  bottom: "conv2"
  top: "pool2"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution3D"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution3D"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution3D"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution3d_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    kernel_depth: 3
    stride: 1
    temporal_stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    temporal_pad: 1
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling3D"
  bottom: "conv5"
  top: "pool5"
  pooling3d_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    kernel_depth: 2
    temporal_stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 70
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1119 11:06:20.936905  8943 layer_factory.hpp:77] Creating layer data
I1119 11:06:20.937126  8943 net.cpp:84] Creating Layer data
I1119 11:06:20.937142  8943 net.cpp:380] data -> data
I1119 11:06:20.937181  8943 net.cpp:380] data -> label
I1119 11:06:20.937203  8943 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: ../train.txt
I1119 11:06:20.937568  8943 hdf5_data_layer.cpp:93] Number of HDF5 files: 146
I1119 11:06:20.977993  8943 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1119 11:06:21.002549  8943 net.cpp:122] Setting up data
I1119 11:06:21.002601  8943 net.cpp:129] Top shape: 2 1 40 120 120 (1152000)
I1119 11:06:21.002611  8943 net.cpp:129] Top shape: 2 (2)
I1119 11:06:21.002619  8943 net.cpp:137] Memory required for data: 4608008
I1119 11:06:21.002634  8943 layer_factory.hpp:77] Creating layer conv1
I1119 11:06:21.002660  8943 net.cpp:84] Creating Layer conv1
I1119 11:06:21.002672  8943 net.cpp:406] conv1 <- data
I1119 11:06:21.002694  8943 net.cpp:380] conv1 -> conv1
I1119 11:06:21.008134  8943 net.cpp:122] Setting up conv1
I1119 11:06:21.008189  8943 net.cpp:129] Top shape: 2 96 40 120 120 (110592000)
I1119 11:06:21.008198  8943 net.cpp:137] Memory required for data: 446976008
I1119 11:06:21.008249  8943 layer_factory.hpp:77] Creating layer relu1
I1119 11:06:21.008297  8943 net.cpp:84] Creating Layer relu1
I1119 11:06:21.008311  8943 net.cpp:406] relu1 <- conv1
I1119 11:06:21.008323  8943 net.cpp:367] relu1 -> conv1 (in-place)
I1119 11:06:21.008342  8943 net.cpp:122] Setting up relu1
I1119 11:06:21.008354  8943 net.cpp:129] Top shape: 2 96 40 120 120 (110592000)
I1119 11:06:21.008361  8943 net.cpp:137] Memory required for data: 889344008
I1119 11:06:21.008368  8943 layer_factory.hpp:77] Creating layer pool1
I1119 11:06:21.008380  8943 net.cpp:84] Creating Layer pool1
I1119 11:06:21.008388  8943 net.cpp:406] pool1 <- conv1
I1119 11:06:21.008399  8943 net.cpp:380] pool1 -> pool1
I1119 11:06:21.008560  8943 net.cpp:122] Setting up pool1
I1119 11:06:21.008571  8943 net.cpp:129] Top shape: 2 96 20 60 60 (13824000)
I1119 11:06:21.008579  8943 net.cpp:137] Memory required for data: 944640008
I1119 11:06:21.008584  8943 layer_factory.hpp:77] Creating layer conv2
I1119 11:06:21.008596  8943 net.cpp:84] Creating Layer conv2
I1119 11:06:21.008602  8943 net.cpp:406] conv2 <- pool1
I1119 11:06:21.008611  8943 net.cpp:380] conv2 -> conv2
I1119 11:06:21.022243  8943 net.cpp:122] Setting up conv2
I1119 11:06:21.022284  8943 net.cpp:129] Top shape: 2 256 20 60 60 (36864000)
I1119 11:06:21.022289  8943 net.cpp:137] Memory required for data: 1092096008
I1119 11:06:21.022348  8943 layer_factory.hpp:77] Creating layer relu2
I1119 11:06:21.022364  8943 net.cpp:84] Creating Layer relu2
I1119 11:06:21.022372  8943 net.cpp:406] relu2 <- conv2
I1119 11:06:21.022382  8943 net.cpp:367] relu2 -> conv2 (in-place)
I1119 11:06:21.022395  8943 net.cpp:122] Setting up relu2
I1119 11:06:21.022403  8943 net.cpp:129] Top shape: 2 256 20 60 60 (36864000)
I1119 11:06:21.022406  8943 net.cpp:137] Memory required for data: 1239552008
I1119 11:06:21.022410  8943 layer_factory.hpp:77] Creating layer pool2
I1119 11:06:21.022418  8943 net.cpp:84] Creating Layer pool2
I1119 11:06:21.022423  8943 net.cpp:406] pool2 <- conv2
I1119 11:06:21.022430  8943 net.cpp:380] pool2 -> pool2
I1119 11:06:21.022472  8943 net.cpp:122] Setting up pool2
I1119 11:06:21.022480  8943 net.cpp:129] Top shape: 2 256 10 30 30 (4608000)
I1119 11:06:21.022483  8943 net.cpp:137] Memory required for data: 1257984008
I1119 11:06:21.022487  8943 layer_factory.hpp:77] Creating layer conv3
I1119 11:06:21.022497  8943 net.cpp:84] Creating Layer conv3
I1119 11:06:21.022502  8943 net.cpp:406] conv3 <- pool2
I1119 11:06:21.022509  8943 net.cpp:380] conv3 -> conv3
I1119 11:06:21.061769  8943 net.cpp:122] Setting up conv3
I1119 11:06:21.061820  8943 net.cpp:129] Top shape: 2 384 10 30 30 (6912000)
I1119 11:06:21.061827  8943 net.cpp:137] Memory required for data: 1285632008
I1119 11:06:21.061858  8943 layer_factory.hpp:77] Creating layer relu3
I1119 11:06:21.061878  8943 net.cpp:84] Creating Layer relu3
I1119 11:06:21.061939  8943 net.cpp:406] relu3 <- conv3
I1119 11:06:21.061965  8943 net.cpp:367] relu3 -> conv3 (in-place)
I1119 11:06:21.061992  8943 net.cpp:122] Setting up relu3
I1119 11:06:21.062011  8943 net.cpp:129] Top shape: 2 384 10 30 30 (6912000)
I1119 11:06:21.062027  8943 net.cpp:137] Memory required for data: 1313280008
I1119 11:06:21.062043  8943 layer_factory.hpp:77] Creating layer conv4
I1119 11:06:21.062065  8943 net.cpp:84] Creating Layer conv4
I1119 11:06:21.062083  8943 net.cpp:406] conv4 <- conv3
I1119 11:06:21.062103  8943 net.cpp:380] conv4 -> conv4
I1119 11:06:21.115053  8943 net.cpp:122] Setting up conv4
I1119 11:06:21.115092  8943 net.cpp:129] Top shape: 2 384 10 30 30 (6912000)
I1119 11:06:21.115097  8943 net.cpp:137] Memory required for data: 1340928008
I1119 11:06:21.115113  8943 layer_factory.hpp:77] Creating layer relu4
I1119 11:06:21.115128  8943 net.cpp:84] Creating Layer relu4
I1119 11:06:21.115134  8943 net.cpp:406] relu4 <- conv4
I1119 11:06:21.115144  8943 net.cpp:367] relu4 -> conv4 (in-place)
I1119 11:06:21.115154  8943 net.cpp:122] Setting up relu4
I1119 11:06:21.115159  8943 net.cpp:129] Top shape: 2 384 10 30 30 (6912000)
I1119 11:06:21.115164  8943 net.cpp:137] Memory required for data: 1368576008
I1119 11:06:21.115170  8943 layer_factory.hpp:77] Creating layer conv5
I1119 11:06:21.115180  8943 net.cpp:84] Creating Layer conv5
I1119 11:06:21.115185  8943 net.cpp:406] conv5 <- conv4
I1119 11:06:21.115192  8943 net.cpp:380] conv5 -> conv5
I1119 11:06:21.167929  8943 net.cpp:122] Setting up conv5
I1119 11:06:21.167968  8943 net.cpp:129] Top shape: 2 384 10 30 30 (6912000)
I1119 11:06:21.167973  8943 net.cpp:137] Memory required for data: 1396224008
I1119 11:06:21.167994  8943 layer_factory.hpp:77] Creating layer relu5
I1119 11:06:21.168010  8943 net.cpp:84] Creating Layer relu5
I1119 11:06:21.168017  8943 net.cpp:406] relu5 <- conv5
I1119 11:06:21.168027  8943 net.cpp:367] relu5 -> conv5 (in-place)
I1119 11:06:21.168040  8943 net.cpp:122] Setting up relu5
I1119 11:06:21.168046  8943 net.cpp:129] Top shape: 2 384 10 30 30 (6912000)
I1119 11:06:21.168051  8943 net.cpp:137] Memory required for data: 1423872008
I1119 11:06:21.168056  8943 layer_factory.hpp:77] Creating layer pool5
I1119 11:06:21.168063  8943 net.cpp:84] Creating Layer pool5
I1119 11:06:21.168068  8943 net.cpp:406] pool5 <- conv5
I1119 11:06:21.168076  8943 net.cpp:380] pool5 -> pool5
I1119 11:06:21.168099  8943 net.cpp:122] Setting up pool5
I1119 11:06:21.168107  8943 net.cpp:129] Top shape: 2 384 5 15 15 (864000)
I1119 11:06:21.168135  8943 net.cpp:137] Memory required for data: 1427328008
I1119 11:06:21.168139  8943 layer_factory.hpp:77] Creating layer fc6
I1119 11:06:21.168149  8943 net.cpp:84] Creating Layer fc6
I1119 11:06:21.168154  8943 net.cpp:406] fc6 <- pool5
I1119 11:06:21.168164  8943 net.cpp:380] fc6 -> fc6
I1119 11:06:26.919981  8943 net.cpp:122] Setting up fc6
I1119 11:06:26.920019  8943 net.cpp:129] Top shape: 2 1024 (2048)
I1119 11:06:26.920024  8943 net.cpp:137] Memory required for data: 1427336200
I1119 11:06:26.920039  8943 layer_factory.hpp:77] Creating layer relu6
I1119 11:06:26.920053  8943 net.cpp:84] Creating Layer relu6
I1119 11:06:26.920059  8943 net.cpp:406] relu6 <- fc6
I1119 11:06:26.920069  8943 net.cpp:367] relu6 -> fc6 (in-place)
I1119 11:06:26.920080  8943 net.cpp:122] Setting up relu6
I1119 11:06:26.920085  8943 net.cpp:129] Top shape: 2 1024 (2048)
I1119 11:06:26.920089  8943 net.cpp:137] Memory required for data: 1427344392
I1119 11:06:26.920092  8943 layer_factory.hpp:77] Creating layer drop6
I1119 11:06:26.920105  8943 net.cpp:84] Creating Layer drop6
I1119 11:06:26.920109  8943 net.cpp:406] drop6 <- fc6
I1119 11:06:26.920115  8943 net.cpp:367] drop6 -> fc6 (in-place)
I1119 11:06:26.920138  8943 net.cpp:122] Setting up drop6
I1119 11:06:26.920143  8943 net.cpp:129] Top shape: 2 1024 (2048)
I1119 11:06:26.920147  8943 net.cpp:137] Memory required for data: 1427352584
I1119 11:06:26.920150  8943 layer_factory.hpp:77] Creating layer fc7
I1119 11:06:26.920159  8943 net.cpp:84] Creating Layer fc7
I1119 11:06:26.920163  8943 net.cpp:406] fc7 <- fc6
I1119 11:06:26.920169  8943 net.cpp:380] fc7 -> fc7
I1119 11:06:26.934805  8943 net.cpp:122] Setting up fc7
I1119 11:06:26.934844  8943 net.cpp:129] Top shape: 2 1024 (2048)
I1119 11:06:26.934849  8943 net.cpp:137] Memory required for data: 1427360776
I1119 11:06:26.934864  8943 layer_factory.hpp:77] Creating layer relu7
I1119 11:06:26.934878  8943 net.cpp:84] Creating Layer relu7
I1119 11:06:26.934885  8943 net.cpp:406] relu7 <- fc7
I1119 11:06:26.934896  8943 net.cpp:367] relu7 -> fc7 (in-place)
I1119 11:06:26.934907  8943 net.cpp:122] Setting up relu7
I1119 11:06:26.934913  8943 net.cpp:129] Top shape: 2 1024 (2048)
I1119 11:06:26.934917  8943 net.cpp:137] Memory required for data: 1427368968
I1119 11:06:26.934921  8943 layer_factory.hpp:77] Creating layer drop7
I1119 11:06:26.934931  8943 net.cpp:84] Creating Layer drop7
I1119 11:06:26.934934  8943 net.cpp:406] drop7 <- fc7
I1119 11:06:26.934942  8943 net.cpp:367] drop7 -> fc7 (in-place)
I1119 11:06:26.934964  8943 net.cpp:122] Setting up drop7
I1119 11:06:26.934970  8943 net.cpp:129] Top shape: 2 1024 (2048)
I1119 11:06:26.934974  8943 net.cpp:137] Memory required for data: 1427377160
I1119 11:06:26.934979  8943 layer_factory.hpp:77] Creating layer fc8
I1119 11:06:26.934988  8943 net.cpp:84] Creating Layer fc8
I1119 11:06:26.934993  8943 net.cpp:406] fc8 <- fc7
I1119 11:06:26.935000  8943 net.cpp:380] fc8 -> fc8
I1119 11:06:26.935958  8943 net.cpp:122] Setting up fc8
I1119 11:06:26.935966  8943 net.cpp:129] Top shape: 2 70 (140)
I1119 11:06:26.935971  8943 net.cpp:137] Memory required for data: 1427377720
I1119 11:06:26.935978  8943 layer_factory.hpp:77] Creating layer loss
I1119 11:06:26.935986  8943 net.cpp:84] Creating Layer loss
I1119 11:06:26.935991  8943 net.cpp:406] loss <- fc8
I1119 11:06:26.935995  8943 net.cpp:406] loss <- label
I1119 11:06:26.936005  8943 net.cpp:380] loss -> loss
I1119 11:06:26.936025  8943 layer_factory.hpp:77] Creating layer loss
I1119 11:06:26.936131  8943 net.cpp:122] Setting up loss
I1119 11:06:26.936139  8943 net.cpp:129] Top shape: (1)
I1119 11:06:26.936144  8943 net.cpp:132]     with loss weight 1
I1119 11:06:26.936195  8943 net.cpp:137] Memory required for data: 1427377724
I1119 11:06:26.936211  8943 net.cpp:198] loss needs backward computation.
I1119 11:06:26.936228  8943 net.cpp:198] fc8 needs backward computation.
I1119 11:06:26.936244  8943 net.cpp:198] drop7 needs backward computation.
I1119 11:06:26.936271  8943 net.cpp:198] relu7 needs backward computation.
I1119 11:06:26.936295  8943 net.cpp:198] fc7 needs backward computation.
I1119 11:06:26.936300  8943 net.cpp:198] drop6 needs backward computation.
I1119 11:06:26.936305  8943 net.cpp:198] relu6 needs backward computation.
I1119 11:06:26.936311  8943 net.cpp:198] fc6 needs backward computation.
I1119 11:06:26.936316  8943 net.cpp:198] pool5 needs backward computation.
I1119 11:06:26.936321  8943 net.cpp:198] relu5 needs backward computation.
I1119 11:06:26.936326  8943 net.cpp:198] conv5 needs backward computation.
I1119 11:06:26.936331  8943 net.cpp:198] relu4 needs backward computation.
I1119 11:06:26.936334  8943 net.cpp:198] conv4 needs backward computation.
I1119 11:06:26.936339  8943 net.cpp:198] relu3 needs backward computation.
I1119 11:06:26.936344  8943 net.cpp:198] conv3 needs backward computation.
I1119 11:06:26.936349  8943 net.cpp:198] pool2 needs backward computation.
I1119 11:06:26.936354  8943 net.cpp:198] relu2 needs backward computation.
I1119 11:06:26.936358  8943 net.cpp:198] conv2 needs backward computation.
I1119 11:06:26.936363  8943 net.cpp:198] pool1 needs backward computation.
I1119 11:06:26.936368  8943 net.cpp:198] relu1 needs backward computation.
I1119 11:06:26.936372  8943 net.cpp:198] conv1 needs backward computation.
I1119 11:06:26.936378  8943 net.cpp:200] data does not need backward computation.
I1119 11:06:26.936383  8943 net.cpp:242] This network produces output loss
I1119 11:06:26.936398  8943 net.cpp:255] Network initialization done.
I1119 11:06:26.936488  8943 solver.cpp:56] Solver scaffolding done.
I1119 11:06:26.937072  8943 caffe.cpp:248] Starting Optimization
I1119 11:06:26.937079  8943 solver.cpp:273] Solving AlexNet
I1119 11:06:26.937083  8943 solver.cpp:274] Learning Rate Policy: step
I1119 11:06:27.740341  8943 solver.cpp:219] Iteration 0 (-4.24808e+21 iter/s, 0.803141s/20 iters), loss = 4.27023
I1119 11:06:27.740399  8943 solver.cpp:238]     Train net output #0: loss = 4.27023 (* 1 = 4.27023 loss)
I1119 11:06:27.740432  8943 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I1119 11:06:41.062657  8943 solver.cpp:219] Iteration 20 (1.50126 iter/s, 13.3221s/20 iters), loss = 4.58634
I1119 11:06:41.062719  8943 solver.cpp:238]     Train net output #0: loss = 4.58634 (* 1 = 4.58634 loss)
I1119 11:06:41.062729  8943 sgd_solver.cpp:105] Iteration 20, lr = 0.001
