I0816 15:27:43.203620  5636 caffe.cpp:218] Using GPUs 0
I0816 15:27:43.241760  5636 caffe.cpp:223] GPU 0: GeForce GTX 970
I0816 15:27:44.607094  5636 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0
snapshot: 5000
snapshot_prefix: "/home/bw/mnist_siamese/mnist_siamese_train"
solver_mode: GPU
device_id: 0
net: "./mnist_siamese_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I0816 15:27:44.607324  5636 solver.cpp:87] Creating training net from net file: ./mnist_siamese_train_test.prototxt
I0816 15:27:44.608992  5636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer pair_data
I0816 15:27:44.609424  5636 net.cpp:51] Initializing net from parameters: 
name: "mnist_siamese_train_test"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "./mnist_siamese_train_leveldb"
    batch_size: 64
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "pool2_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "ip2_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "ip2_p"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip2_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I0816 15:27:44.609724  5636 layer_factory.hpp:77] Creating layer pair_data
I0816 15:27:44.687985  5636 db_leveldb.cpp:18] Opened leveldb ./mnist_siamese_train_leveldb
I0816 15:27:44.688338  5636 net.cpp:84] Creating Layer pair_data
I0816 15:27:44.688381  5636 net.cpp:380] pair_data -> pair_data
I0816 15:27:44.689232  5636 net.cpp:380] pair_data -> sim
I0816 15:27:44.690949  5636 data_layer.cpp:45] output data size: 64,2,28,28
I0816 15:27:44.695272  5636 net.cpp:122] Setting up pair_data
I0816 15:27:44.695318  5636 net.cpp:129] Top shape: 64 2 28 28 (100352)
I0816 15:27:44.695336  5636 net.cpp:129] Top shape: 64 (64)
I0816 15:27:44.695348  5636 net.cpp:137] Memory required for data: 401664
I0816 15:27:44.695369  5636 layer_factory.hpp:77] Creating layer slice_pair
I0816 15:27:44.695392  5636 net.cpp:84] Creating Layer slice_pair
I0816 15:27:44.695410  5636 net.cpp:406] slice_pair <- pair_data
I0816 15:27:44.695435  5636 net.cpp:380] slice_pair -> data
I0816 15:27:44.695463  5636 net.cpp:380] slice_pair -> data_p
I0816 15:27:44.695825  5636 net.cpp:122] Setting up slice_pair
I0816 15:27:44.695950  5636 net.cpp:129] Top shape: 64 1 28 28 (50176)
I0816 15:27:44.695977  5636 net.cpp:129] Top shape: 64 1 28 28 (50176)
I0816 15:27:44.695996  5636 net.cpp:137] Memory required for data: 803072
I0816 15:27:44.696017  5636 layer_factory.hpp:77] Creating layer conv1
I0816 15:27:44.696914  5636 net.cpp:84] Creating Layer conv1
I0816 15:27:44.696969  5636 net.cpp:406] conv1 <- data
I0816 15:27:44.697006  5636 net.cpp:380] conv1 -> conv1
I0816 15:27:46.601730  5636 net.cpp:122] Setting up conv1
I0816 15:27:46.601827  5636 net.cpp:129] Top shape: 64 20 24 24 (737280)
I0816 15:27:46.601845  5636 net.cpp:137] Memory required for data: 3752192
I0816 15:27:46.601883  5636 layer_factory.hpp:77] Creating layer pool1
I0816 15:27:46.601933  5636 net.cpp:84] Creating Layer pool1
I0816 15:27:46.601950  5636 net.cpp:406] pool1 <- conv1
I0816 15:27:46.601966  5636 net.cpp:380] pool1 -> pool1
I0816 15:27:46.602797  5636 net.cpp:122] Setting up pool1
I0816 15:27:46.602823  5636 net.cpp:129] Top shape: 64 20 12 12 (184320)
I0816 15:27:46.602834  5636 net.cpp:137] Memory required for data: 4489472
I0816 15:27:46.602844  5636 layer_factory.hpp:77] Creating layer conv2
I0816 15:27:46.602891  5636 net.cpp:84] Creating Layer conv2
I0816 15:27:46.602908  5636 net.cpp:406] conv2 <- pool1
I0816 15:27:46.602924  5636 net.cpp:380] conv2 -> conv2
I0816 15:27:46.605800  5636 net.cpp:122] Setting up conv2
I0816 15:27:46.605830  5636 net.cpp:129] Top shape: 64 50 8 8 (204800)
I0816 15:27:46.605842  5636 net.cpp:137] Memory required for data: 5308672
I0816 15:27:46.605870  5636 layer_factory.hpp:77] Creating layer pool2
I0816 15:27:46.605903  5636 net.cpp:84] Creating Layer pool2
I0816 15:27:46.605916  5636 net.cpp:406] pool2 <- conv2
I0816 15:27:46.605928  5636 net.cpp:380] pool2 -> pool2
I0816 15:27:46.605990  5636 net.cpp:122] Setting up pool2
I0816 15:27:46.606010  5636 net.cpp:129] Top shape: 64 50 4 4 (51200)
I0816 15:27:46.606020  5636 net.cpp:137] Memory required for data: 5513472
I0816 15:27:46.606029  5636 layer_factory.hpp:77] Creating layer ip1
I0816 15:27:46.606047  5636 net.cpp:84] Creating Layer ip1
I0816 15:27:46.606057  5636 net.cpp:406] ip1 <- pool2
I0816 15:27:46.606071  5636 net.cpp:380] ip1 -> ip1
I0816 15:27:46.610860  5636 net.cpp:122] Setting up ip1
I0816 15:27:46.610901  5636 net.cpp:129] Top shape: 64 500 (32000)
I0816 15:27:46.610913  5636 net.cpp:137] Memory required for data: 5641472
I0816 15:27:46.610929  5636 layer_factory.hpp:77] Creating layer relu1
I0816 15:27:46.610949  5636 net.cpp:84] Creating Layer relu1
I0816 15:27:46.610958  5636 net.cpp:406] relu1 <- ip1
I0816 15:27:46.610971  5636 net.cpp:367] relu1 -> ip1 (in-place)
I0816 15:27:46.611560  5636 net.cpp:122] Setting up relu1
I0816 15:27:46.611582  5636 net.cpp:129] Top shape: 64 500 (32000)
I0816 15:27:46.611593  5636 net.cpp:137] Memory required for data: 5769472
I0816 15:27:46.611603  5636 layer_factory.hpp:77] Creating layer ip2
I0816 15:27:46.611624  5636 net.cpp:84] Creating Layer ip2
I0816 15:27:46.611634  5636 net.cpp:406] ip2 <- ip1
I0816 15:27:46.611649  5636 net.cpp:380] ip2 -> ip2
I0816 15:27:46.612476  5636 net.cpp:122] Setting up ip2
I0816 15:27:46.612502  5636 net.cpp:129] Top shape: 64 10 (640)
I0816 15:27:46.612514  5636 net.cpp:137] Memory required for data: 5772032
I0816 15:27:46.612527  5636 layer_factory.hpp:77] Creating layer feat
I0816 15:27:46.612543  5636 net.cpp:84] Creating Layer feat
I0816 15:27:46.612555  5636 net.cpp:406] feat <- ip2
I0816 15:27:46.612567  5636 net.cpp:380] feat -> feat
I0816 15:27:46.612710  5636 net.cpp:122] Setting up feat
I0816 15:27:46.612728  5636 net.cpp:129] Top shape: 64 2 (128)
I0816 15:27:46.612738  5636 net.cpp:137] Memory required for data: 5772544
I0816 15:27:46.612754  5636 layer_factory.hpp:77] Creating layer conv1_p
I0816 15:27:46.612774  5636 net.cpp:84] Creating Layer conv1_p
I0816 15:27:46.612784  5636 net.cpp:406] conv1_p <- data_p
I0816 15:27:46.612797  5636 net.cpp:380] conv1_p -> conv1_p
I0816 15:27:46.614692  5636 net.cpp:122] Setting up conv1_p
I0816 15:27:46.614717  5636 net.cpp:129] Top shape: 64 20 24 24 (737280)
I0816 15:27:46.614727  5636 net.cpp:137] Memory required for data: 8721664
I0816 15:27:46.614739  5636 net.cpp:465] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I0816 15:27:46.614750  5636 net.cpp:465] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I0816 15:27:46.614759  5636 layer_factory.hpp:77] Creating layer pool1_p
I0816 15:27:46.614778  5636 net.cpp:84] Creating Layer pool1_p
I0816 15:27:46.614789  5636 net.cpp:406] pool1_p <- conv1_p
I0816 15:27:46.614802  5636 net.cpp:380] pool1_p -> pool1_p
I0816 15:27:46.614876  5636 net.cpp:122] Setting up pool1_p
I0816 15:27:46.614893  5636 net.cpp:129] Top shape: 64 20 12 12 (184320)
I0816 15:27:46.614903  5636 net.cpp:137] Memory required for data: 9458944
I0816 15:27:46.614912  5636 layer_factory.hpp:77] Creating layer conv2_p
I0816 15:27:46.614930  5636 net.cpp:84] Creating Layer conv2_p
I0816 15:27:46.614940  5636 net.cpp:406] conv2_p <- pool1_p
I0816 15:27:46.614954  5636 net.cpp:380] conv2_p -> conv2_p
I0816 15:27:46.616902  5636 net.cpp:122] Setting up conv2_p
I0816 15:27:46.616966  5636 net.cpp:129] Top shape: 64 50 8 8 (204800)
I0816 15:27:46.616978  5636 net.cpp:137] Memory required for data: 10278144
I0816 15:27:46.616992  5636 net.cpp:465] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I0816 15:27:46.617004  5636 net.cpp:465] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I0816 15:27:46.617014  5636 layer_factory.hpp:77] Creating layer pool2_p
I0816 15:27:46.617051  5636 net.cpp:84] Creating Layer pool2_p
I0816 15:27:46.617074  5636 net.cpp:406] pool2_p <- conv2_p
I0816 15:27:46.617091  5636 net.cpp:380] pool2_p -> pool2_p
I0816 15:27:46.617161  5636 net.cpp:122] Setting up pool2_p
I0816 15:27:46.617177  5636 net.cpp:129] Top shape: 64 50 4 4 (51200)
I0816 15:27:46.617187  5636 net.cpp:137] Memory required for data: 10482944
I0816 15:27:46.617195  5636 layer_factory.hpp:77] Creating layer ip1_p
I0816 15:27:46.617218  5636 net.cpp:84] Creating Layer ip1_p
I0816 15:27:46.617228  5636 net.cpp:406] ip1_p <- pool2_p
I0816 15:27:46.617241  5636 net.cpp:380] ip1_p -> ip1_p
I0816 15:27:46.621739  5636 net.cpp:122] Setting up ip1_p
I0816 15:27:46.621775  5636 net.cpp:129] Top shape: 64 500 (32000)
I0816 15:27:46.621786  5636 net.cpp:137] Memory required for data: 10610944
I0816 15:27:46.621798  5636 net.cpp:465] Sharing parameters 'ip1_w' owned by layer 'ip1', param index 0
I0816 15:27:46.621810  5636 net.cpp:465] Sharing parameters 'ip1_b' owned by layer 'ip1', param index 1
I0816 15:27:46.621822  5636 layer_factory.hpp:77] Creating layer relu1_p
I0816 15:27:46.621843  5636 net.cpp:84] Creating Layer relu1_p
I0816 15:27:46.621853  5636 net.cpp:406] relu1_p <- ip1_p
I0816 15:27:46.621865  5636 net.cpp:367] relu1_p -> ip1_p (in-place)
I0816 15:27:46.622470  5636 net.cpp:122] Setting up relu1_p
I0816 15:27:46.622496  5636 net.cpp:129] Top shape: 64 500 (32000)
I0816 15:27:46.622506  5636 net.cpp:137] Memory required for data: 10738944
I0816 15:27:46.622516  5636 layer_factory.hpp:77] Creating layer ip2_p
I0816 15:27:46.622539  5636 net.cpp:84] Creating Layer ip2_p
I0816 15:27:46.622555  5636 net.cpp:406] ip2_p <- ip1_p
I0816 15:27:46.622570  5636 net.cpp:380] ip2_p -> ip2_p
I0816 15:27:46.622776  5636 net.cpp:122] Setting up ip2_p
I0816 15:27:46.622798  5636 net.cpp:129] Top shape: 64 10 (640)
I0816 15:27:46.622809  5636 net.cpp:137] Memory required for data: 10741504
I0816 15:27:46.622823  5636 net.cpp:465] Sharing parameters 'ip2_w' owned by layer 'ip2', param index 0
I0816 15:27:46.622835  5636 net.cpp:465] Sharing parameters 'ip2_b' owned by layer 'ip2', param index 1
I0816 15:27:46.622844  5636 layer_factory.hpp:77] Creating layer feat_p
I0816 15:27:46.622859  5636 net.cpp:84] Creating Layer feat_p
I0816 15:27:46.622879  5636 net.cpp:406] feat_p <- ip2_p
I0816 15:27:46.622892  5636 net.cpp:380] feat_p -> feat_p
I0816 15:27:46.623037  5636 net.cpp:122] Setting up feat_p
I0816 15:27:46.623057  5636 net.cpp:129] Top shape: 64 2 (128)
I0816 15:27:46.623067  5636 net.cpp:137] Memory required for data: 10742016
I0816 15:27:46.623077  5636 net.cpp:465] Sharing parameters 'feat_w' owned by layer 'feat', param index 0
I0816 15:27:46.623088  5636 net.cpp:465] Sharing parameters 'feat_b' owned by layer 'feat', param index 1
I0816 15:27:46.623097  5636 layer_factory.hpp:77] Creating layer loss
I0816 15:27:46.623114  5636 net.cpp:84] Creating Layer loss
I0816 15:27:46.623124  5636 net.cpp:406] loss <- feat
I0816 15:27:46.623136  5636 net.cpp:406] loss <- feat_p
I0816 15:27:46.623150  5636 net.cpp:406] loss <- sim
I0816 15:27:46.623168  5636 net.cpp:380] loss -> loss
I0816 15:27:46.623306  5636 net.cpp:122] Setting up loss
I0816 15:27:46.623324  5636 net.cpp:129] Top shape: (1)
I0816 15:27:46.623334  5636 net.cpp:132]     with loss weight 1
I0816 15:27:46.623394  5636 net.cpp:137] Memory required for data: 10742020
I0816 15:27:46.623406  5636 net.cpp:198] loss needs backward computation.
I0816 15:27:46.623416  5636 net.cpp:198] feat_p needs backward computation.
I0816 15:27:46.623425  5636 net.cpp:198] ip2_p needs backward computation.
I0816 15:27:46.623435  5636 net.cpp:198] relu1_p needs backward computation.
I0816 15:27:46.623442  5636 net.cpp:198] ip1_p needs backward computation.
I0816 15:27:46.623451  5636 net.cpp:198] pool2_p needs backward computation.
I0816 15:27:46.623461  5636 net.cpp:198] conv2_p needs backward computation.
I0816 15:27:46.623468  5636 net.cpp:198] pool1_p needs backward computation.
I0816 15:27:46.623477  5636 net.cpp:198] conv1_p needs backward computation.
I0816 15:27:46.623499  5636 net.cpp:198] feat needs backward computation.
I0816 15:27:46.623520  5636 net.cpp:198] ip2 needs backward computation.
I0816 15:27:46.623531  5636 net.cpp:198] relu1 needs backward computation.
I0816 15:27:46.623540  5636 net.cpp:198] ip1 needs backward computation.
I0816 15:27:46.623549  5636 net.cpp:198] pool2 needs backward computation.
I0816 15:27:46.623558  5636 net.cpp:198] conv2 needs backward computation.
I0816 15:27:46.623566  5636 net.cpp:198] pool1 needs backward computation.
I0816 15:27:46.623575  5636 net.cpp:198] conv1 needs backward computation.
I0816 15:27:46.623584  5636 net.cpp:200] slice_pair does not need backward computation.
I0816 15:27:46.623594  5636 net.cpp:200] pair_data does not need backward computation.
I0816 15:27:46.623603  5636 net.cpp:242] This network produces output loss
I0816 15:27:46.624169  5636 net.cpp:255] Network initialization done.
I0816 15:27:46.624907  5636 solver.cpp:172] Creating test net (#0) specified by net file: ./mnist_siamese_train_test.prototxt
I0816 15:27:46.624971  5636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer pair_data
I0816 15:27:46.625185  5636 net.cpp:51] Initializing net from parameters: 
name: "mnist_siamese_train_test"
state {
  phase: TEST
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "./mnist_siamese_test_leveldb"
    batch_size: 100
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "pool2_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "ip2_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "ip2_p"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip2_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I0816 15:27:46.625301  5636 layer_factory.hpp:77] Creating layer pair_data
I0816 15:27:46.661991  5636 db_leveldb.cpp:18] Opened leveldb ./mnist_siamese_test_leveldb
I0816 15:27:46.662202  5636 net.cpp:84] Creating Layer pair_data
I0816 15:27:46.662235  5636 net.cpp:380] pair_data -> pair_data
I0816 15:27:46.662261  5636 net.cpp:380] pair_data -> sim
I0816 15:27:46.662477  5636 data_layer.cpp:45] output data size: 100,2,28,28
I0816 15:27:46.667639  5636 net.cpp:122] Setting up pair_data
I0816 15:27:46.667673  5636 net.cpp:129] Top shape: 100 2 28 28 (156800)
I0816 15:27:46.667687  5636 net.cpp:129] Top shape: 100 (100)
I0816 15:27:46.667697  5636 net.cpp:137] Memory required for data: 627600
I0816 15:27:46.667708  5636 layer_factory.hpp:77] Creating layer slice_pair
I0816 15:27:46.667726  5636 net.cpp:84] Creating Layer slice_pair
I0816 15:27:46.667740  5636 net.cpp:406] slice_pair <- pair_data
I0816 15:27:46.667754  5636 net.cpp:380] slice_pair -> data
I0816 15:27:46.667773  5636 net.cpp:380] slice_pair -> data_p
I0816 15:27:46.667851  5636 net.cpp:122] Setting up slice_pair
I0816 15:27:46.667872  5636 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0816 15:27:46.667884  5636 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0816 15:27:46.667893  5636 net.cpp:137] Memory required for data: 1254800
I0816 15:27:46.667902  5636 layer_factory.hpp:77] Creating layer conv1
I0816 15:27:46.667925  5636 net.cpp:84] Creating Layer conv1
I0816 15:27:46.667937  5636 net.cpp:406] conv1 <- data
I0816 15:27:46.667951  5636 net.cpp:380] conv1 -> conv1
I0816 15:27:46.672650  5636 net.cpp:122] Setting up conv1
I0816 15:27:46.672775  5636 net.cpp:129] Top shape: 100 20 24 24 (1152000)
I0816 15:27:46.672808  5636 net.cpp:137] Memory required for data: 5862800
I0816 15:27:46.672857  5636 layer_factory.hpp:77] Creating layer pool1
I0816 15:27:46.672907  5636 net.cpp:84] Creating Layer pool1
I0816 15:27:46.672931  5636 net.cpp:406] pool1 <- conv1
I0816 15:27:46.672958  5636 net.cpp:380] pool1 -> pool1
I0816 15:27:46.673094  5636 net.cpp:122] Setting up pool1
I0816 15:27:46.673135  5636 net.cpp:129] Top shape: 100 20 12 12 (288000)
I0816 15:27:46.673154  5636 net.cpp:137] Memory required for data: 7014800
I0816 15:27:46.673172  5636 layer_factory.hpp:77] Creating layer conv2
I0816 15:27:46.673243  5636 net.cpp:84] Creating Layer conv2
I0816 15:27:46.673305  5636 net.cpp:406] conv2 <- pool1
I0816 15:27:46.673338  5636 net.cpp:380] conv2 -> conv2
I0816 15:27:46.677471  5636 net.cpp:122] Setting up conv2
I0816 15:27:46.677551  5636 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0816 15:27:46.677575  5636 net.cpp:137] Memory required for data: 8294800
I0816 15:27:46.677609  5636 layer_factory.hpp:77] Creating layer pool2
I0816 15:27:46.677652  5636 net.cpp:84] Creating Layer pool2
I0816 15:27:46.677675  5636 net.cpp:406] pool2 <- conv2
I0816 15:27:46.677707  5636 net.cpp:380] pool2 -> pool2
I0816 15:27:46.677870  5636 net.cpp:122] Setting up pool2
I0816 15:27:46.677909  5636 net.cpp:129] Top shape: 100 50 4 4 (80000)
I0816 15:27:46.677929  5636 net.cpp:137] Memory required for data: 8614800
I0816 15:27:46.677949  5636 layer_factory.hpp:77] Creating layer ip1
I0816 15:27:46.677980  5636 net.cpp:84] Creating Layer ip1
I0816 15:27:46.678000  5636 net.cpp:406] ip1 <- pool2
I0816 15:27:46.678027  5636 net.cpp:380] ip1 -> ip1
I0816 15:27:46.687060  5636 net.cpp:122] Setting up ip1
I0816 15:27:46.687116  5636 net.cpp:129] Top shape: 100 500 (50000)
I0816 15:27:46.687136  5636 net.cpp:137] Memory required for data: 8814800
I0816 15:27:46.687167  5636 layer_factory.hpp:77] Creating layer relu1
I0816 15:27:46.687201  5636 net.cpp:84] Creating Layer relu1
I0816 15:27:46.687219  5636 net.cpp:406] relu1 <- ip1
I0816 15:27:46.687242  5636 net.cpp:367] relu1 -> ip1 (in-place)
I0816 15:27:46.687695  5636 net.cpp:122] Setting up relu1
I0816 15:27:46.687736  5636 net.cpp:129] Top shape: 100 500 (50000)
I0816 15:27:46.687755  5636 net.cpp:137] Memory required for data: 9014800
I0816 15:27:46.687773  5636 layer_factory.hpp:77] Creating layer ip2
I0816 15:27:46.687805  5636 net.cpp:84] Creating Layer ip2
I0816 15:27:46.687824  5636 net.cpp:406] ip2 <- ip1
I0816 15:27:46.687849  5636 net.cpp:380] ip2 -> ip2
I0816 15:27:46.688235  5636 net.cpp:122] Setting up ip2
I0816 15:27:46.688274  5636 net.cpp:129] Top shape: 100 10 (1000)
I0816 15:27:46.688293  5636 net.cpp:137] Memory required for data: 9018800
I0816 15:27:46.688316  5636 layer_factory.hpp:77] Creating layer feat
I0816 15:27:46.688344  5636 net.cpp:84] Creating Layer feat
I0816 15:27:46.688362  5636 net.cpp:406] feat <- ip2
I0816 15:27:46.688386  5636 net.cpp:380] feat -> feat
I0816 15:27:46.688658  5636 net.cpp:122] Setting up feat
I0816 15:27:46.688696  5636 net.cpp:129] Top shape: 100 2 (200)
I0816 15:27:46.688715  5636 net.cpp:137] Memory required for data: 9019600
I0816 15:27:46.688743  5636 layer_factory.hpp:77] Creating layer conv1_p
I0816 15:27:46.688778  5636 net.cpp:84] Creating Layer conv1_p
I0816 15:27:46.688802  5636 net.cpp:406] conv1_p <- data_p
I0816 15:27:46.688827  5636 net.cpp:380] conv1_p -> conv1_p
I0816 15:27:46.691786  5636 net.cpp:122] Setting up conv1_p
I0816 15:27:46.691836  5636 net.cpp:129] Top shape: 100 20 24 24 (1152000)
I0816 15:27:46.691856  5636 net.cpp:137] Memory required for data: 13627600
I0816 15:27:46.691874  5636 net.cpp:465] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I0816 15:27:46.691893  5636 net.cpp:465] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I0816 15:27:46.691910  5636 layer_factory.hpp:77] Creating layer pool1_p
I0816 15:27:46.691934  5636 net.cpp:84] Creating Layer pool1_p
I0816 15:27:46.691956  5636 net.cpp:406] pool1_p <- conv1_p
I0816 15:27:46.691979  5636 net.cpp:380] pool1_p -> pool1_p
I0816 15:27:46.692091  5636 net.cpp:122] Setting up pool1_p
I0816 15:27:46.692126  5636 net.cpp:129] Top shape: 100 20 12 12 (288000)
I0816 15:27:46.692142  5636 net.cpp:137] Memory required for data: 14779600
I0816 15:27:46.692158  5636 layer_factory.hpp:77] Creating layer conv2_p
I0816 15:27:46.692189  5636 net.cpp:84] Creating Layer conv2_p
I0816 15:27:46.692217  5636 net.cpp:406] conv2_p <- pool1_p
I0816 15:27:46.692242  5636 net.cpp:380] conv2_p -> conv2_p
I0816 15:27:46.695433  5636 net.cpp:122] Setting up conv2_p
I0816 15:27:46.695484  5636 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0816 15:27:46.695516  5636 net.cpp:137] Memory required for data: 16059600
I0816 15:27:46.695552  5636 net.cpp:465] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I0816 15:27:46.695575  5636 net.cpp:465] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I0816 15:27:46.695592  5636 layer_factory.hpp:77] Creating layer pool2_p
I0816 15:27:46.695617  5636 net.cpp:84] Creating Layer pool2_p
I0816 15:27:46.695639  5636 net.cpp:406] pool2_p <- conv2_p
I0816 15:27:46.695662  5636 net.cpp:380] pool2_p -> pool2_p
I0816 15:27:46.695775  5636 net.cpp:122] Setting up pool2_p
I0816 15:27:46.695811  5636 net.cpp:129] Top shape: 100 50 4 4 (80000)
I0816 15:27:46.695829  5636 net.cpp:137] Memory required for data: 16379600
I0816 15:27:46.695845  5636 layer_factory.hpp:77] Creating layer ip1_p
I0816 15:27:46.695871  5636 net.cpp:84] Creating Layer ip1_p
I0816 15:27:46.695888  5636 net.cpp:406] ip1_p <- pool2_p
I0816 15:27:46.695911  5636 net.cpp:380] ip1_p -> ip1_p
I0816 15:27:46.703814  5636 net.cpp:122] Setting up ip1_p
I0816 15:27:46.703860  5636 net.cpp:129] Top shape: 100 500 (50000)
I0816 15:27:46.703877  5636 net.cpp:137] Memory required for data: 16579600
I0816 15:27:46.703894  5636 net.cpp:465] Sharing parameters 'ip1_w' owned by layer 'ip1', param index 0
I0816 15:27:46.703912  5636 net.cpp:465] Sharing parameters 'ip1_b' owned by layer 'ip1', param index 1
I0816 15:27:46.703927  5636 layer_factory.hpp:77] Creating layer relu1_p
I0816 15:27:46.703948  5636 net.cpp:84] Creating Layer relu1_p
I0816 15:27:46.703963  5636 net.cpp:406] relu1_p <- ip1_p
I0816 15:27:46.703984  5636 net.cpp:367] relu1_p -> ip1_p (in-place)
I0816 15:27:46.704845  5636 net.cpp:122] Setting up relu1_p
I0816 15:27:46.704886  5636 net.cpp:129] Top shape: 100 500 (50000)
I0816 15:27:46.704903  5636 net.cpp:137] Memory required for data: 16779600
I0816 15:27:46.704919  5636 layer_factory.hpp:77] Creating layer ip2_p
I0816 15:27:46.704949  5636 net.cpp:84] Creating Layer ip2_p
I0816 15:27:46.704972  5636 net.cpp:406] ip2_p <- ip1_p
I0816 15:27:46.704994  5636 net.cpp:380] ip2_p -> ip2_p
I0816 15:27:46.705332  5636 net.cpp:122] Setting up ip2_p
I0816 15:27:46.705368  5636 net.cpp:129] Top shape: 100 10 (1000)
I0816 15:27:46.705384  5636 net.cpp:137] Memory required for data: 16783600
I0816 15:27:46.705406  5636 net.cpp:465] Sharing parameters 'ip2_w' owned by layer 'ip2', param index 0
I0816 15:27:46.705425  5636 net.cpp:465] Sharing parameters 'ip2_b' owned by layer 'ip2', param index 1
I0816 15:27:46.705440  5636 layer_factory.hpp:77] Creating layer feat_p
I0816 15:27:46.705463  5636 net.cpp:84] Creating Layer feat_p
I0816 15:27:46.705483  5636 net.cpp:406] feat_p <- ip2_p
I0816 15:27:46.705507  5636 net.cpp:380] feat_p -> feat_p
I0816 15:27:46.705752  5636 net.cpp:122] Setting up feat_p
I0816 15:27:46.705785  5636 net.cpp:129] Top shape: 100 2 (200)
I0816 15:27:46.705801  5636 net.cpp:137] Memory required for data: 16784400
I0816 15:27:46.705817  5636 net.cpp:465] Sharing parameters 'feat_w' owned by layer 'feat', param index 0
I0816 15:27:46.705834  5636 net.cpp:465] Sharing parameters 'feat_b' owned by layer 'feat', param index 1
I0816 15:27:46.705848  5636 layer_factory.hpp:77] Creating layer loss
I0816 15:27:46.705873  5636 net.cpp:84] Creating Layer loss
I0816 15:27:46.705893  5636 net.cpp:406] loss <- feat
I0816 15:27:46.705910  5636 net.cpp:406] loss <- feat_p
I0816 15:27:46.705927  5636 net.cpp:406] loss <- sim
I0816 15:27:46.705947  5636 net.cpp:380] loss -> loss
I0816 15:27:46.706148  5636 net.cpp:122] Setting up loss
I0816 15:27:46.706179  5636 net.cpp:129] Top shape: (1)
I0816 15:27:46.706195  5636 net.cpp:132]     with loss weight 1
I0816 15:27:46.706223  5636 net.cpp:137] Memory required for data: 16784404
I0816 15:27:46.706238  5636 net.cpp:198] loss needs backward computation.
I0816 15:27:46.706254  5636 net.cpp:198] feat_p needs backward computation.
I0816 15:27:46.706279  5636 net.cpp:198] ip2_p needs backward computation.
I0816 15:27:46.706293  5636 net.cpp:198] relu1_p needs backward computation.
I0816 15:27:46.706321  5636 net.cpp:198] ip1_p needs backward computation.
I0816 15:27:46.706352  5636 net.cpp:198] pool2_p needs backward computation.
I0816 15:27:46.706368  5636 net.cpp:198] conv2_p needs backward computation.
I0816 15:27:46.706382  5636 net.cpp:198] pool1_p needs backward computation.
I0816 15:27:46.706398  5636 net.cpp:198] conv1_p needs backward computation.
I0816 15:27:46.706411  5636 net.cpp:198] feat needs backward computation.
I0816 15:27:46.706426  5636 net.cpp:198] ip2 needs backward computation.
I0816 15:27:46.706441  5636 net.cpp:198] relu1 needs backward computation.
I0816 15:27:46.706455  5636 net.cpp:198] ip1 needs backward computation.
I0816 15:27:46.706470  5636 net.cpp:198] pool2 needs backward computation.
I0816 15:27:46.706483  5636 net.cpp:198] conv2 needs backward computation.
I0816 15:27:46.706497  5636 net.cpp:198] pool1 needs backward computation.
I0816 15:27:46.706511  5636 net.cpp:198] conv1 needs backward computation.
I0816 15:27:46.706526  5636 net.cpp:200] slice_pair does not need backward computation.
I0816 15:27:46.706550  5636 net.cpp:200] pair_data does not need backward computation.
I0816 15:27:46.706565  5636 net.cpp:242] This network produces output loss
I0816 15:27:46.707458  5636 net.cpp:255] Network initialization done.
I0816 15:27:46.707679  5636 solver.cpp:56] Solver scaffolding done.
I0816 15:27:46.708609  5636 caffe.cpp:248] Starting Optimization
I0816 15:27:46.708643  5636 solver.cpp:272] Solving mnist_siamese_train_test
I0816 15:27:46.708658  5636 solver.cpp:273] Learning Rate Policy: inv
I0816 15:27:46.710664  5636 solver.cpp:330] Iteration 0, Testing net (#0)
I0816 15:27:46.733386  5636 blocking_queue.cpp:49] Waiting for data
I0816 15:27:46.943104  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:27:46.945413  5636 solver.cpp:397]     Test net output #0: loss = 0.245166 (* 1 = 0.245166 loss)
I0816 15:27:46.956954  5636 solver.cpp:218] Iteration 0 (0 iter/s, 0.248251s/100 iters), loss = 0.243793
I0816 15:27:46.957029  5636 solver.cpp:237]     Train net output #0: loss = 0.243793 (* 1 = 0.243793 loss)
I0816 15:27:46.957063  5636 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0816 15:27:47.544723  5636 solver.cpp:218] Iteration 100 (170.171 iter/s, 0.587645s/100 iters), loss = 0.111423
I0816 15:27:47.544813  5636 solver.cpp:237]     Train net output #0: loss = 0.111423 (* 1 = 0.111423 loss)
I0816 15:27:47.544836  5636 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0816 15:27:48.121333  5636 solver.cpp:218] Iteration 200 (173.466 iter/s, 0.576481s/100 iters), loss = 0.0317899
I0816 15:27:48.121414  5636 solver.cpp:237]     Train net output #0: loss = 0.0317899 (* 1 = 0.0317899 loss)
I0816 15:27:48.121430  5636 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0816 15:27:48.709048  5636 solver.cpp:218] Iteration 300 (170.184 iter/s, 0.5876s/100 iters), loss = 0.0272907
I0816 15:27:48.709111  5636 solver.cpp:237]     Train net output #0: loss = 0.0272907 (* 1 = 0.0272907 loss)
I0816 15:27:48.709127  5636 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0816 15:27:49.285080  5636 solver.cpp:218] Iteration 400 (173.63 iter/s, 0.575936s/100 iters), loss = 0.0267112
I0816 15:27:49.285159  5636 solver.cpp:237]     Train net output #0: loss = 0.0267112 (* 1 = 0.0267112 loss)
I0816 15:27:49.285176  5636 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0816 15:27:49.859643  5636 solver.cpp:330] Iteration 500, Testing net (#0)
I0816 15:27:50.088130  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:27:50.090198  5636 solver.cpp:397]     Test net output #0: loss = 0.0332359 (* 1 = 0.0332359 loss)
I0816 15:27:50.095944  5636 solver.cpp:218] Iteration 500 (123.344 iter/s, 0.810743s/100 iters), loss = 0.0337852
I0816 15:27:50.096022  5636 solver.cpp:237]     Train net output #0: loss = 0.0337852 (* 1 = 0.0337852 loss)
I0816 15:27:50.096050  5636 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0816 15:27:50.643182  5636 solver.cpp:218] Iteration 600 (182.764 iter/s, 0.547153s/100 iters), loss = 0.021788
I0816 15:27:50.643285  5636 solver.cpp:237]     Train net output #0: loss = 0.021788 (* 1 = 0.021788 loss)
I0816 15:27:50.643314  5636 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0816 15:27:51.204149  5636 solver.cpp:218] Iteration 700 (178.313 iter/s, 0.560811s/100 iters), loss = 0.0254436
I0816 15:27:51.204231  5636 solver.cpp:237]     Train net output #0: loss = 0.0254436 (* 1 = 0.0254436 loss)
I0816 15:27:51.204251  5636 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0816 15:27:51.790246  5636 solver.cpp:218] Iteration 800 (170.668 iter/s, 0.585933s/100 iters), loss = 0.0326603
I0816 15:27:51.790475  5636 solver.cpp:237]     Train net output #0: loss = 0.0326603 (* 1 = 0.0326603 loss)
I0816 15:27:51.790529  5636 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0816 15:27:52.379622  5636 solver.cpp:218] Iteration 900 (169.744 iter/s, 0.589124s/100 iters), loss = 0.0271708
I0816 15:27:52.379712  5636 solver.cpp:237]     Train net output #0: loss = 0.0271708 (* 1 = 0.0271708 loss)
I0816 15:27:52.379729  5636 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0816 15:27:52.573566  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:27:52.951786  5636 solver.cpp:330] Iteration 1000, Testing net (#0)
I0816 15:27:53.168561  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:27:53.176192  5636 solver.cpp:397]     Test net output #0: loss = 0.0294687 (* 1 = 0.0294687 loss)
I0816 15:27:53.181763  5636 solver.cpp:218] Iteration 1000 (124.685 iter/s, 0.802021s/100 iters), loss = 0.0391328
I0816 15:27:53.181820  5636 solver.cpp:237]     Train net output #0: loss = 0.0391328 (* 1 = 0.0391328 loss)
I0816 15:27:53.181840  5636 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I0816 15:27:53.749317  5636 solver.cpp:218] Iteration 1100 (176.221 iter/s, 0.567468s/100 iters), loss = 0.0238242
I0816 15:27:53.749411  5636 solver.cpp:237]     Train net output #0: loss = 0.0238242 (* 1 = 0.0238242 loss)
I0816 15:27:53.749428  5636 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I0816 15:27:54.309001  5636 solver.cpp:218] Iteration 1200 (178.742 iter/s, 0.559466s/100 iters), loss = 0.01567
I0816 15:27:54.309164  5636 solver.cpp:237]     Train net output #0: loss = 0.01567 (* 1 = 0.01567 loss)
I0816 15:27:54.309196  5636 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I0816 15:27:54.873575  5636 solver.cpp:218] Iteration 1300 (177.201 iter/s, 0.56433s/100 iters), loss = 0.0210428
I0816 15:27:54.873725  5636 solver.cpp:237]     Train net output #0: loss = 0.0210428 (* 1 = 0.0210428 loss)
I0816 15:27:54.873759  5636 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I0816 15:27:55.438415  5636 solver.cpp:218] Iteration 1400 (177.113 iter/s, 0.564611s/100 iters), loss = 0.0184932
I0816 15:27:55.438635  5636 solver.cpp:237]     Train net output #0: loss = 0.0184932 (* 1 = 0.0184932 loss)
I0816 15:27:55.438673  5636 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I0816 15:27:56.013537  5636 solver.cpp:330] Iteration 1500, Testing net (#0)
I0816 15:27:56.225504  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:27:56.227489  5636 solver.cpp:397]     Test net output #0: loss = 0.0238704 (* 1 = 0.0238704 loss)
I0816 15:27:56.233302  5636 solver.cpp:218] Iteration 1500 (125.834 iter/s, 0.794699s/100 iters), loss = 0.0217675
I0816 15:27:56.233366  5636 solver.cpp:237]     Train net output #0: loss = 0.0217675 (* 1 = 0.0217675 loss)
I0816 15:27:56.233388  5636 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I0816 15:27:56.791731  5636 solver.cpp:218] Iteration 1600 (179.106 iter/s, 0.558329s/100 iters), loss = 0.0189537
I0816 15:27:56.791848  5636 solver.cpp:237]     Train net output #0: loss = 0.0189537 (* 1 = 0.0189537 loss)
I0816 15:27:56.791883  5636 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I0816 15:27:57.341470  5636 solver.cpp:218] Iteration 1700 (181.953 iter/s, 0.549593s/100 iters), loss = 0.0298981
I0816 15:27:57.341563  5636 solver.cpp:237]     Train net output #0: loss = 0.0298981 (* 1 = 0.0298981 loss)
I0816 15:27:57.341583  5636 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I0816 15:27:57.902544  5636 solver.cpp:218] Iteration 1800 (178.27 iter/s, 0.560946s/100 iters), loss = 0.0123403
I0816 15:27:57.902640  5636 solver.cpp:237]     Train net output #0: loss = 0.0123403 (* 1 = 0.0123403 loss)
I0816 15:27:57.902671  5636 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I0816 15:27:58.282852  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:27:58.440568  5636 solver.cpp:218] Iteration 1900 (185.937 iter/s, 0.537818s/100 iters), loss = 0.0104819
I0816 15:27:58.440750  5636 solver.cpp:237]     Train net output #0: loss = 0.0104819 (* 1 = 0.0104819 loss)
I0816 15:27:58.440791  5636 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I0816 15:27:59.000299  5636 solver.cpp:330] Iteration 2000, Testing net (#0)
I0816 15:27:59.220902  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:27:59.223095  5636 solver.cpp:397]     Test net output #0: loss = 0.0233255 (* 1 = 0.0233255 loss)
I0816 15:27:59.229138  5636 solver.cpp:218] Iteration 2000 (126.84 iter/s, 0.788395s/100 iters), loss = 0.0115434
I0816 15:27:59.229250  5636 solver.cpp:237]     Train net output #0: loss = 0.0115434 (* 1 = 0.0115434 loss)
I0816 15:27:59.229320  5636 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I0816 15:27:59.802966  5636 solver.cpp:218] Iteration 2100 (174.301 iter/s, 0.573721s/100 iters), loss = 0.0241617
I0816 15:27:59.803053  5636 solver.cpp:237]     Train net output #0: loss = 0.0241617 (* 1 = 0.0241617 loss)
I0816 15:27:59.803072  5636 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I0816 15:28:00.387830  5636 solver.cpp:218] Iteration 2200 (171.018 iter/s, 0.584735s/100 iters), loss = 0.0188531
I0816 15:28:00.387890  5636 solver.cpp:237]     Train net output #0: loss = 0.0188531 (* 1 = 0.0188531 loss)
I0816 15:28:00.387905  5636 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I0816 15:28:00.964565  5636 solver.cpp:218] Iteration 2300 (173.42 iter/s, 0.576635s/100 iters), loss = 0.0197755
I0816 15:28:00.964637  5636 solver.cpp:237]     Train net output #0: loss = 0.0197755 (* 1 = 0.0197755 loss)
I0816 15:28:00.964653  5636 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I0816 15:28:01.528569  5636 solver.cpp:218] Iteration 2400 (177.337 iter/s, 0.563899s/100 iters), loss = 0.00991915
I0816 15:28:01.528626  5636 solver.cpp:237]     Train net output #0: loss = 0.00991915 (* 1 = 0.00991915 loss)
I0816 15:28:01.528640  5636 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I0816 15:28:02.101807  5636 solver.cpp:330] Iteration 2500, Testing net (#0)
I0816 15:28:02.311151  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:02.313191  5636 solver.cpp:397]     Test net output #0: loss = 0.0224088 (* 1 = 0.0224088 loss)
I0816 15:28:02.319221  5636 solver.cpp:218] Iteration 2500 (126.493 iter/s, 0.79056s/100 iters), loss = 0.0178629
I0816 15:28:02.319272  5636 solver.cpp:237]     Train net output #0: loss = 0.0178629 (* 1 = 0.0178629 loss)
I0816 15:28:02.319288  5636 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I0816 15:28:02.851081  5636 solver.cpp:218] Iteration 2600 (188.039 iter/s, 0.531803s/100 iters), loss = 0.0373023
I0816 15:28:02.851178  5636 solver.cpp:237]     Train net output #0: loss = 0.0373023 (* 1 = 0.0373023 loss)
I0816 15:28:02.851193  5636 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I0816 15:28:03.431397  5636 solver.cpp:218] Iteration 2700 (172.36 iter/s, 0.58018s/100 iters), loss = 0.0260891
I0816 15:28:03.431455  5636 solver.cpp:237]     Train net output #0: loss = 0.026089 (* 1 = 0.026089 loss)
I0816 15:28:03.431470  5636 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I0816 15:28:04.012904  5636 solver.cpp:218] Iteration 2800 (171.999 iter/s, 0.581398s/100 iters), loss = 0.00872676
I0816 15:28:04.012984  5636 solver.cpp:237]     Train net output #0: loss = 0.00872676 (* 1 = 0.00872676 loss)
I0816 15:28:04.013000  5636 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I0816 15:28:04.060791  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:04.590085  5636 solver.cpp:218] Iteration 2900 (173.29 iter/s, 0.577067s/100 iters), loss = 0.00920072
I0816 15:28:04.590162  5636 solver.cpp:237]     Train net output #0: loss = 0.00920071 (* 1 = 0.00920071 loss)
I0816 15:28:04.590176  5636 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I0816 15:28:05.159282  5636 solver.cpp:330] Iteration 3000, Testing net (#0)
I0816 15:28:05.345419  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:05.351127  5636 solver.cpp:397]     Test net output #0: loss = 0.0209832 (* 1 = 0.0209832 loss)
I0816 15:28:05.355895  5636 solver.cpp:218] Iteration 3000 (130.598 iter/s, 0.765707s/100 iters), loss = 0.0246682
I0816 15:28:05.355940  5636 solver.cpp:237]     Train net output #0: loss = 0.0246682 (* 1 = 0.0246682 loss)
I0816 15:28:05.355959  5636 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I0816 15:28:05.923701  5636 solver.cpp:218] Iteration 3100 (176.132 iter/s, 0.567756s/100 iters), loss = 0.0153913
I0816 15:28:05.923775  5636 solver.cpp:237]     Train net output #0: loss = 0.0153913 (* 1 = 0.0153913 loss)
I0816 15:28:05.923790  5636 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I0816 15:28:06.463567  5636 solver.cpp:218] Iteration 3200 (185.268 iter/s, 0.539757s/100 iters), loss = 0.00479532
I0816 15:28:06.463629  5636 solver.cpp:237]     Train net output #0: loss = 0.00479532 (* 1 = 0.00479532 loss)
I0816 15:28:06.463644  5636 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I0816 15:28:07.031394  5636 solver.cpp:218] Iteration 3300 (176.13 iter/s, 0.567763s/100 iters), loss = 0.0130418
I0816 15:28:07.031471  5636 solver.cpp:237]     Train net output #0: loss = 0.0130418 (* 1 = 0.0130418 loss)
I0816 15:28:07.031486  5636 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I0816 15:28:07.601109  5636 solver.cpp:218] Iteration 3400 (175.55 iter/s, 0.569638s/100 iters), loss = 0.0118066
I0816 15:28:07.601189  5636 solver.cpp:237]     Train net output #0: loss = 0.0118066 (* 1 = 0.0118066 loss)
I0816 15:28:07.601204  5636 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I0816 15:28:08.168143  5636 solver.cpp:330] Iteration 3500, Testing net (#0)
I0816 15:28:08.390938  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:08.393116  5636 solver.cpp:397]     Test net output #0: loss = 0.0195172 (* 1 = 0.0195172 loss)
I0816 15:28:08.399381  5636 solver.cpp:218] Iteration 3500 (125.284 iter/s, 0.798187s/100 iters), loss = 0.0101466
I0816 15:28:08.399497  5636 solver.cpp:237]     Train net output #0: loss = 0.0101467 (* 1 = 0.0101467 loss)
I0816 15:28:08.399550  5636 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I0816 15:28:08.950515  5636 solver.cpp:218] Iteration 3600 (181.484 iter/s, 0.551014s/100 iters), loss = 0.0081062
I0816 15:28:08.950605  5636 solver.cpp:237]     Train net output #0: loss = 0.00810622 (* 1 = 0.00810622 loss)
I0816 15:28:08.950625  5636 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I0816 15:28:09.503402  5636 solver.cpp:218] Iteration 3700 (180.916 iter/s, 0.552743s/100 iters), loss = 0.0143955
I0816 15:28:09.503485  5636 solver.cpp:237]     Train net output #0: loss = 0.0143955 (* 1 = 0.0143955 loss)
I0816 15:28:09.503506  5636 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I0816 15:28:09.761677  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:10.066639  5636 solver.cpp:218] Iteration 3800 (177.573 iter/s, 0.563149s/100 iters), loss = 0.0118016
I0816 15:28:10.066711  5636 solver.cpp:237]     Train net output #0: loss = 0.0118016 (* 1 = 0.0118016 loss)
I0816 15:28:10.066726  5636 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I0816 15:28:10.628638  5636 solver.cpp:218] Iteration 3900 (177.961 iter/s, 0.561922s/100 iters), loss = 0.0142295
I0816 15:28:10.628710  5636 solver.cpp:237]     Train net output #0: loss = 0.0142295 (* 1 = 0.0142295 loss)
I0816 15:28:10.628726  5636 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I0816 15:28:11.181277  5636 solver.cpp:330] Iteration 4000, Testing net (#0)
I0816 15:28:11.393146  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:11.396124  5636 solver.cpp:397]     Test net output #0: loss = 0.019666 (* 1 = 0.019666 loss)
I0816 15:28:11.401744  5636 solver.cpp:218] Iteration 4000 (129.361 iter/s, 0.773029s/100 iters), loss = 0.00706108
I0816 15:28:11.401866  5636 solver.cpp:237]     Train net output #0: loss = 0.00706111 (* 1 = 0.00706111 loss)
I0816 15:28:11.401908  5636 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I0816 15:28:11.958515  5636 solver.cpp:218] Iteration 4100 (179.647 iter/s, 0.556649s/100 iters), loss = 0.00676932
I0816 15:28:11.958603  5636 solver.cpp:237]     Train net output #0: loss = 0.00676935 (* 1 = 0.00676935 loss)
I0816 15:28:11.958623  5636 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I0816 15:28:12.511976  5636 solver.cpp:218] Iteration 4200 (180.723 iter/s, 0.553334s/100 iters), loss = 0.0122414
I0816 15:28:12.512050  5636 solver.cpp:237]     Train net output #0: loss = 0.0122415 (* 1 = 0.0122415 loss)
I0816 15:28:12.512065  5636 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I0816 15:28:13.080955  5636 solver.cpp:218] Iteration 4300 (175.78 iter/s, 0.568894s/100 iters), loss = 0.0040187
I0816 15:28:13.081035  5636 solver.cpp:237]     Train net output #0: loss = 0.00401873 (* 1 = 0.00401873 loss)
I0816 15:28:13.081050  5636 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I0816 15:28:13.647666  5636 solver.cpp:218] Iteration 4400 (176.484 iter/s, 0.566625s/100 iters), loss = 0.0109383
I0816 15:28:13.648238  5636 solver.cpp:237]     Train net output #0: loss = 0.0109383 (* 1 = 0.0109383 loss)
I0816 15:28:13.648314  5636 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I0816 15:28:14.221329  5636 solver.cpp:330] Iteration 4500, Testing net (#0)
I0816 15:28:14.427088  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:14.429710  5636 solver.cpp:397]     Test net output #0: loss = 0.0190161 (* 1 = 0.0190161 loss)
I0816 15:28:14.435024  5636 solver.cpp:218] Iteration 4500 (127.089 iter/s, 0.786852s/100 iters), loss = 0.0165427
I0816 15:28:14.435093  5636 solver.cpp:237]     Train net output #0: loss = 0.0165427 (* 1 = 0.0165427 loss)
I0816 15:28:14.435114  5636 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I0816 15:28:14.971745  5636 solver.cpp:218] Iteration 4600 (186.336 iter/s, 0.536665s/100 iters), loss = 0.00937287
I0816 15:28:14.971825  5636 solver.cpp:237]     Train net output #0: loss = 0.0093729 (* 1 = 0.0093729 loss)
I0816 15:28:14.971846  5636 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I0816 15:28:15.429107  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:15.516652  5636 solver.cpp:218] Iteration 4700 (183.559 iter/s, 0.544784s/100 iters), loss = 0.00736367
I0816 15:28:15.516705  5636 solver.cpp:237]     Train net output #0: loss = 0.00736369 (* 1 = 0.00736369 loss)
I0816 15:28:15.516721  5636 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I0816 15:28:16.076805  5636 solver.cpp:218] Iteration 4800 (178.544 iter/s, 0.560087s/100 iters), loss = 0.00753939
I0816 15:28:16.076900  5636 solver.cpp:237]     Train net output #0: loss = 0.00753941 (* 1 = 0.00753941 loss)
I0816 15:28:16.076915  5636 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I0816 15:28:16.594411  5636 solver.cpp:218] Iteration 4900 (193.23 iter/s, 0.517517s/100 iters), loss = 0.000782669
I0816 15:28:16.594468  5636 solver.cpp:237]     Train net output #0: loss = 0.000782687 (* 1 = 0.000782687 loss)
I0816 15:28:16.594483  5636 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I0816 15:28:17.151859  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_5000.caffemodel
I0816 15:28:17.169037  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_5000.solverstate
I0816 15:28:17.172055  5636 solver.cpp:330] Iteration 5000, Testing net (#0)
I0816 15:28:17.374692  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:17.379667  5636 solver.cpp:397]     Test net output #0: loss = 0.0194767 (* 1 = 0.0194767 loss)
I0816 15:28:17.384856  5636 solver.cpp:218] Iteration 5000 (126.519 iter/s, 0.790393s/100 iters), loss = 0.00694103
I0816 15:28:17.384902  5636 solver.cpp:237]     Train net output #0: loss = 0.00694105 (* 1 = 0.00694105 loss)
I0816 15:28:17.384920  5636 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I0816 15:28:17.941035  5636 solver.cpp:218] Iteration 5100 (179.814 iter/s, 0.556129s/100 iters), loss = 0.00173031
I0816 15:28:17.941124  5636 solver.cpp:237]     Train net output #0: loss = 0.00173033 (* 1 = 0.00173033 loss)
I0816 15:28:17.941140  5636 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I0816 15:28:18.494693  5636 solver.cpp:218] Iteration 5200 (180.657 iter/s, 0.553535s/100 iters), loss = 0.0108351
I0816 15:28:18.494762  5636 solver.cpp:237]     Train net output #0: loss = 0.0108352 (* 1 = 0.0108352 loss)
I0816 15:28:18.494776  5636 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I0816 15:28:19.058707  5636 solver.cpp:218] Iteration 5300 (177.329 iter/s, 0.563922s/100 iters), loss = 0.0055228
I0816 15:28:19.058796  5636 solver.cpp:237]     Train net output #0: loss = 0.00552282 (* 1 = 0.00552282 loss)
I0816 15:28:19.058812  5636 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I0816 15:28:19.623613  5636 solver.cpp:218] Iteration 5400 (177.046 iter/s, 0.564826s/100 iters), loss = 0.0211032
I0816 15:28:19.623672  5636 solver.cpp:237]     Train net output #0: loss = 0.0211032 (* 1 = 0.0211032 loss)
I0816 15:28:19.623713  5636 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I0816 15:28:20.185468  5636 solver.cpp:330] Iteration 5500, Testing net (#0)
I0816 15:28:20.390033  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:20.395927  5636 solver.cpp:397]     Test net output #0: loss = 0.0192507 (* 1 = 0.0192507 loss)
I0816 15:28:20.400866  5636 solver.cpp:218] Iteration 5500 (128.667 iter/s, 0.777198s/100 iters), loss = 0.0104074
I0816 15:28:20.400919  5636 solver.cpp:237]     Train net output #0: loss = 0.0104074 (* 1 = 0.0104074 loss)
I0816 15:28:20.400938  5636 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I0816 15:28:20.944802  5636 solver.cpp:218] Iteration 5600 (183.865 iter/s, 0.543876s/100 iters), loss = 0.00991441
I0816 15:28:20.944893  5636 solver.cpp:237]     Train net output #0: loss = 0.00991444 (* 1 = 0.00991444 loss)
I0816 15:28:20.944911  5636 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I0816 15:28:21.060693  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:21.502003  5636 solver.cpp:218] Iteration 5700 (179.511 iter/s, 0.557069s/100 iters), loss = 0.00709173
I0816 15:28:21.502070  5636 solver.cpp:237]     Train net output #0: loss = 0.00709176 (* 1 = 0.00709176 loss)
I0816 15:28:21.502085  5636 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I0816 15:28:22.092420  5636 solver.cpp:218] Iteration 5800 (169.403 iter/s, 0.590308s/100 iters), loss = 0.00157684
I0816 15:28:22.092509  5636 solver.cpp:237]     Train net output #0: loss = 0.00157687 (* 1 = 0.00157687 loss)
I0816 15:28:22.092525  5636 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I0816 15:28:22.673324  5636 solver.cpp:218] Iteration 5900 (172.182 iter/s, 0.58078s/100 iters), loss = 0.0039264
I0816 15:28:22.673405  5636 solver.cpp:237]     Train net output #0: loss = 0.00392643 (* 1 = 0.00392643 loss)
I0816 15:28:22.673420  5636 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I0816 15:28:23.246233  5636 solver.cpp:330] Iteration 6000, Testing net (#0)
I0816 15:28:23.463924  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:23.471474  5636 solver.cpp:397]     Test net output #0: loss = 0.0177486 (* 1 = 0.0177486 loss)
I0816 15:28:23.477205  5636 solver.cpp:218] Iteration 6000 (124.413 iter/s, 0.803773s/100 iters), loss = 0.00871671
I0816 15:28:23.477254  5636 solver.cpp:237]     Train net output #0: loss = 0.00871674 (* 1 = 0.00871674 loss)
I0816 15:28:23.477272  5636 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I0816 15:28:24.066431  5636 solver.cpp:218] Iteration 6100 (169.738 iter/s, 0.589142s/100 iters), loss = 0.00726175
I0816 15:28:24.066529  5636 solver.cpp:237]     Train net output #0: loss = 0.00726178 (* 1 = 0.00726178 loss)
I0816 15:28:24.066545  5636 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I0816 15:28:24.656973  5636 solver.cpp:218] Iteration 6200 (169.377 iter/s, 0.590399s/100 iters), loss = 0.0091992
I0816 15:28:24.657037  5636 solver.cpp:237]     Train net output #0: loss = 0.00919923 (* 1 = 0.00919923 loss)
I0816 15:28:24.657052  5636 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I0816 15:28:25.239920  5636 solver.cpp:218] Iteration 6300 (171.573 iter/s, 0.582842s/100 iters), loss = 0.00302823
I0816 15:28:25.239997  5636 solver.cpp:237]     Train net output #0: loss = 0.00302826 (* 1 = 0.00302826 loss)
I0816 15:28:25.240017  5636 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I0816 15:28:25.818204  5636 solver.cpp:218] Iteration 6400 (172.961 iter/s, 0.578164s/100 iters), loss = 0.0181716
I0816 15:28:25.818277  5636 solver.cpp:237]     Train net output #0: loss = 0.0181716 (* 1 = 0.0181716 loss)
I0816 15:28:25.818292  5636 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I0816 15:28:26.382858  5636 solver.cpp:330] Iteration 6500, Testing net (#0)
I0816 15:28:26.579835  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:26.587505  5636 solver.cpp:397]     Test net output #0: loss = 0.0189259 (* 1 = 0.0189259 loss)
I0816 15:28:26.593185  5636 solver.cpp:218] Iteration 6500 (129.052 iter/s, 0.774881s/100 iters), loss = 0.0118572
I0816 15:28:26.593252  5636 solver.cpp:237]     Train net output #0: loss = 0.0118572 (* 1 = 0.0118572 loss)
I0816 15:28:26.593271  5636 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I0816 15:28:26.932286  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:27.176949  5636 solver.cpp:218] Iteration 6600 (171.334 iter/s, 0.583657s/100 iters), loss = 0.00910226
I0816 15:28:27.177016  5636 solver.cpp:237]     Train net output #0: loss = 0.00910228 (* 1 = 0.00910228 loss)
I0816 15:28:27.177031  5636 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I0816 15:28:27.760843  5636 solver.cpp:218] Iteration 6700 (171.294 iter/s, 0.583791s/100 iters), loss = 0.0188228
I0816 15:28:27.760921  5636 solver.cpp:237]     Train net output #0: loss = 0.0188228 (* 1 = 0.0188228 loss)
I0816 15:28:27.760936  5636 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I0816 15:28:28.343767  5636 solver.cpp:218] Iteration 6800 (171.596 iter/s, 0.582765s/100 iters), loss = 0.0305597
I0816 15:28:28.343855  5636 solver.cpp:237]     Train net output #0: loss = 0.0305597 (* 1 = 0.0305597 loss)
I0816 15:28:28.343871  5636 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I0816 15:28:28.932760  5636 solver.cpp:218] Iteration 6900 (169.819 iter/s, 0.588863s/100 iters), loss = 0.0136404
I0816 15:28:28.932837  5636 solver.cpp:237]     Train net output #0: loss = 0.0136404 (* 1 = 0.0136404 loss)
I0816 15:28:28.932852  5636 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I0816 15:28:29.485121  5636 solver.cpp:330] Iteration 7000, Testing net (#0)
I0816 15:28:29.684449  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:29.689353  5636 solver.cpp:397]     Test net output #0: loss = 0.0174019 (* 1 = 0.0174019 loss)
I0816 15:28:29.694514  5636 solver.cpp:218] Iteration 7000 (131.293 iter/s, 0.761657s/100 iters), loss = 0.0132783
I0816 15:28:29.694558  5636 solver.cpp:237]     Train net output #0: loss = 0.0132783 (* 1 = 0.0132783 loss)
I0816 15:28:29.694576  5636 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I0816 15:28:30.233137  5636 solver.cpp:218] Iteration 7100 (185.674 iter/s, 0.538577s/100 iters), loss = 0.0205082
I0816 15:28:30.233206  5636 solver.cpp:237]     Train net output #0: loss = 0.0205082 (* 1 = 0.0205082 loss)
I0816 15:28:30.233220  5636 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I0816 15:28:30.783638  5636 solver.cpp:218] Iteration 7200 (181.688 iter/s, 0.550394s/100 iters), loss = 0.0104774
I0816 15:28:30.783728  5636 solver.cpp:237]     Train net output #0: loss = 0.0104774 (* 1 = 0.0104774 loss)
I0816 15:28:30.783759  5636 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I0816 15:28:31.348044  5636 solver.cpp:218] Iteration 7300 (177.207 iter/s, 0.564313s/100 iters), loss = 0.0217026
I0816 15:28:31.348124  5636 solver.cpp:237]     Train net output #0: loss = 0.0217026 (* 1 = 0.0217026 loss)
I0816 15:28:31.348139  5636 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I0816 15:28:31.912554  5636 solver.cpp:218] Iteration 7400 (177.172 iter/s, 0.564423s/100 iters), loss = 0.00785008
I0816 15:28:31.912632  5636 solver.cpp:237]     Train net output #0: loss = 0.0078501 (* 1 = 0.0078501 loss)
I0816 15:28:31.912647  5636 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I0816 15:28:32.467553  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:32.486578  5636 solver.cpp:330] Iteration 7500, Testing net (#0)
I0816 15:28:32.704195  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:32.711737  5636 solver.cpp:397]     Test net output #0: loss = 0.0181275 (* 1 = 0.0181275 loss)
I0816 15:28:32.717388  5636 solver.cpp:218] Iteration 7500 (124.267 iter/s, 0.804721s/100 iters), loss = 0.00905309
I0816 15:28:32.717432  5636 solver.cpp:237]     Train net output #0: loss = 0.00905311 (* 1 = 0.00905311 loss)
I0816 15:28:32.717448  5636 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I0816 15:28:33.290390  5636 solver.cpp:218] Iteration 7600 (174.544 iter/s, 0.572922s/100 iters), loss = 0.0121075
I0816 15:28:33.290496  5636 solver.cpp:237]     Train net output #0: loss = 0.0121076 (* 1 = 0.0121076 loss)
I0816 15:28:33.290513  5636 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I0816 15:28:33.871265  5636 solver.cpp:218] Iteration 7700 (172.185 iter/s, 0.58077s/100 iters), loss = 0.010491
I0816 15:28:33.871330  5636 solver.cpp:237]     Train net output #0: loss = 0.010491 (* 1 = 0.010491 loss)
I0816 15:28:33.871343  5636 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I0816 15:28:34.455253  5636 solver.cpp:218] Iteration 7800 (171.273 iter/s, 0.583865s/100 iters), loss = 0.00752971
I0816 15:28:34.455307  5636 solver.cpp:237]     Train net output #0: loss = 0.00752972 (* 1 = 0.00752972 loss)
I0816 15:28:34.455322  5636 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I0816 15:28:35.034577  5636 solver.cpp:218] Iteration 7900 (172.642 iter/s, 0.579233s/100 iters), loss = 0.00414775
I0816 15:28:35.034653  5636 solver.cpp:237]     Train net output #0: loss = 0.00414776 (* 1 = 0.00414776 loss)
I0816 15:28:35.034668  5636 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I0816 15:28:35.598215  5636 solver.cpp:330] Iteration 8000, Testing net (#0)
I0816 15:28:35.805232  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:35.812862  5636 solver.cpp:397]     Test net output #0: loss = 0.0171376 (* 1 = 0.0171376 loss)
I0816 15:28:35.818712  5636 solver.cpp:218] Iteration 8000 (127.546 iter/s, 0.784032s/100 iters), loss = 0.0111945
I0816 15:28:35.818763  5636 solver.cpp:237]     Train net output #0: loss = 0.0111945 (* 1 = 0.0111945 loss)
I0816 15:28:35.818779  5636 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I0816 15:28:36.407516  5636 solver.cpp:218] Iteration 8100 (169.861 iter/s, 0.588716s/100 iters), loss = 0.00356086
I0816 15:28:36.407593  5636 solver.cpp:237]     Train net output #0: loss = 0.00356087 (* 1 = 0.00356087 loss)
I0816 15:28:36.407608  5636 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I0816 15:28:36.983366  5636 solver.cpp:218] Iteration 8200 (173.693 iter/s, 0.575728s/100 iters), loss = 0.00460821
I0816 15:28:36.983444  5636 solver.cpp:237]     Train net output #0: loss = 0.00460822 (* 1 = 0.00460822 loss)
I0816 15:28:36.983459  5636 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I0816 15:28:37.543620  5636 solver.cpp:218] Iteration 8300 (178.527 iter/s, 0.560141s/100 iters), loss = 0.00693919
I0816 15:28:37.543678  5636 solver.cpp:237]     Train net output #0: loss = 0.00693919 (* 1 = 0.00693919 loss)
I0816 15:28:37.543692  5636 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I0816 15:28:38.087544  5636 solver.cpp:218] Iteration 8400 (183.883 iter/s, 0.543823s/100 iters), loss = 0.00521622
I0816 15:28:38.087625  5636 solver.cpp:237]     Train net output #0: loss = 0.00521623 (* 1 = 0.00521623 loss)
I0816 15:28:38.087641  5636 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I0816 15:28:38.273344  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:38.647774  5636 solver.cpp:330] Iteration 8500, Testing net (#0)
I0816 15:28:38.844961  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:38.852553  5636 solver.cpp:397]     Test net output #0: loss = 0.0178681 (* 1 = 0.0178681 loss)
I0816 15:28:38.858474  5636 solver.cpp:218] Iteration 8500 (129.726 iter/s, 0.770855s/100 iters), loss = 0.00413523
I0816 15:28:38.858517  5636 solver.cpp:237]     Train net output #0: loss = 0.00413523 (* 1 = 0.00413523 loss)
I0816 15:28:38.858536  5636 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I0816 15:28:39.405740  5636 solver.cpp:218] Iteration 8600 (182.753 iter/s, 0.547186s/100 iters), loss = 0.0058527
I0816 15:28:39.405798  5636 solver.cpp:237]     Train net output #0: loss = 0.0058527 (* 1 = 0.0058527 loss)
I0816 15:28:39.405812  5636 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I0816 15:28:39.966433  5636 solver.cpp:218] Iteration 8700 (178.382 iter/s, 0.560595s/100 iters), loss = 0.0029306
I0816 15:28:39.966503  5636 solver.cpp:237]     Train net output #0: loss = 0.0029306 (* 1 = 0.0029306 loss)
I0816 15:28:39.966542  5636 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I0816 15:28:40.555791  5636 solver.cpp:218] Iteration 8800 (169.707 iter/s, 0.58925s/100 iters), loss = 0.00905103
I0816 15:28:40.555881  5636 solver.cpp:237]     Train net output #0: loss = 0.00905103 (* 1 = 0.00905103 loss)
I0816 15:28:40.555897  5636 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I0816 15:28:41.145426  5636 solver.cpp:218] Iteration 8900 (169.635 iter/s, 0.589502s/100 iters), loss = 0.00454588
I0816 15:28:41.145479  5636 solver.cpp:237]     Train net output #0: loss = 0.00454589 (* 1 = 0.00454589 loss)
I0816 15:28:41.145494  5636 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I0816 15:28:41.728323  5636 solver.cpp:330] Iteration 9000, Testing net (#0)
I0816 15:28:41.949313  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:41.956946  5636 solver.cpp:397]     Test net output #0: loss = 0.0172544 (* 1 = 0.0172544 loss)
I0816 15:28:41.962599  5636 solver.cpp:218] Iteration 9000 (122.387 iter/s, 0.817082s/100 iters), loss = 0.00635134
I0816 15:28:41.962640  5636 solver.cpp:237]     Train net output #0: loss = 0.00635135 (* 1 = 0.00635135 loss)
I0816 15:28:41.962657  5636 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I0816 15:28:42.545809  5636 solver.cpp:218] Iteration 9100 (171.489 iter/s, 0.583128s/100 iters), loss = 0.00504157
I0816 15:28:42.545893  5636 solver.cpp:237]     Train net output #0: loss = 0.00504157 (* 1 = 0.00504157 loss)
I0816 15:28:42.545909  5636 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I0816 15:28:43.134963  5636 solver.cpp:218] Iteration 9200 (169.77 iter/s, 0.589032s/100 iters), loss = 0.00950909
I0816 15:28:43.135053  5636 solver.cpp:237]     Train net output #0: loss = 0.00950909 (* 1 = 0.00950909 loss)
I0816 15:28:43.135072  5636 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I0816 15:28:43.718842  5636 solver.cpp:218] Iteration 9300 (171.309 iter/s, 0.583739s/100 iters), loss = 0.0036916
I0816 15:28:43.719328  5636 solver.cpp:237]     Train net output #0: loss = 0.0036916 (* 1 = 0.0036916 loss)
I0816 15:28:43.719370  5636 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I0816 15:28:44.139276  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:44.317344  5636 solver.cpp:218] Iteration 9400 (167.218 iter/s, 0.59802s/100 iters), loss = 0.00575844
I0816 15:28:44.317407  5636 solver.cpp:237]     Train net output #0: loss = 0.00575844 (* 1 = 0.00575844 loss)
I0816 15:28:44.317425  5636 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I0816 15:28:44.906159  5636 solver.cpp:330] Iteration 9500, Testing net (#0)
I0816 15:28:45.093780  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:45.095855  5636 solver.cpp:397]     Test net output #0: loss = 0.0170595 (* 1 = 0.0170595 loss)
I0816 15:28:45.101697  5636 solver.cpp:218] Iteration 9500 (127.509 iter/s, 0.784257s/100 iters), loss = 0.00211705
I0816 15:28:45.101749  5636 solver.cpp:237]     Train net output #0: loss = 0.00211706 (* 1 = 0.00211706 loss)
I0816 15:28:45.101769  5636 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I0816 15:28:45.652545  5636 solver.cpp:218] Iteration 9600 (181.556 iter/s, 0.550795s/100 iters), loss = 0.00583619
I0816 15:28:45.652619  5636 solver.cpp:237]     Train net output #0: loss = 0.00583619 (* 1 = 0.00583619 loss)
I0816 15:28:45.652638  5636 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I0816 15:28:46.193903  5636 solver.cpp:218] Iteration 9700 (184.763 iter/s, 0.541234s/100 iters), loss = 0.00773654
I0816 15:28:46.194044  5636 solver.cpp:237]     Train net output #0: loss = 0.00773655 (* 1 = 0.00773655 loss)
I0816 15:28:46.194080  5636 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I0816 15:28:46.759125  5636 solver.cpp:218] Iteration 9800 (176.963 iter/s, 0.565089s/100 iters), loss = 0.0119614
I0816 15:28:46.759218  5636 solver.cpp:237]     Train net output #0: loss = 0.0119614 (* 1 = 0.0119614 loss)
I0816 15:28:46.759238  5636 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I0816 15:28:47.320997  5636 solver.cpp:218] Iteration 9900 (178.006 iter/s, 0.56178s/100 iters), loss = 0.00553552
I0816 15:28:47.321071  5636 solver.cpp:237]     Train net output #0: loss = 0.00553553 (* 1 = 0.00553553 loss)
I0816 15:28:47.321090  5636 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I0816 15:28:47.878096  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_10000.caffemodel
I0816 15:28:47.892511  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_10000.solverstate
I0816 15:28:47.895481  5636 solver.cpp:330] Iteration 10000, Testing net (#0)
I0816 15:28:48.095533  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:48.101325  5636 solver.cpp:397]     Test net output #0: loss = 0.0182806 (* 1 = 0.0182806 loss)
I0816 15:28:48.106766  5636 solver.cpp:218] Iteration 10000 (127.274 iter/s, 0.785705s/100 iters), loss = 0.00664286
I0816 15:28:48.106812  5636 solver.cpp:237]     Train net output #0: loss = 0.00664287 (* 1 = 0.00664287 loss)
I0816 15:28:48.106829  5636 sgd_solver.cpp:105] Iteration 10000, lr = 0.00594604
I0816 15:28:48.655987  5636 solver.cpp:218] Iteration 10100 (182.09 iter/s, 0.549178s/100 iters), loss = 0.0119412
I0816 15:28:48.656047  5636 solver.cpp:237]     Train net output #0: loss = 0.0119412 (* 1 = 0.0119412 loss)
I0816 15:28:48.656062  5636 sgd_solver.cpp:105] Iteration 10100, lr = 0.00592384
I0816 15:28:49.216094  5636 solver.cpp:218] Iteration 10200 (178.569 iter/s, 0.560006s/100 iters), loss = 0.0105275
I0816 15:28:49.216167  5636 solver.cpp:237]     Train net output #0: loss = 0.0105275 (* 1 = 0.0105275 loss)
I0816 15:28:49.216182  5636 sgd_solver.cpp:105] Iteration 10200, lr = 0.00590183
I0816 15:28:49.787175  5636 solver.cpp:218] Iteration 10300 (175.129 iter/s, 0.571006s/100 iters), loss = 0.00325695
I0816 15:28:49.787252  5636 solver.cpp:237]     Train net output #0: loss = 0.00325696 (* 1 = 0.00325696 loss)
I0816 15:28:49.787293  5636 sgd_solver.cpp:105] Iteration 10300, lr = 0.00588001
I0816 15:28:49.831183  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:50.360397  5636 solver.cpp:218] Iteration 10400 (174.475 iter/s, 0.573149s/100 iters), loss = 0.00378046
I0816 15:28:50.360461  5636 solver.cpp:237]     Train net output #0: loss = 0.00378046 (* 1 = 0.00378046 loss)
I0816 15:28:50.360476  5636 sgd_solver.cpp:105] Iteration 10400, lr = 0.00585838
I0816 15:28:50.924394  5636 solver.cpp:330] Iteration 10500, Testing net (#0)
I0816 15:28:51.127157  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:51.132726  5636 solver.cpp:397]     Test net output #0: loss = 0.0177625 (* 1 = 0.0177625 loss)
I0816 15:28:51.137643  5636 solver.cpp:218] Iteration 10500 (128.669 iter/s, 0.777189s/100 iters), loss = 0.0053655
I0816 15:28:51.137687  5636 solver.cpp:237]     Train net output #0: loss = 0.00536551 (* 1 = 0.00536551 loss)
I0816 15:28:51.137706  5636 sgd_solver.cpp:105] Iteration 10500, lr = 0.00583693
I0816 15:28:51.679018  5636 solver.cpp:218] Iteration 10600 (184.732 iter/s, 0.541326s/100 iters), loss = 0.00320202
I0816 15:28:51.679098  5636 solver.cpp:237]     Train net output #0: loss = 0.00320202 (* 1 = 0.00320202 loss)
I0816 15:28:51.679113  5636 sgd_solver.cpp:105] Iteration 10600, lr = 0.00581567
I0816 15:28:52.231521  5636 solver.cpp:218] Iteration 10700 (181.033 iter/s, 0.552386s/100 iters), loss = 0.00414152
I0816 15:28:52.231587  5636 solver.cpp:237]     Train net output #0: loss = 0.00414153 (* 1 = 0.00414153 loss)
I0816 15:28:52.231603  5636 sgd_solver.cpp:105] Iteration 10700, lr = 0.00579458
I0816 15:28:52.790298  5636 solver.cpp:218] Iteration 10800 (178.984 iter/s, 0.558711s/100 iters), loss = 0.00675557
I0816 15:28:52.790369  5636 solver.cpp:237]     Train net output #0: loss = 0.00675557 (* 1 = 0.00675557 loss)
I0816 15:28:52.790385  5636 sgd_solver.cpp:105] Iteration 10800, lr = 0.00577368
I0816 15:28:53.351171  5636 solver.cpp:218] Iteration 10900 (178.316 iter/s, 0.560801s/100 iters), loss = 0.00234296
I0816 15:28:53.351255  5636 solver.cpp:237]     Train net output #0: loss = 0.00234296 (* 1 = 0.00234296 loss)
I0816 15:28:53.351270  5636 sgd_solver.cpp:105] Iteration 10900, lr = 0.00575295
I0816 15:28:53.902856  5636 solver.cpp:330] Iteration 11000, Testing net (#0)
I0816 15:28:54.102653  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:54.108721  5636 solver.cpp:397]     Test net output #0: loss = 0.0173484 (* 1 = 0.0173484 loss)
I0816 15:28:54.114060  5636 solver.cpp:218] Iteration 11000 (131.094 iter/s, 0.762811s/100 iters), loss = 0.00562056
I0816 15:28:54.114117  5636 solver.cpp:237]     Train net output #0: loss = 0.00562057 (* 1 = 0.00562057 loss)
I0816 15:28:54.114136  5636 sgd_solver.cpp:105] Iteration 11000, lr = 0.00573239
I0816 15:28:54.662891  5636 solver.cpp:218] Iteration 11100 (182.226 iter/s, 0.548768s/100 iters), loss = 0.00413507
I0816 15:28:54.662967  5636 solver.cpp:237]     Train net output #0: loss = 0.00413507 (* 1 = 0.00413507 loss)
I0816 15:28:54.662982  5636 sgd_solver.cpp:105] Iteration 11100, lr = 0.005712
I0816 15:28:55.208257  5636 solver.cpp:218] Iteration 11200 (183.403 iter/s, 0.545247s/100 iters), loss = 0.00534165
I0816 15:28:55.208323  5636 solver.cpp:237]     Train net output #0: loss = 0.00534165 (* 1 = 0.00534165 loss)
I0816 15:28:55.208338  5636 sgd_solver.cpp:105] Iteration 11200, lr = 0.00569178
I0816 15:28:55.462604  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:55.769187  5636 solver.cpp:218] Iteration 11300 (178.296 iter/s, 0.560864s/100 iters), loss = 0.00525178
I0816 15:28:55.769251  5636 solver.cpp:237]     Train net output #0: loss = 0.00525179 (* 1 = 0.00525179 loss)
I0816 15:28:55.769266  5636 sgd_solver.cpp:105] Iteration 11300, lr = 0.00567173
I0816 15:28:56.336346  5636 solver.cpp:218] Iteration 11400 (176.337 iter/s, 0.567096s/100 iters), loss = 0.00565258
I0816 15:28:56.336407  5636 solver.cpp:237]     Train net output #0: loss = 0.00565259 (* 1 = 0.00565259 loss)
I0816 15:28:56.336458  5636 sgd_solver.cpp:105] Iteration 11400, lr = 0.00565184
I0816 15:28:56.889238  5636 solver.cpp:330] Iteration 11500, Testing net (#0)
I0816 15:28:57.092561  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:28:57.098363  5636 solver.cpp:397]     Test net output #0: loss = 0.017311 (* 1 = 0.017311 loss)
I0816 15:28:57.103745  5636 solver.cpp:218] Iteration 11500 (130.32 iter/s, 0.767344s/100 iters), loss = 0.00360844
I0816 15:28:57.103790  5636 solver.cpp:237]     Train net output #0: loss = 0.00360844 (* 1 = 0.00360844 loss)
I0816 15:28:57.103824  5636 sgd_solver.cpp:105] Iteration 11500, lr = 0.00563211
I0816 15:28:57.662808  5636 solver.cpp:218] Iteration 11600 (178.934 iter/s, 0.558865s/100 iters), loss = 0.00669868
I0816 15:28:57.662905  5636 solver.cpp:237]     Train net output #0: loss = 0.00669868 (* 1 = 0.00669868 loss)
I0816 15:28:57.662932  5636 sgd_solver.cpp:105] Iteration 11600, lr = 0.00561254
I0816 15:28:58.209861  5636 solver.cpp:218] Iteration 11700 (182.844 iter/s, 0.546913s/100 iters), loss = 0.00417356
I0816 15:28:58.209959  5636 solver.cpp:237]     Train net output #0: loss = 0.00417356 (* 1 = 0.00417356 loss)
I0816 15:28:58.209983  5636 sgd_solver.cpp:105] Iteration 11700, lr = 0.00559313
I0816 15:28:58.775043  5636 solver.cpp:218] Iteration 11800 (176.966 iter/s, 0.56508s/100 iters), loss = 0.00117413
I0816 15:28:58.775133  5636 solver.cpp:237]     Train net output #0: loss = 0.00117413 (* 1 = 0.00117413 loss)
I0816 15:28:58.775153  5636 sgd_solver.cpp:105] Iteration 11800, lr = 0.00557388
I0816 15:28:59.343312  5636 solver.cpp:218] Iteration 11900 (176 iter/s, 0.568181s/100 iters), loss = 0.00548375
I0816 15:28:59.343379  5636 solver.cpp:237]     Train net output #0: loss = 0.00548375 (* 1 = 0.00548375 loss)
I0816 15:28:59.343394  5636 sgd_solver.cpp:105] Iteration 11900, lr = 0.00555478
I0816 15:28:59.901358  5636 solver.cpp:330] Iteration 12000, Testing net (#0)
I0816 15:29:00.102229  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:00.107830  5636 solver.cpp:397]     Test net output #0: loss = 0.0169681 (* 1 = 0.0169681 loss)
I0816 15:29:00.113418  5636 solver.cpp:218] Iteration 12000 (129.863 iter/s, 0.770045s/100 iters), loss = 0.00962187
I0816 15:29:00.113472  5636 solver.cpp:237]     Train net output #0: loss = 0.00962187 (* 1 = 0.00962187 loss)
I0816 15:29:00.113492  5636 sgd_solver.cpp:105] Iteration 12000, lr = 0.00553583
I0816 15:29:00.659826  5636 solver.cpp:218] Iteration 12100 (183.034 iter/s, 0.546348s/100 iters), loss = 0.00367899
I0816 15:29:00.659922  5636 solver.cpp:237]     Train net output #0: loss = 0.003679 (* 1 = 0.003679 loss)
I0816 15:29:00.659940  5636 sgd_solver.cpp:105] Iteration 12100, lr = 0.00551704
I0816 15:29:01.123978  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:01.215618  5636 solver.cpp:218] Iteration 12200 (179.965 iter/s, 0.555665s/100 iters), loss = 0.00158149
I0816 15:29:01.215673  5636 solver.cpp:237]     Train net output #0: loss = 0.00158149 (* 1 = 0.00158149 loss)
I0816 15:29:01.215689  5636 sgd_solver.cpp:105] Iteration 12200, lr = 0.00549839
I0816 15:29:01.782158  5636 solver.cpp:218] Iteration 12300 (176.528 iter/s, 0.566483s/100 iters), loss = 0.0029707
I0816 15:29:01.782248  5636 solver.cpp:237]     Train net output #0: loss = 0.00297071 (* 1 = 0.00297071 loss)
I0816 15:29:01.782264  5636 sgd_solver.cpp:105] Iteration 12300, lr = 0.00547988
I0816 15:29:02.315403  5636 solver.cpp:218] Iteration 12400 (187.563 iter/s, 0.533154s/100 iters), loss = 0.000694469
I0816 15:29:02.315480  5636 solver.cpp:237]     Train net output #0: loss = 0.000694476 (* 1 = 0.000694476 loss)
I0816 15:29:02.315503  5636 sgd_solver.cpp:105] Iteration 12400, lr = 0.00546153
I0816 15:29:02.869956  5636 solver.cpp:330] Iteration 12500, Testing net (#0)
I0816 15:29:03.067564  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:03.075075  5636 solver.cpp:397]     Test net output #0: loss = 0.0177402 (* 1 = 0.0177402 loss)
I0816 15:29:03.081324  5636 solver.cpp:218] Iteration 12500 (130.573 iter/s, 0.765853s/100 iters), loss = 0.00414147
I0816 15:29:03.081383  5636 solver.cpp:237]     Train net output #0: loss = 0.00414148 (* 1 = 0.00414148 loss)
I0816 15:29:03.081403  5636 sgd_solver.cpp:105] Iteration 12500, lr = 0.00544331
I0816 15:29:03.619529  5636 solver.cpp:218] Iteration 12600 (185.827 iter/s, 0.538136s/100 iters), loss = 0.00160019
I0816 15:29:03.619619  5636 solver.cpp:237]     Train net output #0: loss = 0.0016002 (* 1 = 0.0016002 loss)
I0816 15:29:03.619638  5636 sgd_solver.cpp:105] Iteration 12600, lr = 0.00542524
I0816 15:29:04.172219  5636 solver.cpp:218] Iteration 12700 (180.975 iter/s, 0.552561s/100 iters), loss = 0.00544552
I0816 15:29:04.172317  5636 solver.cpp:237]     Train net output #0: loss = 0.00544553 (* 1 = 0.00544553 loss)
I0816 15:29:04.172333  5636 sgd_solver.cpp:105] Iteration 12700, lr = 0.0054073
I0816 15:29:04.733417  5636 solver.cpp:218] Iteration 12800 (178.223 iter/s, 0.561095s/100 iters), loss = 0.00309498
I0816 15:29:04.733516  5636 solver.cpp:237]     Train net output #0: loss = 0.00309499 (* 1 = 0.00309499 loss)
I0816 15:29:04.733532  5636 sgd_solver.cpp:105] Iteration 12800, lr = 0.0053895
I0816 15:29:05.297336  5636 solver.cpp:218] Iteration 12900 (177.361 iter/s, 0.563822s/100 iters), loss = 0.00629485
I0816 15:29:05.297415  5636 solver.cpp:237]     Train net output #0: loss = 0.00629486 (* 1 = 0.00629486 loss)
I0816 15:29:05.297430  5636 sgd_solver.cpp:105] Iteration 12900, lr = 0.00537184
I0816 15:29:05.854781  5636 solver.cpp:330] Iteration 13000, Testing net (#0)
I0816 15:29:06.055055  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:06.060667  5636 solver.cpp:397]     Test net output #0: loss = 0.0179453 (* 1 = 0.0179453 loss)
I0816 15:29:06.065913  5636 solver.cpp:218] Iteration 13000 (130.123 iter/s, 0.768506s/100 iters), loss = 0.0040103
I0816 15:29:06.065958  5636 solver.cpp:237]     Train net output #0: loss = 0.00401031 (* 1 = 0.00401031 loss)
I0816 15:29:06.065979  5636 sgd_solver.cpp:105] Iteration 13000, lr = 0.00535432
I0816 15:29:06.607626  5636 solver.cpp:218] Iteration 13100 (184.615 iter/s, 0.541667s/100 iters), loss = 0.00508699
I0816 15:29:06.607699  5636 solver.cpp:237]     Train net output #0: loss = 0.005087 (* 1 = 0.005087 loss)
I0816 15:29:06.607714  5636 sgd_solver.cpp:105] Iteration 13100, lr = 0.00533692
I0816 15:29:06.725627  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:07.160619  5636 solver.cpp:218] Iteration 13200 (180.869 iter/s, 0.552887s/100 iters), loss = 0.00452101
I0816 15:29:07.160701  5636 solver.cpp:237]     Train net output #0: loss = 0.00452102 (* 1 = 0.00452102 loss)
I0816 15:29:07.160717  5636 sgd_solver.cpp:105] Iteration 13200, lr = 0.00531966
I0816 15:29:07.725592  5636 solver.cpp:218] Iteration 13300 (177.025 iter/s, 0.564893s/100 iters), loss = 0.00119486
I0816 15:29:07.725661  5636 solver.cpp:237]     Train net output #0: loss = 0.00119487 (* 1 = 0.00119487 loss)
I0816 15:29:07.725677  5636 sgd_solver.cpp:105] Iteration 13300, lr = 0.00530253
I0816 15:29:08.297148  5636 solver.cpp:218] Iteration 13400 (174.981 iter/s, 0.57149s/100 iters), loss = 0.00468316
I0816 15:29:08.297222  5636 solver.cpp:237]     Train net output #0: loss = 0.00468316 (* 1 = 0.00468316 loss)
I0816 15:29:08.297237  5636 sgd_solver.cpp:105] Iteration 13400, lr = 0.00528552
I0816 15:29:08.854180  5636 solver.cpp:330] Iteration 13500, Testing net (#0)
I0816 15:29:09.057284  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:09.062963  5636 solver.cpp:397]     Test net output #0: loss = 0.0174297 (* 1 = 0.0174297 loss)
I0816 15:29:09.068594  5636 solver.cpp:218] Iteration 13500 (129.638 iter/s, 0.771379s/100 iters), loss = 0.00498427
I0816 15:29:09.068651  5636 solver.cpp:237]     Train net output #0: loss = 0.00498428 (* 1 = 0.00498428 loss)
I0816 15:29:09.068670  5636 sgd_solver.cpp:105] Iteration 13500, lr = 0.00526865
I0816 15:29:09.601944  5636 solver.cpp:218] Iteration 13600 (187.516 iter/s, 0.533288s/100 iters), loss = 0.00379776
I0816 15:29:09.602061  5636 solver.cpp:237]     Train net output #0: loss = 0.00379777 (* 1 = 0.00379777 loss)
I0816 15:29:09.602077  5636 sgd_solver.cpp:105] Iteration 13600, lr = 0.00525189
I0816 15:29:10.155988  5636 solver.cpp:218] Iteration 13700 (180.543 iter/s, 0.553884s/100 iters), loss = 0.00616049
I0816 15:29:10.156080  5636 solver.cpp:237]     Train net output #0: loss = 0.0061605 (* 1 = 0.0061605 loss)
I0816 15:29:10.156095  5636 sgd_solver.cpp:105] Iteration 13700, lr = 0.00523527
I0816 15:29:10.719712  5636 solver.cpp:218] Iteration 13800 (177.42 iter/s, 0.563633s/100 iters), loss = 0.00131759
I0816 15:29:10.719813  5636 solver.cpp:237]     Train net output #0: loss = 0.0013176 (* 1 = 0.0013176 loss)
I0816 15:29:10.719830  5636 sgd_solver.cpp:105] Iteration 13800, lr = 0.00521876
I0816 15:29:11.289326  5636 solver.cpp:218] Iteration 13900 (175.588 iter/s, 0.569515s/100 iters), loss = 0.00776904
I0816 15:29:11.289399  5636 solver.cpp:237]     Train net output #0: loss = 0.00776904 (* 1 = 0.00776904 loss)
I0816 15:29:11.289415  5636 sgd_solver.cpp:105] Iteration 13900, lr = 0.00520237
I0816 15:29:11.855973  5636 solver.cpp:330] Iteration 14000, Testing net (#0)
I0816 15:29:12.058820  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:12.063637  5636 solver.cpp:397]     Test net output #0: loss = 0.0176849 (* 1 = 0.0176849 loss)
I0816 15:29:12.069000  5636 solver.cpp:218] Iteration 14000 (128.27 iter/s, 0.779607s/100 iters), loss = 0.00762027
I0816 15:29:12.069057  5636 solver.cpp:237]     Train net output #0: loss = 0.00762028 (* 1 = 0.00762028 loss)
I0816 15:29:12.069079  5636 sgd_solver.cpp:105] Iteration 14000, lr = 0.00518611
I0816 15:29:12.378159  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:12.615141  5636 solver.cpp:218] Iteration 14100 (183.121 iter/s, 0.546088s/100 iters), loss = 0.00379188
I0816 15:29:12.615200  5636 solver.cpp:237]     Train net output #0: loss = 0.00379189 (* 1 = 0.00379189 loss)
I0816 15:29:12.615214  5636 sgd_solver.cpp:105] Iteration 14100, lr = 0.00516996
I0816 15:29:13.180358  5636 solver.cpp:218] Iteration 14200 (176.955 iter/s, 0.565116s/100 iters), loss = 0.00795112
I0816 15:29:13.180441  5636 solver.cpp:237]     Train net output #0: loss = 0.00795112 (* 1 = 0.00795112 loss)
I0816 15:29:13.180459  5636 sgd_solver.cpp:105] Iteration 14200, lr = 0.00515393
I0816 15:29:13.728492  5636 solver.cpp:218] Iteration 14300 (182.476 iter/s, 0.548016s/100 iters), loss = 0.0124344
I0816 15:29:13.728886  5636 solver.cpp:237]     Train net output #0: loss = 0.0124344 (* 1 = 0.0124344 loss)
I0816 15:29:13.728904  5636 sgd_solver.cpp:105] Iteration 14300, lr = 0.00513801
I0816 15:29:14.297694  5636 solver.cpp:218] Iteration 14400 (175.805 iter/s, 0.568812s/100 iters), loss = 0.00500724
I0816 15:29:14.297768  5636 solver.cpp:237]     Train net output #0: loss = 0.00500724 (* 1 = 0.00500724 loss)
I0816 15:29:14.297783  5636 sgd_solver.cpp:105] Iteration 14400, lr = 0.00512221
I0816 15:29:14.853700  5636 solver.cpp:330] Iteration 14500, Testing net (#0)
I0816 15:29:15.056758  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:15.062259  5636 solver.cpp:397]     Test net output #0: loss = 0.0173268 (* 1 = 0.0173268 loss)
I0816 15:29:15.067373  5636 solver.cpp:218] Iteration 14500 (129.936 iter/s, 0.769612s/100 iters), loss = 0.00465132
I0816 15:29:15.067431  5636 solver.cpp:237]     Train net output #0: loss = 0.00465133 (* 1 = 0.00465133 loss)
I0816 15:29:15.067452  5636 sgd_solver.cpp:105] Iteration 14500, lr = 0.00510653
I0816 15:29:15.610473  5636 solver.cpp:218] Iteration 14600 (184.145 iter/s, 0.54305s/100 iters), loss = 0.00712348
I0816 15:29:15.610569  5636 solver.cpp:237]     Train net output #0: loss = 0.00712348 (* 1 = 0.00712348 loss)
I0816 15:29:15.610589  5636 sgd_solver.cpp:105] Iteration 14600, lr = 0.00509095
I0816 15:29:16.166039  5636 solver.cpp:218] Iteration 14700 (180.038 iter/s, 0.555437s/100 iters), loss = 0.00454318
I0816 15:29:16.166126  5636 solver.cpp:237]     Train net output #0: loss = 0.00454318 (* 1 = 0.00454318 loss)
I0816 15:29:16.166144  5636 sgd_solver.cpp:105] Iteration 14700, lr = 0.00507548
I0816 15:29:16.731402  5636 solver.cpp:218] Iteration 14800 (176.904 iter/s, 0.565277s/100 iters), loss = 0.0101589
I0816 15:29:16.731484  5636 solver.cpp:237]     Train net output #0: loss = 0.0101589 (* 1 = 0.0101589 loss)
I0816 15:29:16.731503  5636 sgd_solver.cpp:105] Iteration 14800, lr = 0.00506012
I0816 15:29:17.298858  5636 solver.cpp:218] Iteration 14900 (176.25 iter/s, 0.567377s/100 iters), loss = 0.00379766
I0816 15:29:17.298954  5636 solver.cpp:237]     Train net output #0: loss = 0.00379766 (* 1 = 0.00379766 loss)
I0816 15:29:17.298972  5636 sgd_solver.cpp:105] Iteration 14900, lr = 0.00504488
I0816 15:29:17.840382  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:17.857990  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_15000.caffemodel
I0816 15:29:17.876066  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_15000.solverstate
I0816 15:29:17.880362  5636 solver.cpp:330] Iteration 15000, Testing net (#0)
I0816 15:29:18.082008  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:18.088001  5636 solver.cpp:397]     Test net output #0: loss = 0.0179654 (* 1 = 0.0179654 loss)
I0816 15:29:18.093327  5636 solver.cpp:218] Iteration 15000 (125.884 iter/s, 0.794381s/100 iters), loss = 0.00497153
I0816 15:29:18.093391  5636 solver.cpp:237]     Train net output #0: loss = 0.00497153 (* 1 = 0.00497153 loss)
I0816 15:29:18.093415  5636 sgd_solver.cpp:105] Iteration 15000, lr = 0.00502973
I0816 15:29:18.644731  5636 solver.cpp:218] Iteration 15100 (181.372 iter/s, 0.551352s/100 iters), loss = 0.00501186
I0816 15:29:18.644809  5636 solver.cpp:237]     Train net output #0: loss = 0.00501187 (* 1 = 0.00501187 loss)
I0816 15:29:18.644829  5636 sgd_solver.cpp:105] Iteration 15100, lr = 0.0050147
I0816 15:29:19.208772  5636 solver.cpp:218] Iteration 15200 (177.328 iter/s, 0.563928s/100 iters), loss = 0.00412377
I0816 15:29:19.208858  5636 solver.cpp:237]     Train net output #0: loss = 0.00412378 (* 1 = 0.00412378 loss)
I0816 15:29:19.208878  5636 sgd_solver.cpp:105] Iteration 15200, lr = 0.00499976
I0816 15:29:19.775315  5636 solver.cpp:218] Iteration 15300 (176.537 iter/s, 0.566454s/100 iters), loss = 0.00357484
I0816 15:29:19.775398  5636 solver.cpp:237]     Train net output #0: loss = 0.00357485 (* 1 = 0.00357485 loss)
I0816 15:29:19.775454  5636 sgd_solver.cpp:105] Iteration 15300, lr = 0.00498494
I0816 15:29:20.341437  5636 solver.cpp:218] Iteration 15400 (176.664 iter/s, 0.566046s/100 iters), loss = 0.00284837
I0816 15:29:20.341502  5636 solver.cpp:237]     Train net output #0: loss = 0.00284837 (* 1 = 0.00284837 loss)
I0816 15:29:20.341517  5636 sgd_solver.cpp:105] Iteration 15400, lr = 0.00497021
I0816 15:29:20.897991  5636 solver.cpp:330] Iteration 15500, Testing net (#0)
I0816 15:29:21.100177  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:21.105782  5636 solver.cpp:397]     Test net output #0: loss = 0.0171691 (* 1 = 0.0171691 loss)
I0816 15:29:21.110908  5636 solver.cpp:218] Iteration 15500 (129.969 iter/s, 0.769412s/100 iters), loss = 0.00450212
I0816 15:29:21.110952  5636 solver.cpp:237]     Train net output #0: loss = 0.00450212 (* 1 = 0.00450212 loss)
I0816 15:29:21.110970  5636 sgd_solver.cpp:105] Iteration 15500, lr = 0.00495558
I0816 15:29:21.649541  5636 solver.cpp:218] Iteration 15600 (185.67 iter/s, 0.538589s/100 iters), loss = 0.00257396
I0816 15:29:21.649605  5636 solver.cpp:237]     Train net output #0: loss = 0.00257397 (* 1 = 0.00257397 loss)
I0816 15:29:21.649619  5636 sgd_solver.cpp:105] Iteration 15600, lr = 0.00494106
I0816 15:29:22.199789  5636 solver.cpp:218] Iteration 15700 (181.769 iter/s, 0.550148s/100 iters), loss = 0.0033662
I0816 15:29:22.199861  5636 solver.cpp:237]     Train net output #0: loss = 0.0033662 (* 1 = 0.0033662 loss)
I0816 15:29:22.199875  5636 sgd_solver.cpp:105] Iteration 15700, lr = 0.00492663
I0816 15:29:22.757565  5636 solver.cpp:218] Iteration 15800 (179.306 iter/s, 0.557706s/100 iters), loss = 0.00388568
I0816 15:29:22.757642  5636 solver.cpp:237]     Train net output #0: loss = 0.00388569 (* 1 = 0.00388569 loss)
I0816 15:29:22.757658  5636 sgd_solver.cpp:105] Iteration 15800, lr = 0.0049123
I0816 15:29:23.316941  5636 solver.cpp:218] Iteration 15900 (178.795 iter/s, 0.559301s/100 iters), loss = 0.00301425
I0816 15:29:23.317009  5636 solver.cpp:237]     Train net output #0: loss = 0.00301425 (* 1 = 0.00301425 loss)
I0816 15:29:23.317039  5636 sgd_solver.cpp:105] Iteration 15900, lr = 0.00489807
I0816 15:29:23.504470  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:23.876477  5636 solver.cpp:330] Iteration 16000, Testing net (#0)
I0816 15:29:24.081564  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:24.087268  5636 solver.cpp:397]     Test net output #0: loss = 0.0178537 (* 1 = 0.0178537 loss)
I0816 15:29:24.092569  5636 solver.cpp:218] Iteration 16000 (128.938 iter/s, 0.775566s/100 iters), loss = 0.00149635
I0816 15:29:24.092613  5636 solver.cpp:237]     Train net output #0: loss = 0.00149636 (* 1 = 0.00149636 loss)
I0816 15:29:24.092633  5636 sgd_solver.cpp:105] Iteration 16000, lr = 0.00488394
I0816 15:29:24.640419  5636 solver.cpp:218] Iteration 16100 (182.546 iter/s, 0.547806s/100 iters), loss = 0.00248456
I0816 15:29:24.640487  5636 solver.cpp:237]     Train net output #0: loss = 0.00248456 (* 1 = 0.00248456 loss)
I0816 15:29:24.640502  5636 sgd_solver.cpp:105] Iteration 16100, lr = 0.0048699
I0816 15:29:25.193593  5636 solver.cpp:218] Iteration 16200 (180.808 iter/s, 0.553073s/100 iters), loss = 0.00183957
I0816 15:29:25.193666  5636 solver.cpp:237]     Train net output #0: loss = 0.00183957 (* 1 = 0.00183957 loss)
I0816 15:29:25.193681  5636 sgd_solver.cpp:105] Iteration 16200, lr = 0.00485595
I0816 15:29:25.760823  5636 solver.cpp:218] Iteration 16300 (176.318 iter/s, 0.567157s/100 iters), loss = 0.00432079
I0816 15:29:25.760893  5636 solver.cpp:237]     Train net output #0: loss = 0.00432079 (* 1 = 0.00432079 loss)
I0816 15:29:25.760908  5636 sgd_solver.cpp:105] Iteration 16300, lr = 0.00484209
I0816 15:29:26.334939  5636 solver.cpp:218] Iteration 16400 (174.202 iter/s, 0.574046s/100 iters), loss = 0.00185049
I0816 15:29:26.335013  5636 solver.cpp:237]     Train net output #0: loss = 0.00185049 (* 1 = 0.00185049 loss)
I0816 15:29:26.335028  5636 sgd_solver.cpp:105] Iteration 16400, lr = 0.00482833
I0816 15:29:26.890058  5636 solver.cpp:330] Iteration 16500, Testing net (#0)
I0816 15:29:27.095245  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:27.101083  5636 solver.cpp:397]     Test net output #0: loss = 0.017411 (* 1 = 0.017411 loss)
I0816 15:29:27.106192  5636 solver.cpp:218] Iteration 16500 (129.67 iter/s, 0.771187s/100 iters), loss = 0.00339823
I0816 15:29:27.106248  5636 solver.cpp:237]     Train net output #0: loss = 0.00339823 (* 1 = 0.00339823 loss)
I0816 15:29:27.106267  5636 sgd_solver.cpp:105] Iteration 16500, lr = 0.00481466
I0816 15:29:27.644605  5636 solver.cpp:218] Iteration 16600 (185.752 iter/s, 0.538352s/100 iters), loss = 0.00312278
I0816 15:29:27.644677  5636 solver.cpp:237]     Train net output #0: loss = 0.00312278 (* 1 = 0.00312278 loss)
I0816 15:29:27.644691  5636 sgd_solver.cpp:105] Iteration 16600, lr = 0.00480108
I0816 15:29:28.205154  5636 solver.cpp:218] Iteration 16700 (178.432 iter/s, 0.560436s/100 iters), loss = 0.00411299
I0816 15:29:28.205232  5636 solver.cpp:237]     Train net output #0: loss = 0.00411299 (* 1 = 0.00411299 loss)
I0816 15:29:28.205247  5636 sgd_solver.cpp:105] Iteration 16700, lr = 0.00478759
I0816 15:29:28.774041  5636 solver.cpp:218] Iteration 16800 (175.806 iter/s, 0.56881s/100 iters), loss = 0.00312406
I0816 15:29:28.774117  5636 solver.cpp:237]     Train net output #0: loss = 0.00312406 (* 1 = 0.00312406 loss)
I0816 15:29:28.774132  5636 sgd_solver.cpp:105] Iteration 16800, lr = 0.00477418
I0816 15:29:29.178277  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:29.339634  5636 solver.cpp:218] Iteration 16900 (176.828 iter/s, 0.565521s/100 iters), loss = 0.00263439
I0816 15:29:29.339687  5636 solver.cpp:237]     Train net output #0: loss = 0.00263439 (* 1 = 0.00263439 loss)
I0816 15:29:29.339702  5636 sgd_solver.cpp:105] Iteration 16900, lr = 0.00476086
I0816 15:29:29.895638  5636 solver.cpp:330] Iteration 17000, Testing net (#0)
I0816 15:29:30.097509  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:30.103644  5636 solver.cpp:397]     Test net output #0: loss = 0.0172063 (* 1 = 0.0172063 loss)
I0816 15:29:30.109025  5636 solver.cpp:218] Iteration 17000 (129.981 iter/s, 0.769342s/100 iters), loss = 0.00152978
I0816 15:29:30.109072  5636 solver.cpp:237]     Train net output #0: loss = 0.00152978 (* 1 = 0.00152978 loss)
I0816 15:29:30.109091  5636 sgd_solver.cpp:105] Iteration 17000, lr = 0.00474763
I0816 15:29:30.647423  5636 solver.cpp:218] Iteration 17100 (185.753 iter/s, 0.538348s/100 iters), loss = 0.00328294
I0816 15:29:30.647492  5636 solver.cpp:237]     Train net output #0: loss = 0.00328294 (* 1 = 0.00328294 loss)
I0816 15:29:30.647830  5636 sgd_solver.cpp:105] Iteration 17100, lr = 0.00473449
I0816 15:29:31.200034  5636 solver.cpp:218] Iteration 17200 (180.994 iter/s, 0.552505s/100 iters), loss = 0.003368
I0816 15:29:31.200111  5636 solver.cpp:237]     Train net output #0: loss = 0.003368 (* 1 = 0.003368 loss)
I0816 15:29:31.200126  5636 sgd_solver.cpp:105] Iteration 17200, lr = 0.00472143
I0816 15:29:31.764760  5636 solver.cpp:218] Iteration 17300 (177.101 iter/s, 0.564648s/100 iters), loss = 0.00480479
I0816 15:29:31.764830  5636 solver.cpp:237]     Train net output #0: loss = 0.00480479 (* 1 = 0.00480479 loss)
I0816 15:29:31.764844  5636 sgd_solver.cpp:105] Iteration 17300, lr = 0.00470845
I0816 15:29:32.331436  5636 solver.cpp:218] Iteration 17400 (176.491 iter/s, 0.566602s/100 iters), loss = 0.00330324
I0816 15:29:32.331522  5636 solver.cpp:237]     Train net output #0: loss = 0.00330324 (* 1 = 0.00330324 loss)
I0816 15:29:32.331537  5636 sgd_solver.cpp:105] Iteration 17400, lr = 0.00469556
I0816 15:29:32.890653  5636 solver.cpp:330] Iteration 17500, Testing net (#0)
I0816 15:29:33.094431  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:33.099967  5636 solver.cpp:397]     Test net output #0: loss = 0.0184258 (* 1 = 0.0184258 loss)
I0816 15:29:33.105676  5636 solver.cpp:218] Iteration 17500 (129.172 iter/s, 0.774162s/100 iters), loss = 0.00278298
I0816 15:29:33.105744  5636 solver.cpp:237]     Train net output #0: loss = 0.00278298 (* 1 = 0.00278298 loss)
I0816 15:29:33.105762  5636 sgd_solver.cpp:105] Iteration 17500, lr = 0.00468274
I0816 15:29:33.649320  5636 solver.cpp:218] Iteration 17600 (183.968 iter/s, 0.543573s/100 iters), loss = 0.00589603
I0816 15:29:33.649385  5636 solver.cpp:237]     Train net output #0: loss = 0.00589603 (* 1 = 0.00589603 loss)
I0816 15:29:33.649401  5636 sgd_solver.cpp:105] Iteration 17600, lr = 0.00467001
I0816 15:29:34.202075  5636 solver.cpp:218] Iteration 17700 (180.945 iter/s, 0.552655s/100 iters), loss = 0.00385483
I0816 15:29:34.202145  5636 solver.cpp:237]     Train net output #0: loss = 0.00385484 (* 1 = 0.00385484 loss)
I0816 15:29:34.202160  5636 sgd_solver.cpp:105] Iteration 17700, lr = 0.00465736
I0816 15:29:34.763356  5636 solver.cpp:218] Iteration 17800 (178.187 iter/s, 0.561209s/100 iters), loss = 0.00195082
I0816 15:29:34.763432  5636 solver.cpp:237]     Train net output #0: loss = 0.00195082 (* 1 = 0.00195082 loss)
I0816 15:29:34.763448  5636 sgd_solver.cpp:105] Iteration 17800, lr = 0.00464479
I0816 15:29:34.805047  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:35.327213  5636 solver.cpp:218] Iteration 17900 (177.374 iter/s, 0.563781s/100 iters), loss = 0.00178495
I0816 15:29:35.327277  5636 solver.cpp:237]     Train net output #0: loss = 0.00178495 (* 1 = 0.00178495 loss)
I0816 15:29:35.327291  5636 sgd_solver.cpp:105] Iteration 17900, lr = 0.0046323
I0816 15:29:35.888603  5636 solver.cpp:330] Iteration 18000, Testing net (#0)
I0816 15:29:36.092550  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:36.098147  5636 solver.cpp:397]     Test net output #0: loss = 0.018336 (* 1 = 0.018336 loss)
I0816 15:29:36.102919  5636 solver.cpp:218] Iteration 18000 (128.924 iter/s, 0.775649s/100 iters), loss = 0.00181983
I0816 15:29:36.102975  5636 solver.cpp:237]     Train net output #0: loss = 0.00181983 (* 1 = 0.00181983 loss)
I0816 15:29:36.102994  5636 sgd_solver.cpp:105] Iteration 18000, lr = 0.00461989
I0816 15:29:36.631903  5636 solver.cpp:218] Iteration 18100 (189.064 iter/s, 0.528922s/100 iters), loss = 0.00121516
I0816 15:29:36.632002  5636 solver.cpp:237]     Train net output #0: loss = 0.00121516 (* 1 = 0.00121516 loss)
I0816 15:29:36.632019  5636 sgd_solver.cpp:105] Iteration 18100, lr = 0.00460755
I0816 15:29:37.183840  5636 solver.cpp:218] Iteration 18200 (181.239 iter/s, 0.551756s/100 iters), loss = 0.002658
I0816 15:29:37.183925  5636 solver.cpp:237]     Train net output #0: loss = 0.002658 (* 1 = 0.002658 loss)
I0816 15:29:37.183943  5636 sgd_solver.cpp:105] Iteration 18200, lr = 0.00459529
I0816 15:29:37.747727  5636 solver.cpp:218] Iteration 18300 (177.363 iter/s, 0.563814s/100 iters), loss = 0.00514082
I0816 15:29:37.747813  5636 solver.cpp:237]     Train net output #0: loss = 0.00514082 (* 1 = 0.00514082 loss)
I0816 15:29:37.747829  5636 sgd_solver.cpp:105] Iteration 18300, lr = 0.00458311
I0816 15:29:38.317122  5636 solver.cpp:218] Iteration 18400 (175.651 iter/s, 0.569311s/100 iters), loss = 0.0011665
I0816 15:29:38.317196  5636 solver.cpp:237]     Train net output #0: loss = 0.0011665 (* 1 = 0.0011665 loss)
I0816 15:29:38.317212  5636 sgd_solver.cpp:105] Iteration 18400, lr = 0.004571
I0816 15:29:38.876221  5636 solver.cpp:330] Iteration 18500, Testing net (#0)
I0816 15:29:39.076949  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:39.082666  5636 solver.cpp:397]     Test net output #0: loss = 0.0176836 (* 1 = 0.0176836 loss)
I0816 15:29:39.087740  5636 solver.cpp:218] Iteration 18500 (129.777 iter/s, 0.770552s/100 iters), loss = 0.00383361
I0816 15:29:39.087797  5636 solver.cpp:237]     Train net output #0: loss = 0.00383361 (* 1 = 0.00383361 loss)
I0816 15:29:39.087816  5636 sgd_solver.cpp:105] Iteration 18500, lr = 0.00455897
I0816 15:29:39.635159  5636 solver.cpp:218] Iteration 18600 (182.694 iter/s, 0.547364s/100 iters), loss = 0.00241363
I0816 15:29:39.635226  5636 solver.cpp:237]     Train net output #0: loss = 0.00241363 (* 1 = 0.00241363 loss)
I0816 15:29:39.635264  5636 sgd_solver.cpp:105] Iteration 18600, lr = 0.00454701
I0816 15:29:40.188489  5636 solver.cpp:218] Iteration 18700 (180.757 iter/s, 0.553228s/100 iters), loss = 0.00232433
I0816 15:29:40.188573  5636 solver.cpp:237]     Train net output #0: loss = 0.00232433 (* 1 = 0.00232433 loss)
I0816 15:29:40.188590  5636 sgd_solver.cpp:105] Iteration 18700, lr = 0.00453512
I0816 15:29:40.444427  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:40.753598  5636 solver.cpp:218] Iteration 18800 (176.983 iter/s, 0.565026s/100 iters), loss = 0.0027845
I0816 15:29:40.753671  5636 solver.cpp:237]     Train net output #0: loss = 0.0027845 (* 1 = 0.0027845 loss)
I0816 15:29:40.753686  5636 sgd_solver.cpp:105] Iteration 18800, lr = 0.0045233
I0816 15:29:41.319245  5636 solver.cpp:218] Iteration 18900 (176.814 iter/s, 0.565566s/100 iters), loss = 0.00199552
I0816 15:29:41.319346  5636 solver.cpp:237]     Train net output #0: loss = 0.00199552 (* 1 = 0.00199552 loss)
I0816 15:29:41.319363  5636 sgd_solver.cpp:105] Iteration 18900, lr = 0.00451156
I0816 15:29:41.876837  5636 solver.cpp:330] Iteration 19000, Testing net (#0)
I0816 15:29:42.079840  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:42.085733  5636 solver.cpp:397]     Test net output #0: loss = 0.0177753 (* 1 = 0.0177753 loss)
I0816 15:29:42.090847  5636 solver.cpp:218] Iteration 19000 (129.616 iter/s, 0.77151s/100 iters), loss = 0.00170416
I0816 15:29:42.090908  5636 solver.cpp:237]     Train net output #0: loss = 0.00170417 (* 1 = 0.00170417 loss)
I0816 15:29:42.090935  5636 sgd_solver.cpp:105] Iteration 19000, lr = 0.00449989
I0816 15:29:42.634049  5636 solver.cpp:218] Iteration 19100 (184.113 iter/s, 0.543144s/100 iters), loss = 0.00339966
I0816 15:29:42.634130  5636 solver.cpp:237]     Train net output #0: loss = 0.00339966 (* 1 = 0.00339966 loss)
I0816 15:29:42.634147  5636 sgd_solver.cpp:105] Iteration 19100, lr = 0.00448828
I0816 15:29:43.189388  5636 solver.cpp:218] Iteration 19200 (180.108 iter/s, 0.555223s/100 iters), loss = 0.00231159
I0816 15:29:43.189486  5636 solver.cpp:237]     Train net output #0: loss = 0.00231159 (* 1 = 0.00231159 loss)
I0816 15:29:43.189503  5636 sgd_solver.cpp:105] Iteration 19200, lr = 0.00447675
I0816 15:29:43.752385  5636 solver.cpp:218] Iteration 19300 (177.652 iter/s, 0.5629s/100 iters), loss = 0.000665307
I0816 15:29:43.752786  5636 solver.cpp:237]     Train net output #0: loss = 0.000665307 (* 1 = 0.000665307 loss)
I0816 15:29:43.752830  5636 sgd_solver.cpp:105] Iteration 19300, lr = 0.00446529
I0816 15:29:44.316896  5636 solver.cpp:218] Iteration 19400 (177.263 iter/s, 0.564132s/100 iters), loss = 0.00272885
I0816 15:29:44.316962  5636 solver.cpp:237]     Train net output #0: loss = 0.00272885 (* 1 = 0.00272885 loss)
I0816 15:29:44.316978  5636 sgd_solver.cpp:105] Iteration 19400, lr = 0.00445389
I0816 15:29:44.872398  5636 solver.cpp:330] Iteration 19500, Testing net (#0)
I0816 15:29:45.075812  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:45.082119  5636 solver.cpp:397]     Test net output #0: loss = 0.0174825 (* 1 = 0.0174825 loss)
I0816 15:29:45.087448  5636 solver.cpp:218] Iteration 19500 (129.787 iter/s, 0.770493s/100 iters), loss = 0.00651811
I0816 15:29:45.087492  5636 solver.cpp:237]     Train net output #0: loss = 0.00651811 (* 1 = 0.00651811 loss)
I0816 15:29:45.087512  5636 sgd_solver.cpp:105] Iteration 19500, lr = 0.00444256
I0816 15:29:45.639310  5636 solver.cpp:218] Iteration 19600 (181.221 iter/s, 0.551813s/100 iters), loss = 0.00253706
I0816 15:29:45.639386  5636 solver.cpp:237]     Train net output #0: loss = 0.00253706 (* 1 = 0.00253706 loss)
I0816 15:29:45.639405  5636 sgd_solver.cpp:105] Iteration 19600, lr = 0.0044313
I0816 15:29:46.093816  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:46.181336  5636 solver.cpp:218] Iteration 19700 (184.533 iter/s, 0.541908s/100 iters), loss = 0.000665842
I0816 15:29:46.181396  5636 solver.cpp:237]     Train net output #0: loss = 0.000665843 (* 1 = 0.000665843 loss)
I0816 15:29:46.181411  5636 sgd_solver.cpp:105] Iteration 19700, lr = 0.00442011
I0816 15:29:46.749191  5636 solver.cpp:218] Iteration 19800 (176.119 iter/s, 0.567797s/100 iters), loss = 0.00185667
I0816 15:29:46.749263  5636 solver.cpp:237]     Train net output #0: loss = 0.00185667 (* 1 = 0.00185667 loss)
I0816 15:29:46.749277  5636 sgd_solver.cpp:105] Iteration 19800, lr = 0.00440898
I0816 15:29:47.294256  5636 solver.cpp:218] Iteration 19900 (183.489 iter/s, 0.544991s/100 iters), loss = 0.000427324
I0816 15:29:47.294340  5636 solver.cpp:237]     Train net output #0: loss = 0.000427324 (* 1 = 0.000427324 loss)
I0816 15:29:47.294368  5636 sgd_solver.cpp:105] Iteration 19900, lr = 0.00439791
I0816 15:29:47.852766  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_20000.caffemodel
I0816 15:29:47.868005  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_20000.solverstate
I0816 15:29:47.871213  5636 solver.cpp:330] Iteration 20000, Testing net (#0)
I0816 15:29:48.071233  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:48.077105  5636 solver.cpp:397]     Test net output #0: loss = 0.0179477 (* 1 = 0.0179477 loss)
I0816 15:29:48.082165  5636 solver.cpp:218] Iteration 20000 (126.93 iter/s, 0.787836s/100 iters), loss = 0.00202024
I0816 15:29:48.082226  5636 solver.cpp:237]     Train net output #0: loss = 0.00202024 (* 1 = 0.00202024 loss)
I0816 15:29:48.082245  5636 sgd_solver.cpp:105] Iteration 20000, lr = 0.00438691
I0816 15:29:48.631888  5636 solver.cpp:218] Iteration 20100 (182.081 iter/s, 0.549206s/100 iters), loss = 0.00106502
I0816 15:29:48.631956  5636 solver.cpp:237]     Train net output #0: loss = 0.00106502 (* 1 = 0.00106502 loss)
I0816 15:29:48.631974  5636 sgd_solver.cpp:105] Iteration 20100, lr = 0.00437598
I0816 15:29:49.189873  5636 solver.cpp:218] Iteration 20200 (179.255 iter/s, 0.557864s/100 iters), loss = 0.00308061
I0816 15:29:49.190028  5636 solver.cpp:237]     Train net output #0: loss = 0.00308061 (* 1 = 0.00308061 loss)
I0816 15:29:49.190063  5636 sgd_solver.cpp:105] Iteration 20200, lr = 0.00436511
I0816 15:29:49.760036  5636 solver.cpp:218] Iteration 20300 (175.434 iter/s, 0.570016s/100 iters), loss = 0.00149911
I0816 15:29:49.760129  5636 solver.cpp:237]     Train net output #0: loss = 0.00149911 (* 1 = 0.00149911 loss)
I0816 15:29:49.760169  5636 sgd_solver.cpp:105] Iteration 20300, lr = 0.0043543
I0816 15:29:50.321722  5636 solver.cpp:218] Iteration 20400 (178.066 iter/s, 0.561589s/100 iters), loss = 0.00218454
I0816 15:29:50.321810  5636 solver.cpp:237]     Train net output #0: loss = 0.00218454 (* 1 = 0.00218454 loss)
I0816 15:29:50.321831  5636 sgd_solver.cpp:105] Iteration 20400, lr = 0.00434355
I0816 15:29:50.877916  5636 solver.cpp:330] Iteration 20500, Testing net (#0)
I0816 15:29:51.078819  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:51.085000  5636 solver.cpp:397]     Test net output #0: loss = 0.0180526 (* 1 = 0.0180526 loss)
I0816 15:29:51.089808  5636 solver.cpp:218] Iteration 20500 (130.207 iter/s, 0.768007s/100 iters), loss = 0.00188256
I0816 15:29:51.089861  5636 solver.cpp:237]     Train net output #0: loss = 0.00188255 (* 1 = 0.00188255 loss)
I0816 15:29:51.089881  5636 sgd_solver.cpp:105] Iteration 20500, lr = 0.00433286
I0816 15:29:51.635211  5636 solver.cpp:218] Iteration 20600 (183.371 iter/s, 0.545343s/100 iters), loss = 0.00271988
I0816 15:29:51.635309  5636 solver.cpp:237]     Train net output #0: loss = 0.00271988 (* 1 = 0.00271988 loss)
I0816 15:29:51.635329  5636 sgd_solver.cpp:105] Iteration 20600, lr = 0.00432224
I0816 15:29:51.752934  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:52.178496  5636 solver.cpp:218] Iteration 20700 (184.109 iter/s, 0.543157s/100 iters), loss = 0.00241632
I0816 15:29:52.178570  5636 solver.cpp:237]     Train net output #0: loss = 0.00241632 (* 1 = 0.00241632 loss)
I0816 15:29:52.178586  5636 sgd_solver.cpp:105] Iteration 20700, lr = 0.00431168
I0816 15:29:52.743154  5636 solver.cpp:218] Iteration 20800 (177.121 iter/s, 0.564586s/100 iters), loss = 0.00123189
I0816 15:29:52.743228  5636 solver.cpp:237]     Train net output #0: loss = 0.00123189 (* 1 = 0.00123189 loss)
I0816 15:29:52.743244  5636 sgd_solver.cpp:105] Iteration 20800, lr = 0.00430117
I0816 15:29:53.306489  5636 solver.cpp:218] Iteration 20900 (177.537 iter/s, 0.563263s/100 iters), loss = 0.00309724
I0816 15:29:53.306571  5636 solver.cpp:237]     Train net output #0: loss = 0.00309724 (* 1 = 0.00309724 loss)
I0816 15:29:53.306586  5636 sgd_solver.cpp:105] Iteration 20900, lr = 0.00429073
I0816 15:29:53.866327  5636 solver.cpp:330] Iteration 21000, Testing net (#0)
I0816 15:29:54.068686  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:54.074836  5636 solver.cpp:397]     Test net output #0: loss = 0.0181697 (* 1 = 0.0181697 loss)
I0816 15:29:54.079978  5636 solver.cpp:218] Iteration 21000 (129.297 iter/s, 0.773415s/100 iters), loss = 0.00332595
I0816 15:29:54.080034  5636 solver.cpp:237]     Train net output #0: loss = 0.00332595 (* 1 = 0.00332595 loss)
I0816 15:29:54.080054  5636 sgd_solver.cpp:105] Iteration 21000, lr = 0.00428034
I0816 15:29:54.616156  5636 solver.cpp:218] Iteration 21100 (186.525 iter/s, 0.536121s/100 iters), loss = 0.00191935
I0816 15:29:54.616227  5636 solver.cpp:237]     Train net output #0: loss = 0.00191935 (* 1 = 0.00191935 loss)
I0816 15:29:54.616243  5636 sgd_solver.cpp:105] Iteration 21100, lr = 0.00427002
I0816 15:29:55.163816  5636 solver.cpp:218] Iteration 21200 (182.63 iter/s, 0.547555s/100 iters), loss = 0.00338879
I0816 15:29:55.163897  5636 solver.cpp:237]     Train net output #0: loss = 0.00338879 (* 1 = 0.00338879 loss)
I0816 15:29:55.163913  5636 sgd_solver.cpp:105] Iteration 21200, lr = 0.00425975
I0816 15:29:55.728698  5636 solver.cpp:218] Iteration 21300 (177.053 iter/s, 0.564802s/100 iters), loss = 0.00056067
I0816 15:29:55.728775  5636 solver.cpp:237]     Train net output #0: loss = 0.00056067 (* 1 = 0.00056067 loss)
I0816 15:29:55.728801  5636 sgd_solver.cpp:105] Iteration 21300, lr = 0.00424954
I0816 15:29:56.287111  5636 solver.cpp:218] Iteration 21400 (179.102 iter/s, 0.55834s/100 iters), loss = 0.00357701
I0816 15:29:56.287183  5636 solver.cpp:237]     Train net output #0: loss = 0.00357701 (* 1 = 0.00357701 loss)
I0816 15:29:56.287199  5636 sgd_solver.cpp:105] Iteration 21400, lr = 0.00423938
I0816 15:29:56.842092  5636 solver.cpp:330] Iteration 21500, Testing net (#0)
I0816 15:29:57.044077  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:57.050772  5636 solver.cpp:397]     Test net output #0: loss = 0.0178637 (* 1 = 0.0178637 loss)
I0816 15:29:57.055553  5636 solver.cpp:218] Iteration 21500 (130.144 iter/s, 0.768377s/100 iters), loss = 0.00533646
I0816 15:29:57.055610  5636 solver.cpp:237]     Train net output #0: loss = 0.00533646 (* 1 = 0.00533646 loss)
I0816 15:29:57.055629  5636 sgd_solver.cpp:105] Iteration 21500, lr = 0.00422929
I0816 15:29:57.363267  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:29:57.602478  5636 solver.cpp:218] Iteration 21600 (183.005 iter/s, 0.546432s/100 iters), loss = 0.00223259
I0816 15:29:57.602577  5636 solver.cpp:237]     Train net output #0: loss = 0.00223259 (* 1 = 0.00223259 loss)
I0816 15:29:57.602593  5636 sgd_solver.cpp:105] Iteration 21600, lr = 0.00421924
I0816 15:29:58.171728  5636 solver.cpp:218] Iteration 21700 (175.706 iter/s, 0.569133s/100 iters), loss = 0.00394895
I0816 15:29:58.171810  5636 solver.cpp:237]     Train net output #0: loss = 0.00394895 (* 1 = 0.00394895 loss)
I0816 15:29:58.171826  5636 sgd_solver.cpp:105] Iteration 21700, lr = 0.00420926
I0816 15:29:58.720237  5636 solver.cpp:218] Iteration 21800 (182.351 iter/s, 0.548393s/100 iters), loss = 0.00572097
I0816 15:29:58.720304  5636 solver.cpp:237]     Train net output #0: loss = 0.00572097 (* 1 = 0.00572097 loss)
I0816 15:29:58.720320  5636 sgd_solver.cpp:105] Iteration 21800, lr = 0.00419933
I0816 15:29:59.282795  5636 solver.cpp:218] Iteration 21900 (177.78 iter/s, 0.562493s/100 iters), loss = 0.00299948
I0816 15:29:59.282867  5636 solver.cpp:237]     Train net output #0: loss = 0.00299948 (* 1 = 0.00299948 loss)
I0816 15:29:59.282884  5636 sgd_solver.cpp:105] Iteration 21900, lr = 0.00418945
I0816 15:29:59.837236  5636 solver.cpp:330] Iteration 22000, Testing net (#0)
I0816 15:30:00.039034  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:00.045227  5636 solver.cpp:397]     Test net output #0: loss = 0.0178754 (* 1 = 0.0178754 loss)
I0816 15:30:00.050513  5636 solver.cpp:218] Iteration 22000 (130.266 iter/s, 0.767659s/100 iters), loss = 0.00170929
I0816 15:30:00.050571  5636 solver.cpp:237]     Train net output #0: loss = 0.00170929 (* 1 = 0.00170929 loss)
I0816 15:30:00.050591  5636 sgd_solver.cpp:105] Iteration 22000, lr = 0.00417963
I0816 15:30:00.606022  5636 solver.cpp:218] Iteration 22100 (180.034 iter/s, 0.555451s/100 iters), loss = 0.00295009
I0816 15:30:00.606088  5636 solver.cpp:237]     Train net output #0: loss = 0.00295009 (* 1 = 0.00295009 loss)
I0816 15:30:00.606104  5636 sgd_solver.cpp:105] Iteration 22100, lr = 0.00416986
I0816 15:30:01.158108  5636 solver.cpp:218] Iteration 22200 (181.164 iter/s, 0.551985s/100 iters), loss = 0.00228543
I0816 15:30:01.158201  5636 solver.cpp:237]     Train net output #0: loss = 0.00228544 (* 1 = 0.00228544 loss)
I0816 15:30:01.158233  5636 sgd_solver.cpp:105] Iteration 22200, lr = 0.00416014
I0816 15:30:01.726016  5636 solver.cpp:218] Iteration 22300 (176.114 iter/s, 0.567813s/100 iters), loss = 0.00512331
I0816 15:30:01.726114  5636 solver.cpp:237]     Train net output #0: loss = 0.00512331 (* 1 = 0.00512331 loss)
I0816 15:30:01.726131  5636 sgd_solver.cpp:105] Iteration 22300, lr = 0.00415048
I0816 15:30:02.289798  5636 solver.cpp:218] Iteration 22400 (177.403 iter/s, 0.563687s/100 iters), loss = 0.00264378
I0816 15:30:02.289875  5636 solver.cpp:237]     Train net output #0: loss = 0.00264378 (* 1 = 0.00264378 loss)
I0816 15:30:02.289916  5636 sgd_solver.cpp:105] Iteration 22400, lr = 0.00414087
I0816 15:30:02.827399  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:02.844537  5636 solver.cpp:330] Iteration 22500, Testing net (#0)
I0816 15:30:03.043668  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:03.051313  5636 solver.cpp:397]     Test net output #0: loss = 0.0187217 (* 1 = 0.0187217 loss)
I0816 15:30:03.057011  5636 solver.cpp:218] Iteration 22500 (130.354 iter/s, 0.767141s/100 iters), loss = 0.00208937
I0816 15:30:03.057068  5636 solver.cpp:237]     Train net output #0: loss = 0.00208937 (* 1 = 0.00208937 loss)
I0816 15:30:03.057087  5636 sgd_solver.cpp:105] Iteration 22500, lr = 0.00413131
I0816 15:30:03.608445  5636 solver.cpp:218] Iteration 22600 (181.365 iter/s, 0.551374s/100 iters), loss = 0.00288603
I0816 15:30:03.608546  5636 solver.cpp:237]     Train net output #0: loss = 0.00288603 (* 1 = 0.00288603 loss)
I0816 15:30:03.608561  5636 sgd_solver.cpp:105] Iteration 22600, lr = 0.0041218
I0816 15:30:04.164142  5636 solver.cpp:218] Iteration 22700 (180 iter/s, 0.555557s/100 iters), loss = 0.00177058
I0816 15:30:04.164237  5636 solver.cpp:237]     Train net output #0: loss = 0.00177058 (* 1 = 0.00177058 loss)
I0816 15:30:04.164252  5636 sgd_solver.cpp:105] Iteration 22700, lr = 0.00411234
I0816 15:30:04.731019  5636 solver.cpp:218] Iteration 22800 (176.434 iter/s, 0.566784s/100 iters), loss = 0.00193202
I0816 15:30:04.731088  5636 solver.cpp:237]     Train net output #0: loss = 0.00193202 (* 1 = 0.00193202 loss)
I0816 15:30:04.731103  5636 sgd_solver.cpp:105] Iteration 22800, lr = 0.00410293
I0816 15:30:05.298694  5636 solver.cpp:218] Iteration 22900 (176.178 iter/s, 0.567608s/100 iters), loss = 0.00189946
I0816 15:30:05.298761  5636 solver.cpp:237]     Train net output #0: loss = 0.00189946 (* 1 = 0.00189946 loss)
I0816 15:30:05.298776  5636 sgd_solver.cpp:105] Iteration 22900, lr = 0.00409358
I0816 15:30:05.856436  5636 solver.cpp:330] Iteration 23000, Testing net (#0)
I0816 15:30:06.056052  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:06.063482  5636 solver.cpp:397]     Test net output #0: loss = 0.0175651 (* 1 = 0.0175651 loss)
I0816 15:30:06.068840  5636 solver.cpp:218] Iteration 23000 (129.856 iter/s, 0.770085s/100 iters), loss = 0.00191527
I0816 15:30:06.068894  5636 solver.cpp:237]     Train net output #0: loss = 0.00191527 (* 1 = 0.00191527 loss)
I0816 15:30:06.068913  5636 sgd_solver.cpp:105] Iteration 23000, lr = 0.00408427
I0816 15:30:06.605162  5636 solver.cpp:218] Iteration 23100 (186.472 iter/s, 0.536273s/100 iters), loss = 0.00182393
I0816 15:30:06.605238  5636 solver.cpp:237]     Train net output #0: loss = 0.00182393 (* 1 = 0.00182393 loss)
I0816 15:30:06.605257  5636 sgd_solver.cpp:105] Iteration 23100, lr = 0.00407501
I0816 15:30:07.154839  5636 solver.cpp:218] Iteration 23200 (181.966 iter/s, 0.549553s/100 iters), loss = 0.00221092
I0816 15:30:07.154932  5636 solver.cpp:237]     Train net output #0: loss = 0.00221092 (* 1 = 0.00221092 loss)
I0816 15:30:07.154953  5636 sgd_solver.cpp:105] Iteration 23200, lr = 0.0040658
I0816 15:30:07.716161  5636 solver.cpp:218] Iteration 23300 (178.18 iter/s, 0.561231s/100 iters), loss = 0.00179867
I0816 15:30:07.716240  5636 solver.cpp:237]     Train net output #0: loss = 0.00179868 (* 1 = 0.00179868 loss)
I0816 15:30:07.716256  5636 sgd_solver.cpp:105] Iteration 23300, lr = 0.00405664
I0816 15:30:08.280678  5636 solver.cpp:218] Iteration 23400 (177.168 iter/s, 0.564436s/100 iters), loss = 0.00206088
I0816 15:30:08.280762  5636 solver.cpp:237]     Train net output #0: loss = 0.00206088 (* 1 = 0.00206088 loss)
I0816 15:30:08.280778  5636 sgd_solver.cpp:105] Iteration 23400, lr = 0.00404753
I0816 15:30:08.469069  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:08.842170  5636 solver.cpp:330] Iteration 23500, Testing net (#0)
I0816 15:30:09.044559  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:09.050523  5636 solver.cpp:397]     Test net output #0: loss = 0.0182349 (* 1 = 0.0182349 loss)
I0816 15:30:09.055968  5636 solver.cpp:218] Iteration 23500 (128.997 iter/s, 0.775214s/100 iters), loss = 0.000666327
I0816 15:30:09.056023  5636 solver.cpp:237]     Train net output #0: loss = 0.000666331 (* 1 = 0.000666331 loss)
I0816 15:30:09.056043  5636 sgd_solver.cpp:105] Iteration 23500, lr = 0.00403847
I0816 15:30:09.600909  5636 solver.cpp:218] Iteration 23600 (183.522 iter/s, 0.544894s/100 iters), loss = 0.00127006
I0816 15:30:09.601004  5636 solver.cpp:237]     Train net output #0: loss = 0.00127007 (* 1 = 0.00127007 loss)
I0816 15:30:09.601020  5636 sgd_solver.cpp:105] Iteration 23600, lr = 0.00402945
I0816 15:30:10.152796  5636 solver.cpp:218] Iteration 23700 (181.26 iter/s, 0.551695s/100 iters), loss = 0.0010369
I0816 15:30:10.152881  5636 solver.cpp:237]     Train net output #0: loss = 0.0010369 (* 1 = 0.0010369 loss)
I0816 15:30:10.152897  5636 sgd_solver.cpp:105] Iteration 23700, lr = 0.00402048
I0816 15:30:10.718049  5636 solver.cpp:218] Iteration 23800 (176.939 iter/s, 0.565167s/100 iters), loss = 0.00248321
I0816 15:30:10.718125  5636 solver.cpp:237]     Train net output #0: loss = 0.00248321 (* 1 = 0.00248321 loss)
I0816 15:30:10.718144  5636 sgd_solver.cpp:105] Iteration 23800, lr = 0.00401155
I0816 15:30:11.285681  5636 solver.cpp:218] Iteration 23900 (176.194 iter/s, 0.567557s/100 iters), loss = 0.000862797
I0816 15:30:11.285759  5636 solver.cpp:237]     Train net output #0: loss = 0.000862801 (* 1 = 0.000862801 loss)
I0816 15:30:11.285774  5636 sgd_solver.cpp:105] Iteration 23900, lr = 0.00400267
I0816 15:30:11.839495  5636 solver.cpp:330] Iteration 24000, Testing net (#0)
I0816 15:30:12.042536  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:12.049235  5636 solver.cpp:397]     Test net output #0: loss = 0.0179932 (* 1 = 0.0179932 loss)
I0816 15:30:12.054841  5636 solver.cpp:218] Iteration 24000 (130.024 iter/s, 0.76909s/100 iters), loss = 0.00195054
I0816 15:30:12.054908  5636 solver.cpp:237]     Train net output #0: loss = 0.00195055 (* 1 = 0.00195055 loss)
I0816 15:30:12.054934  5636 sgd_solver.cpp:105] Iteration 24000, lr = 0.00399384
I0816 15:30:12.603165  5636 solver.cpp:218] Iteration 24100 (182.398 iter/s, 0.548252s/100 iters), loss = 0.00251961
I0816 15:30:12.603260  5636 solver.cpp:237]     Train net output #0: loss = 0.00251961 (* 1 = 0.00251961 loss)
I0816 15:30:12.603276  5636 sgd_solver.cpp:105] Iteration 24100, lr = 0.00398505
I0816 15:30:13.160812  5636 solver.cpp:218] Iteration 24200 (179.366 iter/s, 0.557519s/100 iters), loss = 0.00183707
I0816 15:30:13.160889  5636 solver.cpp:237]     Train net output #0: loss = 0.00183707 (* 1 = 0.00183707 loss)
I0816 15:30:13.160905  5636 sgd_solver.cpp:105] Iteration 24200, lr = 0.00397631
I0816 15:30:13.728647  5636 solver.cpp:218] Iteration 24300 (176.133 iter/s, 0.567754s/100 iters), loss = 0.00170547
I0816 15:30:13.728732  5636 solver.cpp:237]     Train net output #0: loss = 0.00170547 (* 1 = 0.00170547 loss)
I0816 15:30:13.728751  5636 sgd_solver.cpp:105] Iteration 24300, lr = 0.00396761
I0816 15:30:14.138542  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:14.299283  5636 solver.cpp:218] Iteration 24400 (175.268 iter/s, 0.570556s/100 iters), loss = 0.000979987
I0816 15:30:14.299347  5636 solver.cpp:237]     Train net output #0: loss = 0.00097999 (* 1 = 0.00097999 loss)
I0816 15:30:14.299363  5636 sgd_solver.cpp:105] Iteration 24400, lr = 0.00395896
I0816 15:30:14.854509  5636 solver.cpp:330] Iteration 24500, Testing net (#0)
I0816 15:30:15.053220  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:15.060194  5636 solver.cpp:397]     Test net output #0: loss = 0.0178122 (* 1 = 0.0178122 loss)
I0816 15:30:15.065289  5636 solver.cpp:218] Iteration 24500 (130.557 iter/s, 0.765948s/100 iters), loss = 0.0013914
I0816 15:30:15.065347  5636 solver.cpp:237]     Train net output #0: loss = 0.0013914 (* 1 = 0.0013914 loss)
I0816 15:30:15.065366  5636 sgd_solver.cpp:105] Iteration 24500, lr = 0.00395035
I0816 15:30:15.609853  5636 solver.cpp:218] Iteration 24600 (183.656 iter/s, 0.544496s/100 iters), loss = 0.0016485
I0816 15:30:15.609979  5636 solver.cpp:237]     Train net output #0: loss = 0.00164851 (* 1 = 0.00164851 loss)
I0816 15:30:15.610020  5636 sgd_solver.cpp:105] Iteration 24600, lr = 0.00394178
I0816 15:30:16.170771  5636 solver.cpp:218] Iteration 24700 (178.332 iter/s, 0.560751s/100 iters), loss = 0.00162606
I0816 15:30:16.170872  5636 solver.cpp:237]     Train net output #0: loss = 0.00162606 (* 1 = 0.00162606 loss)
I0816 15:30:16.170893  5636 sgd_solver.cpp:105] Iteration 24700, lr = 0.00393326
I0816 15:30:16.741163  5636 solver.cpp:218] Iteration 24800 (175.348 iter/s, 0.570296s/100 iters), loss = 0.00255781
I0816 15:30:16.741256  5636 solver.cpp:237]     Train net output #0: loss = 0.00255781 (* 1 = 0.00255781 loss)
I0816 15:30:16.741276  5636 sgd_solver.cpp:105] Iteration 24800, lr = 0.00392478
I0816 15:30:17.307050  5636 solver.cpp:218] Iteration 24900 (176.742 iter/s, 0.565796s/100 iters), loss = 0.00191424
I0816 15:30:17.307137  5636 solver.cpp:237]     Train net output #0: loss = 0.00191424 (* 1 = 0.00191424 loss)
I0816 15:30:17.307153  5636 sgd_solver.cpp:105] Iteration 24900, lr = 0.00391634
I0816 15:30:17.862781  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_25000.caffemodel
I0816 15:30:17.877207  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_25000.solverstate
I0816 15:30:17.880168  5636 solver.cpp:330] Iteration 25000, Testing net (#0)
I0816 15:30:18.076184  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:18.081789  5636 solver.cpp:397]     Test net output #0: loss = 0.0187573 (* 1 = 0.0187573 loss)
I0816 15:30:18.086807  5636 solver.cpp:218] Iteration 25000 (128.258 iter/s, 0.779679s/100 iters), loss = 0.00180522
I0816 15:30:18.086870  5636 solver.cpp:237]     Train net output #0: loss = 0.00180522 (* 1 = 0.00180522 loss)
I0816 15:30:18.086894  5636 sgd_solver.cpp:105] Iteration 25000, lr = 0.00390795
I0816 15:30:18.644973  5636 solver.cpp:218] Iteration 25100 (179.178 iter/s, 0.558105s/100 iters), loss = 0.00361129
I0816 15:30:18.645072  5636 solver.cpp:237]     Train net output #0: loss = 0.00361129 (* 1 = 0.00361129 loss)
I0816 15:30:18.645092  5636 sgd_solver.cpp:105] Iteration 25100, lr = 0.0038996
I0816 15:30:19.203896  5636 solver.cpp:218] Iteration 25200 (178.96 iter/s, 0.558786s/100 iters), loss = 0.00226995
I0816 15:30:19.203997  5636 solver.cpp:237]     Train net output #0: loss = 0.00226995 (* 1 = 0.00226995 loss)
I0816 15:30:19.204020  5636 sgd_solver.cpp:105] Iteration 25200, lr = 0.00389128
I0816 15:30:19.773699  5636 solver.cpp:218] Iteration 25300 (175.534 iter/s, 0.56969s/100 iters), loss = 0.00151318
I0816 15:30:19.773851  5636 solver.cpp:237]     Train net output #0: loss = 0.00151318 (* 1 = 0.00151318 loss)
I0816 15:30:19.773891  5636 sgd_solver.cpp:105] Iteration 25300, lr = 0.00388301
I0816 15:30:19.819660  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:20.342116  5636 solver.cpp:218] Iteration 25400 (175.973 iter/s, 0.56827s/100 iters), loss = 0.000952628
I0816 15:30:20.342255  5636 solver.cpp:237]     Train net output #0: loss = 0.000952631 (* 1 = 0.000952631 loss)
I0816 15:30:20.342283  5636 sgd_solver.cpp:105] Iteration 25400, lr = 0.00387478
I0816 15:30:20.896338  5636 solver.cpp:330] Iteration 25500, Testing net (#0)
I0816 15:30:21.100250  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:21.103281  5636 solver.cpp:397]     Test net output #0: loss = 0.0189392 (* 1 = 0.0189392 loss)
I0816 15:30:21.108873  5636 solver.cpp:218] Iteration 25500 (130.441 iter/s, 0.766631s/100 iters), loss = 0.000767724
I0816 15:30:21.108925  5636 solver.cpp:237]     Train net output #0: loss = 0.000767727 (* 1 = 0.000767727 loss)
I0816 15:30:21.108948  5636 sgd_solver.cpp:105] Iteration 25500, lr = 0.0038666
I0816 15:30:21.659117  5636 solver.cpp:218] Iteration 25600 (181.777 iter/s, 0.550125s/100 iters), loss = 0.000935795
I0816 15:30:21.659287  5636 solver.cpp:237]     Train net output #0: loss = 0.000935798 (* 1 = 0.000935798 loss)
I0816 15:30:21.659312  5636 sgd_solver.cpp:105] Iteration 25600, lr = 0.00385845
I0816 15:30:22.228463  5636 solver.cpp:218] Iteration 25700 (175.708 iter/s, 0.569125s/100 iters), loss = 0.00189494
I0816 15:30:22.228576  5636 solver.cpp:237]     Train net output #0: loss = 0.00189494 (* 1 = 0.00189494 loss)
I0816 15:30:22.228596  5636 sgd_solver.cpp:105] Iteration 25700, lr = 0.00385034
I0816 15:30:22.795559  5636 solver.cpp:218] Iteration 25800 (176.372 iter/s, 0.566983s/100 iters), loss = 0.00334841
I0816 15:30:22.795648  5636 solver.cpp:237]     Train net output #0: loss = 0.00334841 (* 1 = 0.00334841 loss)
I0816 15:30:22.795665  5636 sgd_solver.cpp:105] Iteration 25800, lr = 0.00384227
I0816 15:30:23.360327  5636 solver.cpp:218] Iteration 25900 (177.094 iter/s, 0.564672s/100 iters), loss = 0.000578986
I0816 15:30:23.360430  5636 solver.cpp:237]     Train net output #0: loss = 0.000578989 (* 1 = 0.000578989 loss)
I0816 15:30:23.360445  5636 sgd_solver.cpp:105] Iteration 25900, lr = 0.00383424
I0816 15:30:23.919819  5636 solver.cpp:330] Iteration 26000, Testing net (#0)
I0816 15:30:24.121016  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:24.126780  5636 solver.cpp:397]     Test net output #0: loss = 0.0181604 (* 1 = 0.0181604 loss)
I0816 15:30:24.132321  5636 solver.cpp:218] Iteration 26000 (129.55 iter/s, 0.771901s/100 iters), loss = 0.00238717
I0816 15:30:24.132371  5636 solver.cpp:237]     Train net output #0: loss = 0.00238717 (* 1 = 0.00238717 loss)
I0816 15:30:24.132390  5636 sgd_solver.cpp:105] Iteration 26000, lr = 0.00382625
I0816 15:30:24.677685  5636 solver.cpp:218] Iteration 26100 (183.382 iter/s, 0.545309s/100 iters), loss = 0.00137407
I0816 15:30:24.677757  5636 solver.cpp:237]     Train net output #0: loss = 0.00137408 (* 1 = 0.00137408 loss)
I0816 15:30:24.677772  5636 sgd_solver.cpp:105] Iteration 26100, lr = 0.0038183
I0816 15:30:25.229382  5636 solver.cpp:218] Iteration 26200 (181.294 iter/s, 0.551589s/100 iters), loss = 0.00166139
I0816 15:30:25.229455  5636 solver.cpp:237]     Train net output #0: loss = 0.00166139 (* 1 = 0.00166139 loss)
I0816 15:30:25.229470  5636 sgd_solver.cpp:105] Iteration 26200, lr = 0.00381038
I0816 15:30:25.485960  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:25.798238  5636 solver.cpp:218] Iteration 26300 (175.814 iter/s, 0.568784s/100 iters), loss = 0.00178621
I0816 15:30:25.798300  5636 solver.cpp:237]     Train net output #0: loss = 0.00178621 (* 1 = 0.00178621 loss)
I0816 15:30:25.798316  5636 sgd_solver.cpp:105] Iteration 26300, lr = 0.00380251
I0816 15:30:26.360164  5636 solver.cpp:218] Iteration 26400 (177.978 iter/s, 0.561866s/100 iters), loss = 0.00118242
I0816 15:30:26.360226  5636 solver.cpp:237]     Train net output #0: loss = 0.00118242 (* 1 = 0.00118242 loss)
I0816 15:30:26.360241  5636 sgd_solver.cpp:105] Iteration 26400, lr = 0.00379467
I0816 15:30:26.918485  5636 solver.cpp:330] Iteration 26500, Testing net (#0)
I0816 15:30:27.119889  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:27.125622  5636 solver.cpp:397]     Test net output #0: loss = 0.018599 (* 1 = 0.018599 loss)
I0816 15:30:27.131212  5636 solver.cpp:218] Iteration 26500 (129.703 iter/s, 0.770991s/100 iters), loss = 0.00137161
I0816 15:30:27.131261  5636 solver.cpp:237]     Train net output #0: loss = 0.00137162 (* 1 = 0.00137162 loss)
I0816 15:30:27.131280  5636 sgd_solver.cpp:105] Iteration 26500, lr = 0.00378687
I0816 15:30:27.684229  5636 solver.cpp:218] Iteration 26600 (180.845 iter/s, 0.552961s/100 iters), loss = 0.00178242
I0816 15:30:27.684311  5636 solver.cpp:237]     Train net output #0: loss = 0.00178242 (* 1 = 0.00178242 loss)
I0816 15:30:27.684327  5636 sgd_solver.cpp:105] Iteration 26600, lr = 0.00377911
I0816 15:30:28.236932  5636 solver.cpp:218] Iteration 26700 (180.968 iter/s, 0.552585s/100 iters), loss = 0.00139688
I0816 15:30:28.236994  5636 solver.cpp:237]     Train net output #0: loss = 0.00139688 (* 1 = 0.00139688 loss)
I0816 15:30:28.237025  5636 sgd_solver.cpp:105] Iteration 26700, lr = 0.00377138
I0816 15:30:28.806699  5636 solver.cpp:218] Iteration 26800 (175.531 iter/s, 0.5697s/100 iters), loss = 0.000649195
I0816 15:30:28.806800  5636 solver.cpp:237]     Train net output #0: loss = 0.000649199 (* 1 = 0.000649199 loss)
I0816 15:30:28.806818  5636 sgd_solver.cpp:105] Iteration 26800, lr = 0.00376369
I0816 15:30:29.368007  5636 solver.cpp:218] Iteration 26900 (178.189 iter/s, 0.561203s/100 iters), loss = 0.000915953
I0816 15:30:29.368101  5636 solver.cpp:237]     Train net output #0: loss = 0.000915956 (* 1 = 0.000915956 loss)
I0816 15:30:29.368125  5636 sgd_solver.cpp:105] Iteration 26900, lr = 0.00375604
I0816 15:30:29.925806  5636 solver.cpp:330] Iteration 27000, Testing net (#0)
I0816 15:30:30.128275  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:30.134642  5636 solver.cpp:397]     Test net output #0: loss = 0.0181875 (* 1 = 0.0181875 loss)
I0816 15:30:30.139600  5636 solver.cpp:218] Iteration 27000 (129.617 iter/s, 0.771506s/100 iters), loss = 0.00481104
I0816 15:30:30.139648  5636 solver.cpp:237]     Train net output #0: loss = 0.00481105 (* 1 = 0.00481105 loss)
I0816 15:30:30.139668  5636 sgd_solver.cpp:105] Iteration 27000, lr = 0.00374842
I0816 15:30:30.679704  5636 solver.cpp:218] Iteration 27100 (185.167 iter/s, 0.540053s/100 iters), loss = 0.00201986
I0816 15:30:30.679781  5636 solver.cpp:237]     Train net output #0: loss = 0.00201986 (* 1 = 0.00201986 loss)
I0816 15:30:30.679796  5636 sgd_solver.cpp:105] Iteration 27100, lr = 0.00374084
I0816 15:30:31.142585  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:31.231601  5636 solver.cpp:218] Iteration 27200 (181.231 iter/s, 0.551781s/100 iters), loss = 0.000378509
I0816 15:30:31.231657  5636 solver.cpp:237]     Train net output #0: loss = 0.000378512 (* 1 = 0.000378512 loss)
I0816 15:30:31.231672  5636 sgd_solver.cpp:105] Iteration 27200, lr = 0.0037333
I0816 15:30:31.800457  5636 solver.cpp:218] Iteration 27300 (175.809 iter/s, 0.568798s/100 iters), loss = 0.00128944
I0816 15:30:31.800547  5636 solver.cpp:237]     Train net output #0: loss = 0.00128944 (* 1 = 0.00128944 loss)
I0816 15:30:31.800562  5636 sgd_solver.cpp:105] Iteration 27300, lr = 0.00372579
I0816 15:30:32.320705  5636 solver.cpp:218] Iteration 27400 (192.249 iter/s, 0.520159s/100 iters), loss = 0.000208814
I0816 15:30:32.320775  5636 solver.cpp:237]     Train net output #0: loss = 0.000208817 (* 1 = 0.000208817 loss)
I0816 15:30:32.320794  5636 sgd_solver.cpp:105] Iteration 27400, lr = 0.00371832
I0816 15:30:32.874562  5636 solver.cpp:330] Iteration 27500, Testing net (#0)
I0816 15:30:33.074146  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:33.080629  5636 solver.cpp:397]     Test net output #0: loss = 0.0185166 (* 1 = 0.0185166 loss)
I0816 15:30:33.086544  5636 solver.cpp:218] Iteration 27500 (130.586 iter/s, 0.765779s/100 iters), loss = 0.0009692
I0816 15:30:33.086588  5636 solver.cpp:237]     Train net output #0: loss = 0.000969202 (* 1 = 0.000969202 loss)
I0816 15:30:33.086633  5636 sgd_solver.cpp:105] Iteration 27500, lr = 0.00371088
I0816 15:30:33.636185  5636 solver.cpp:218] Iteration 27600 (181.965 iter/s, 0.549556s/100 iters), loss = 0.000772572
I0816 15:30:33.636270  5636 solver.cpp:237]     Train net output #0: loss = 0.000772575 (* 1 = 0.000772575 loss)
I0816 15:30:33.636286  5636 sgd_solver.cpp:105] Iteration 27600, lr = 0.00370347
I0816 15:30:34.189960  5636 solver.cpp:218] Iteration 27700 (180.619 iter/s, 0.553652s/100 iters), loss = 0.00170637
I0816 15:30:34.190047  5636 solver.cpp:237]     Train net output #0: loss = 0.00170637 (* 1 = 0.00170637 loss)
I0816 15:30:34.190066  5636 sgd_solver.cpp:105] Iteration 27700, lr = 0.0036961
I0816 15:30:34.756767  5636 solver.cpp:218] Iteration 27800 (176.456 iter/s, 0.566715s/100 iters), loss = 0.000706467
I0816 15:30:34.756871  5636 solver.cpp:237]     Train net output #0: loss = 0.00070647 (* 1 = 0.00070647 loss)
I0816 15:30:34.756907  5636 sgd_solver.cpp:105] Iteration 27800, lr = 0.00368877
I0816 15:30:35.330077  5636 solver.cpp:218] Iteration 27900 (174.458 iter/s, 0.573204s/100 iters), loss = 0.00100252
I0816 15:30:35.330178  5636 solver.cpp:237]     Train net output #0: loss = 0.00100252 (* 1 = 0.00100252 loss)
I0816 15:30:35.330193  5636 sgd_solver.cpp:105] Iteration 27900, lr = 0.00368146
I0816 15:30:35.892163  5636 solver.cpp:330] Iteration 28000, Testing net (#0)
I0816 15:30:36.098057  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:36.104331  5636 solver.cpp:397]     Test net output #0: loss = 0.0184304 (* 1 = 0.0184304 loss)
I0816 15:30:36.109428  5636 solver.cpp:218] Iteration 28000 (128.327 iter/s, 0.779259s/100 iters), loss = 0.0010135
I0816 15:30:36.109484  5636 solver.cpp:237]     Train net output #0: loss = 0.0010135 (* 1 = 0.0010135 loss)
I0816 15:30:36.109504  5636 sgd_solver.cpp:105] Iteration 28000, lr = 0.0036742
I0816 15:30:36.659621  5636 solver.cpp:218] Iteration 28100 (181.776 iter/s, 0.550129s/100 iters), loss = 0.00190823
I0816 15:30:36.659715  5636 solver.cpp:237]     Train net output #0: loss = 0.00190823 (* 1 = 0.00190823 loss)
I0816 15:30:36.659731  5636 sgd_solver.cpp:105] Iteration 28100, lr = 0.00366696
I0816 15:30:36.778723  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:37.216272  5636 solver.cpp:218] Iteration 28200 (179.705 iter/s, 0.556468s/100 iters), loss = 0.00145278
I0816 15:30:37.216351  5636 solver.cpp:237]     Train net output #0: loss = 0.00145278 (* 1 = 0.00145278 loss)
I0816 15:30:37.216365  5636 sgd_solver.cpp:105] Iteration 28200, lr = 0.00365976
I0816 15:30:37.788905  5636 solver.cpp:218] Iteration 28300 (174.657 iter/s, 0.57255s/100 iters), loss = 0.00102859
I0816 15:30:37.788995  5636 solver.cpp:237]     Train net output #0: loss = 0.0010286 (* 1 = 0.0010286 loss)
I0816 15:30:37.789011  5636 sgd_solver.cpp:105] Iteration 28300, lr = 0.00365259
I0816 15:30:38.353688  5636 solver.cpp:218] Iteration 28400 (177.087 iter/s, 0.564694s/100 iters), loss = 0.00198099
I0816 15:30:38.353752  5636 solver.cpp:237]     Train net output #0: loss = 0.00198099 (* 1 = 0.00198099 loss)
I0816 15:30:38.353767  5636 sgd_solver.cpp:105] Iteration 28400, lr = 0.00364545
I0816 15:30:38.908764  5636 solver.cpp:330] Iteration 28500, Testing net (#0)
I0816 15:30:39.109890  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:39.116204  5636 solver.cpp:397]     Test net output #0: loss = 0.0189099 (* 1 = 0.0189099 loss)
I0816 15:30:39.121294  5636 solver.cpp:218] Iteration 28500 (130.285 iter/s, 0.767547s/100 iters), loss = 0.00208631
I0816 15:30:39.121348  5636 solver.cpp:237]     Train net output #0: loss = 0.00208631 (* 1 = 0.00208631 loss)
I0816 15:30:39.121367  5636 sgd_solver.cpp:105] Iteration 28500, lr = 0.00363835
I0816 15:30:39.671437  5636 solver.cpp:218] Iteration 28600 (181.79 iter/s, 0.550085s/100 iters), loss = 0.000993339
I0816 15:30:39.671527  5636 solver.cpp:237]     Train net output #0: loss = 0.000993343 (* 1 = 0.000993343 loss)
I0816 15:30:39.671545  5636 sgd_solver.cpp:105] Iteration 28600, lr = 0.00363128
I0816 15:30:40.228310  5636 solver.cpp:218] Iteration 28700 (179.616 iter/s, 0.556742s/100 iters), loss = 0.00198796
I0816 15:30:40.228395  5636 solver.cpp:237]     Train net output #0: loss = 0.00198796 (* 1 = 0.00198796 loss)
I0816 15:30:40.228411  5636 sgd_solver.cpp:105] Iteration 28700, lr = 0.00362424
I0816 15:30:40.789621  5636 solver.cpp:218] Iteration 28800 (178.182 iter/s, 0.561223s/100 iters), loss = 0.000457652
I0816 15:30:40.789710  5636 solver.cpp:237]     Train net output #0: loss = 0.000457657 (* 1 = 0.000457657 loss)
I0816 15:30:40.789726  5636 sgd_solver.cpp:105] Iteration 28800, lr = 0.00361723
I0816 15:30:41.350788  5636 solver.cpp:218] Iteration 28900 (178.228 iter/s, 0.56108s/100 iters), loss = 0.00194438
I0816 15:30:41.350867  5636 solver.cpp:237]     Train net output #0: loss = 0.00194438 (* 1 = 0.00194438 loss)
I0816 15:30:41.350884  5636 sgd_solver.cpp:105] Iteration 28900, lr = 0.00361025
I0816 15:30:41.910056  5636 solver.cpp:330] Iteration 29000, Testing net (#0)
I0816 15:30:42.108937  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:42.115926  5636 solver.cpp:397]     Test net output #0: loss = 0.018379 (* 1 = 0.018379 loss)
I0816 15:30:42.121016  5636 solver.cpp:218] Iteration 29000 (129.843 iter/s, 0.770161s/100 iters), loss = 0.00358138
I0816 15:30:42.121068  5636 solver.cpp:237]     Train net output #0: loss = 0.00358138 (* 1 = 0.00358138 loss)
I0816 15:30:42.121088  5636 sgd_solver.cpp:105] Iteration 29000, lr = 0.00360331
I0816 15:30:42.428249  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:42.662147  5636 solver.cpp:218] Iteration 29100 (184.815 iter/s, 0.541083s/100 iters), loss = 0.00131898
I0816 15:30:42.662230  5636 solver.cpp:237]     Train net output #0: loss = 0.00131899 (* 1 = 0.00131899 loss)
I0816 15:30:42.662246  5636 sgd_solver.cpp:105] Iteration 29100, lr = 0.0035964
I0816 15:30:43.249833  5636 solver.cpp:218] Iteration 29200 (170.193 iter/s, 0.587567s/100 iters), loss = 0.00205626
I0816 15:30:43.249897  5636 solver.cpp:237]     Train net output #0: loss = 0.00205626 (* 1 = 0.00205626 loss)
I0816 15:30:43.249912  5636 sgd_solver.cpp:105] Iteration 29200, lr = 0.00358951
I0816 15:30:43.796039  5636 solver.cpp:218] Iteration 29300 (183.114 iter/s, 0.546107s/100 iters), loss = 0.00353665
I0816 15:30:43.796125  5636 solver.cpp:237]     Train net output #0: loss = 0.00353666 (* 1 = 0.00353666 loss)
I0816 15:30:43.796141  5636 sgd_solver.cpp:105] Iteration 29300, lr = 0.00358266
I0816 15:30:44.365772  5636 solver.cpp:218] Iteration 29400 (175.548 iter/s, 0.569646s/100 iters), loss = 0.00178841
I0816 15:30:44.366127  5636 solver.cpp:237]     Train net output #0: loss = 0.00178842 (* 1 = 0.00178842 loss)
I0816 15:30:44.366158  5636 sgd_solver.cpp:105] Iteration 29400, lr = 0.00357584
I0816 15:30:44.929003  5636 solver.cpp:330] Iteration 29500, Testing net (#0)
I0816 15:30:45.130951  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:45.136580  5636 solver.cpp:397]     Test net output #0: loss = 0.018462 (* 1 = 0.018462 loss)
I0816 15:30:45.141757  5636 solver.cpp:218] Iteration 29500 (128.926 iter/s, 0.77564s/100 iters), loss = 0.000726423
I0816 15:30:45.141800  5636 solver.cpp:237]     Train net output #0: loss = 0.000726427 (* 1 = 0.000726427 loss)
I0816 15:30:45.141820  5636 sgd_solver.cpp:105] Iteration 29500, lr = 0.00356905
I0816 15:30:45.695705  5636 solver.cpp:218] Iteration 29600 (180.539 iter/s, 0.553898s/100 iters), loss = 0.00109628
I0816 15:30:45.695797  5636 solver.cpp:237]     Train net output #0: loss = 0.00109628 (* 1 = 0.00109628 loss)
I0816 15:30:45.695813  5636 sgd_solver.cpp:105] Iteration 29600, lr = 0.00356228
I0816 15:30:46.262836  5636 solver.cpp:218] Iteration 29700 (176.366 iter/s, 0.567001s/100 iters), loss = 0.00128738
I0816 15:30:46.262917  5636 solver.cpp:237]     Train net output #0: loss = 0.00128739 (* 1 = 0.00128739 loss)
I0816 15:30:46.262933  5636 sgd_solver.cpp:105] Iteration 29700, lr = 0.00355555
I0816 15:30:46.831094  5636 solver.cpp:218] Iteration 29800 (176.002 iter/s, 0.568176s/100 iters), loss = 0.00273491
I0816 15:30:46.831166  5636 solver.cpp:237]     Train net output #0: loss = 0.00273492 (* 1 = 0.00273492 loss)
I0816 15:30:46.831182  5636 sgd_solver.cpp:105] Iteration 29800, lr = 0.00354885
I0816 15:30:47.395717  5636 solver.cpp:218] Iteration 29900 (177.132 iter/s, 0.564552s/100 iters), loss = 0.00194702
I0816 15:30:47.395792  5636 solver.cpp:237]     Train net output #0: loss = 0.00194703 (* 1 = 0.00194703 loss)
I0816 15:30:47.395807  5636 sgd_solver.cpp:105] Iteration 29900, lr = 0.00354218
I0816 15:30:47.927193  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:47.944358  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_30000.caffemodel
I0816 15:30:47.958410  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_30000.solverstate
I0816 15:30:47.961433  5636 solver.cpp:330] Iteration 30000, Testing net (#0)
I0816 15:30:48.160975  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:48.167074  5636 solver.cpp:397]     Test net output #0: loss = 0.019399 (* 1 = 0.019399 loss)
I0816 15:30:48.172155  5636 solver.cpp:218] Iteration 30000 (128.805 iter/s, 0.77637s/100 iters), loss = 0.00108951
I0816 15:30:48.172204  5636 solver.cpp:237]     Train net output #0: loss = 0.00108951 (* 1 = 0.00108951 loss)
I0816 15:30:48.172222  5636 sgd_solver.cpp:105] Iteration 30000, lr = 0.00353553
I0816 15:30:48.714751  5636 solver.cpp:218] Iteration 30100 (184.363 iter/s, 0.542407s/100 iters), loss = 0.00169216
I0816 15:30:48.714814  5636 solver.cpp:237]     Train net output #0: loss = 0.00169216 (* 1 = 0.00169216 loss)
I0816 15:30:48.714830  5636 sgd_solver.cpp:105] Iteration 30100, lr = 0.00352892
I0816 15:30:49.269498  5636 solver.cpp:218] Iteration 30200 (180.294 iter/s, 0.554649s/100 iters), loss = 0.00111113
I0816 15:30:49.269573  5636 solver.cpp:237]     Train net output #0: loss = 0.00111113 (* 1 = 0.00111113 loss)
I0816 15:30:49.269589  5636 sgd_solver.cpp:105] Iteration 30200, lr = 0.00352233
I0816 15:30:49.850519  5636 solver.cpp:218] Iteration 30300 (172.132 iter/s, 0.580949s/100 iters), loss = 0.00111939
I0816 15:30:49.850589  5636 solver.cpp:237]     Train net output #0: loss = 0.0011194 (* 1 = 0.0011194 loss)
I0816 15:30:49.850605  5636 sgd_solver.cpp:105] Iteration 30300, lr = 0.00351578
I0816 15:30:50.415963  5636 solver.cpp:218] Iteration 30400 (176.873 iter/s, 0.565377s/100 iters), loss = 0.00142953
I0816 15:30:50.416028  5636 solver.cpp:237]     Train net output #0: loss = 0.00142954 (* 1 = 0.00142954 loss)
I0816 15:30:50.416064  5636 sgd_solver.cpp:105] Iteration 30400, lr = 0.00350925
I0816 15:30:50.971168  5636 solver.cpp:330] Iteration 30500, Testing net (#0)
I0816 15:30:51.172901  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:51.178899  5636 solver.cpp:397]     Test net output #0: loss = 0.0180125 (* 1 = 0.0180125 loss)
I0816 15:30:51.184260  5636 solver.cpp:218] Iteration 30500 (130.168 iter/s, 0.768238s/100 iters), loss = 0.00101549
I0816 15:30:51.184319  5636 solver.cpp:237]     Train net output #0: loss = 0.00101549 (* 1 = 0.00101549 loss)
I0816 15:30:51.184340  5636 sgd_solver.cpp:105] Iteration 30500, lr = 0.00350275
I0816 15:30:51.722964  5636 solver.cpp:218] Iteration 30600 (185.653 iter/s, 0.53864s/100 iters), loss = 0.000972754
I0816 15:30:51.723050  5636 solver.cpp:237]     Train net output #0: loss = 0.000972758 (* 1 = 0.000972758 loss)
I0816 15:30:51.723069  5636 sgd_solver.cpp:105] Iteration 30600, lr = 0.00349627
I0816 15:30:52.277362  5636 solver.cpp:218] Iteration 30700 (180.414 iter/s, 0.554281s/100 iters), loss = 0.00158467
I0816 15:30:52.277437  5636 solver.cpp:237]     Train net output #0: loss = 0.00158467 (* 1 = 0.00158467 loss)
I0816 15:30:52.277456  5636 sgd_solver.cpp:105] Iteration 30700, lr = 0.00348983
I0816 15:30:52.840293  5636 solver.cpp:218] Iteration 30800 (177.665 iter/s, 0.562858s/100 iters), loss = 0.00104668
I0816 15:30:52.840374  5636 solver.cpp:237]     Train net output #0: loss = 0.00104668 (* 1 = 0.00104668 loss)
I0816 15:30:52.840394  5636 sgd_solver.cpp:105] Iteration 30800, lr = 0.00348341
I0816 15:30:53.407933  5636 solver.cpp:218] Iteration 30900 (176.193 iter/s, 0.56756s/100 iters), loss = 0.00143656
I0816 15:30:53.408017  5636 solver.cpp:237]     Train net output #0: loss = 0.00143657 (* 1 = 0.00143657 loss)
I0816 15:30:53.408036  5636 sgd_solver.cpp:105] Iteration 30900, lr = 0.00347702
I0816 15:30:53.598042  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:53.968549  5636 solver.cpp:330] Iteration 31000, Testing net (#0)
I0816 15:30:54.175184  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:54.177224  5636 solver.cpp:397]     Test net output #0: loss = 0.0186634 (* 1 = 0.0186634 loss)
I0816 15:30:54.183452  5636 solver.cpp:218] Iteration 31000 (128.958 iter/s, 0.775443s/100 iters), loss = 0.000626299
I0816 15:30:54.183521  5636 solver.cpp:237]     Train net output #0: loss = 0.000626303 (* 1 = 0.000626303 loss)
I0816 15:30:54.183547  5636 sgd_solver.cpp:105] Iteration 31000, lr = 0.00347066
I0816 15:30:54.724409  5636 solver.cpp:218] Iteration 31100 (184.883 iter/s, 0.540882s/100 iters), loss = 0.000669197
I0816 15:30:54.724505  5636 solver.cpp:237]     Train net output #0: loss = 0.000669201 (* 1 = 0.000669201 loss)
I0816 15:30:54.724524  5636 sgd_solver.cpp:105] Iteration 31100, lr = 0.00346433
I0816 15:30:55.277832  5636 solver.cpp:218] Iteration 31200 (180.735 iter/s, 0.553297s/100 iters), loss = 0.000599233
I0816 15:30:55.277906  5636 solver.cpp:237]     Train net output #0: loss = 0.000599237 (* 1 = 0.000599237 loss)
I0816 15:30:55.277925  5636 sgd_solver.cpp:105] Iteration 31200, lr = 0.00345802
I0816 15:30:55.842110  5636 solver.cpp:218] Iteration 31300 (177.24 iter/s, 0.564206s/100 iters), loss = 0.00128451
I0816 15:30:55.842187  5636 solver.cpp:237]     Train net output #0: loss = 0.00128452 (* 1 = 0.00128452 loss)
I0816 15:30:55.842202  5636 sgd_solver.cpp:105] Iteration 31300, lr = 0.00345174
I0816 15:30:56.423271  5636 solver.cpp:218] Iteration 31400 (172.092 iter/s, 0.581086s/100 iters), loss = 0.000486442
I0816 15:30:56.423334  5636 solver.cpp:237]     Train net output #0: loss = 0.000486446 (* 1 = 0.000486446 loss)
I0816 15:30:56.423354  5636 sgd_solver.cpp:105] Iteration 31400, lr = 0.00344548
I0816 15:30:56.976547  5636 solver.cpp:330] Iteration 31500, Testing net (#0)
I0816 15:30:57.175573  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:57.183174  5636 solver.cpp:397]     Test net output #0: loss = 0.0185269 (* 1 = 0.0185269 loss)
I0816 15:30:57.188082  5636 solver.cpp:218] Iteration 31500 (130.761 iter/s, 0.764757s/100 iters), loss = 0.00148296
I0816 15:30:57.188141  5636 solver.cpp:237]     Train net output #0: loss = 0.00148297 (* 1 = 0.00148297 loss)
I0816 15:30:57.188161  5636 sgd_solver.cpp:105] Iteration 31500, lr = 0.00343925
I0816 15:30:57.728231  5636 solver.cpp:218] Iteration 31600 (185.3 iter/s, 0.539665s/100 iters), loss = 0.00218855
I0816 15:30:57.728314  5636 solver.cpp:237]     Train net output #0: loss = 0.00218856 (* 1 = 0.00218856 loss)
I0816 15:30:57.728330  5636 sgd_solver.cpp:105] Iteration 31600, lr = 0.00343305
I0816 15:30:58.281643  5636 solver.cpp:218] Iteration 31700 (180.738 iter/s, 0.553287s/100 iters), loss = 0.000943574
I0816 15:30:58.281720  5636 solver.cpp:237]     Train net output #0: loss = 0.000943578 (* 1 = 0.000943578 loss)
I0816 15:30:58.281735  5636 sgd_solver.cpp:105] Iteration 31700, lr = 0.00342687
I0816 15:30:58.842020  5636 solver.cpp:218] Iteration 31800 (178.477 iter/s, 0.560297s/100 iters), loss = 0.0011418
I0816 15:30:58.842094  5636 solver.cpp:237]     Train net output #0: loss = 0.00114181 (* 1 = 0.00114181 loss)
I0816 15:30:58.842110  5636 sgd_solver.cpp:105] Iteration 31800, lr = 0.00342072
I0816 15:30:59.239969  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:30:59.400997  5636 solver.cpp:218] Iteration 31900 (178.921 iter/s, 0.558905s/100 iters), loss = 0.000487502
I0816 15:30:59.401055  5636 solver.cpp:237]     Train net output #0: loss = 0.000487507 (* 1 = 0.000487507 loss)
I0816 15:30:59.401072  5636 sgd_solver.cpp:105] Iteration 31900, lr = 0.0034146
I0816 15:30:59.953819  5636 solver.cpp:330] Iteration 32000, Testing net (#0)
I0816 15:31:00.149577  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:00.157088  5636 solver.cpp:397]     Test net output #0: loss = 0.0184649 (* 1 = 0.0184649 loss)
I0816 15:31:00.162952  5636 solver.cpp:218] Iteration 32000 (131.25 iter/s, 0.761905s/100 iters), loss = 0.000968927
I0816 15:31:00.163010  5636 solver.cpp:237]     Train net output #0: loss = 0.000968931 (* 1 = 0.000968931 loss)
I0816 15:31:00.163030  5636 sgd_solver.cpp:105] Iteration 32000, lr = 0.0034085
I0816 15:31:00.712481  5636 solver.cpp:218] Iteration 32100 (182.002 iter/s, 0.549444s/100 iters), loss = 0.000817583
I0816 15:31:00.712589  5636 solver.cpp:237]     Train net output #0: loss = 0.000817587 (* 1 = 0.000817587 loss)
I0816 15:31:00.712605  5636 sgd_solver.cpp:105] Iteration 32100, lr = 0.00340242
I0816 15:31:01.270275  5636 solver.cpp:218] Iteration 32200 (179.322 iter/s, 0.557656s/100 iters), loss = 0.00109673
I0816 15:31:01.270352  5636 solver.cpp:237]     Train net output #0: loss = 0.00109673 (* 1 = 0.00109673 loss)
I0816 15:31:01.270400  5636 sgd_solver.cpp:105] Iteration 32200, lr = 0.00339637
I0816 15:31:01.844692  5636 solver.cpp:218] Iteration 32300 (174.113 iter/s, 0.57434s/100 iters), loss = 0.00141631
I0816 15:31:01.844775  5636 solver.cpp:237]     Train net output #0: loss = 0.00141632 (* 1 = 0.00141632 loss)
I0816 15:31:01.844791  5636 sgd_solver.cpp:105] Iteration 32300, lr = 0.00339035
I0816 15:31:02.424641  5636 solver.cpp:218] Iteration 32400 (172.453 iter/s, 0.579869s/100 iters), loss = 0.00106358
I0816 15:31:02.424713  5636 solver.cpp:237]     Train net output #0: loss = 0.00106358 (* 1 = 0.00106358 loss)
I0816 15:31:02.424729  5636 sgd_solver.cpp:105] Iteration 32400, lr = 0.00338435
I0816 15:31:02.983851  5636 solver.cpp:330] Iteration 32500, Testing net (#0)
I0816 15:31:03.183590  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:03.190397  5636 solver.cpp:397]     Test net output #0: loss = 0.0190147 (* 1 = 0.0190147 loss)
I0816 15:31:03.195690  5636 solver.cpp:218] Iteration 32500 (129.704 iter/s, 0.770985s/100 iters), loss = 0.00136951
I0816 15:31:03.195745  5636 solver.cpp:237]     Train net output #0: loss = 0.00136952 (* 1 = 0.00136952 loss)
I0816 15:31:03.195765  5636 sgd_solver.cpp:105] Iteration 32500, lr = 0.00337838
I0816 15:31:03.738181  5636 solver.cpp:218] Iteration 32600 (184.351 iter/s, 0.542443s/100 iters), loss = 0.00209738
I0816 15:31:03.738291  5636 solver.cpp:237]     Train net output #0: loss = 0.00209738 (* 1 = 0.00209738 loss)
I0816 15:31:03.738307  5636 sgd_solver.cpp:105] Iteration 32600, lr = 0.00337243
I0816 15:31:04.293889  5636 solver.cpp:218] Iteration 32700 (180 iter/s, 0.555556s/100 iters), loss = 0.00142811
I0816 15:31:04.293963  5636 solver.cpp:237]     Train net output #0: loss = 0.00142811 (* 1 = 0.00142811 loss)
I0816 15:31:04.293979  5636 sgd_solver.cpp:105] Iteration 32700, lr = 0.0033665
I0816 15:31:04.855134  5636 solver.cpp:218] Iteration 32800 (178.199 iter/s, 0.56117s/100 iters), loss = 0.00127431
I0816 15:31:04.855221  5636 solver.cpp:237]     Train net output #0: loss = 0.00127432 (* 1 = 0.00127432 loss)
I0816 15:31:04.855235  5636 sgd_solver.cpp:105] Iteration 32800, lr = 0.0033606
I0816 15:31:04.898072  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:05.420373  5636 solver.cpp:218] Iteration 32900 (176.942 iter/s, 0.565156s/100 iters), loss = 0.000441375
I0816 15:31:05.420454  5636 solver.cpp:237]     Train net output #0: loss = 0.00044138 (* 1 = 0.00044138 loss)
I0816 15:31:05.420470  5636 sgd_solver.cpp:105] Iteration 32900, lr = 0.00335473
I0816 15:31:05.978243  5636 solver.cpp:330] Iteration 33000, Testing net (#0)
I0816 15:31:06.180166  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:06.185709  5636 solver.cpp:397]     Test net output #0: loss = 0.0192124 (* 1 = 0.0192124 loss)
I0816 15:31:06.190770  5636 solver.cpp:218] Iteration 33000 (129.815 iter/s, 0.770325s/100 iters), loss = 0.000355141
I0816 15:31:06.190825  5636 solver.cpp:237]     Train net output #0: loss = 0.000355146 (* 1 = 0.000355146 loss)
I0816 15:31:06.190845  5636 sgd_solver.cpp:105] Iteration 33000, lr = 0.00334887
I0816 15:31:06.729676  5636 solver.cpp:218] Iteration 33100 (185.579 iter/s, 0.538854s/100 iters), loss = 0.000766289
I0816 15:31:06.729768  5636 solver.cpp:237]     Train net output #0: loss = 0.000766295 (* 1 = 0.000766295 loss)
I0816 15:31:06.729784  5636 sgd_solver.cpp:105] Iteration 33100, lr = 0.00334304
I0816 15:31:07.279001  5636 solver.cpp:218] Iteration 33200 (182.088 iter/s, 0.549185s/100 iters), loss = 0.00140605
I0816 15:31:07.279109  5636 solver.cpp:237]     Train net output #0: loss = 0.00140605 (* 1 = 0.00140605 loss)
I0816 15:31:07.279142  5636 sgd_solver.cpp:105] Iteration 33200, lr = 0.00333724
I0816 15:31:07.842574  5636 solver.cpp:218] Iteration 33300 (177.473 iter/s, 0.563465s/100 iters), loss = 0.00208661
I0816 15:31:07.842658  5636 solver.cpp:237]     Train net output #0: loss = 0.00208661 (* 1 = 0.00208661 loss)
I0816 15:31:07.842674  5636 sgd_solver.cpp:105] Iteration 33300, lr = 0.00333146
I0816 15:31:08.412777  5636 solver.cpp:218] Iteration 33400 (175.402 iter/s, 0.57012s/100 iters), loss = 0.000336186
I0816 15:31:08.412853  5636 solver.cpp:237]     Train net output #0: loss = 0.000336191 (* 1 = 0.000336191 loss)
I0816 15:31:08.412869  5636 sgd_solver.cpp:105] Iteration 33400, lr = 0.0033257
I0816 15:31:08.972038  5636 solver.cpp:330] Iteration 33500, Testing net (#0)
I0816 15:31:09.172462  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:09.178318  5636 solver.cpp:397]     Test net output #0: loss = 0.0186116 (* 1 = 0.0186116 loss)
I0816 15:31:09.183866  5636 solver.cpp:218] Iteration 33500 (129.698 iter/s, 0.77102s/100 iters), loss = 0.00155791
I0816 15:31:09.183924  5636 solver.cpp:237]     Train net output #0: loss = 0.00155792 (* 1 = 0.00155792 loss)
I0816 15:31:09.183944  5636 sgd_solver.cpp:105] Iteration 33500, lr = 0.00331996
I0816 15:31:09.723568  5636 solver.cpp:218] Iteration 33600 (185.306 iter/s, 0.539649s/100 iters), loss = 0.00107046
I0816 15:31:09.723664  5636 solver.cpp:237]     Train net output #0: loss = 0.00107046 (* 1 = 0.00107046 loss)
I0816 15:31:09.723680  5636 sgd_solver.cpp:105] Iteration 33600, lr = 0.00331425
I0816 15:31:10.283706  5636 solver.cpp:218] Iteration 33700 (178.569 iter/s, 0.560007s/100 iters), loss = 0.000988225
I0816 15:31:10.283810  5636 solver.cpp:237]     Train net output #0: loss = 0.00098823 (* 1 = 0.00098823 loss)
I0816 15:31:10.283826  5636 sgd_solver.cpp:105] Iteration 33700, lr = 0.00330856
I0816 15:31:10.539026  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:10.849246  5636 solver.cpp:218] Iteration 33800 (176.854 iter/s, 0.565437s/100 iters), loss = 0.00138032
I0816 15:31:10.849324  5636 solver.cpp:237]     Train net output #0: loss = 0.00138033 (* 1 = 0.00138033 loss)
I0816 15:31:10.849340  5636 sgd_solver.cpp:105] Iteration 33800, lr = 0.00330289
I0816 15:31:11.414721  5636 solver.cpp:218] Iteration 33900 (176.866 iter/s, 0.565399s/100 iters), loss = 0.00080923
I0816 15:31:11.414794  5636 solver.cpp:237]     Train net output #0: loss = 0.000809236 (* 1 = 0.000809236 loss)
I0816 15:31:11.414809  5636 sgd_solver.cpp:105] Iteration 33900, lr = 0.00329725
I0816 15:31:11.980957  5636 solver.cpp:330] Iteration 34000, Testing net (#0)
I0816 15:31:12.183218  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:12.189291  5636 solver.cpp:397]     Test net output #0: loss = 0.0193172 (* 1 = 0.0193172 loss)
I0816 15:31:12.194119  5636 solver.cpp:218] Iteration 34000 (128.315 iter/s, 0.779333s/100 iters), loss = 0.00110223
I0816 15:31:12.194181  5636 solver.cpp:237]     Train net output #0: loss = 0.00110223 (* 1 = 0.00110223 loss)
I0816 15:31:12.194201  5636 sgd_solver.cpp:105] Iteration 34000, lr = 0.00329163
I0816 15:31:12.734611  5636 solver.cpp:218] Iteration 34100 (185.033 iter/s, 0.540443s/100 iters), loss = 0.0010223
I0816 15:31:12.734696  5636 solver.cpp:237]     Train net output #0: loss = 0.0010223 (* 1 = 0.0010223 loss)
I0816 15:31:12.734712  5636 sgd_solver.cpp:105] Iteration 34100, lr = 0.00328603
I0816 15:31:13.283816  5636 solver.cpp:218] Iteration 34200 (182.152 iter/s, 0.548991s/100 iters), loss = 0.000949155
I0816 15:31:13.283888  5636 solver.cpp:237]     Train net output #0: loss = 0.000949159 (* 1 = 0.000949159 loss)
I0816 15:31:13.283905  5636 sgd_solver.cpp:105] Iteration 34200, lr = 0.00328045
I0816 15:31:13.849567  5636 solver.cpp:218] Iteration 34300 (176.779 iter/s, 0.565678s/100 iters), loss = 0.000509193
I0816 15:31:13.849650  5636 solver.cpp:237]     Train net output #0: loss = 0.000509197 (* 1 = 0.000509197 loss)
I0816 15:31:13.849689  5636 sgd_solver.cpp:105] Iteration 34300, lr = 0.00327489
I0816 15:31:14.420368  5636 solver.cpp:218] Iteration 34400 (175.217 iter/s, 0.57072s/100 iters), loss = 0.000318842
I0816 15:31:14.420747  5636 solver.cpp:237]     Train net output #0: loss = 0.000318847 (* 1 = 0.000318847 loss)
I0816 15:31:14.420768  5636 sgd_solver.cpp:105] Iteration 34400, lr = 0.00326936
I0816 15:31:14.990658  5636 solver.cpp:330] Iteration 34500, Testing net (#0)
I0816 15:31:15.193625  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:15.199080  5636 solver.cpp:397]     Test net output #0: loss = 0.0187233 (* 1 = 0.0187233 loss)
I0816 15:31:15.204675  5636 solver.cpp:218] Iteration 34500 (127.559 iter/s, 0.783954s/100 iters), loss = 0.00341613
I0816 15:31:15.204731  5636 solver.cpp:237]     Train net output #0: loss = 0.00341614 (* 1 = 0.00341614 loss)
I0816 15:31:15.204751  5636 sgd_solver.cpp:105] Iteration 34500, lr = 0.00326385
I0816 15:31:15.748303  5636 solver.cpp:218] Iteration 34600 (183.969 iter/s, 0.54357s/100 iters), loss = 0.00136385
I0816 15:31:15.748399  5636 solver.cpp:237]     Train net output #0: loss = 0.00136386 (* 1 = 0.00136386 loss)
I0816 15:31:15.748416  5636 sgd_solver.cpp:105] Iteration 34600, lr = 0.00325836
I0816 15:31:16.228991  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:16.317405  5636 solver.cpp:218] Iteration 34700 (175.754 iter/s, 0.568976s/100 iters), loss = 0.000402446
I0816 15:31:16.317471  5636 solver.cpp:237]     Train net output #0: loss = 0.000402451 (* 1 = 0.000402451 loss)
I0816 15:31:16.317487  5636 sgd_solver.cpp:105] Iteration 34700, lr = 0.00325289
I0816 15:31:16.882366  5636 solver.cpp:218] Iteration 34800 (177.025 iter/s, 0.564893s/100 iters), loss = 0.000910798
I0816 15:31:16.882463  5636 solver.cpp:237]     Train net output #0: loss = 0.000910803 (* 1 = 0.000910803 loss)
I0816 15:31:16.882479  5636 sgd_solver.cpp:105] Iteration 34800, lr = 0.00324744
I0816 15:31:17.418278  5636 solver.cpp:218] Iteration 34900 (186.633 iter/s, 0.535811s/100 iters), loss = 9.42822e-05
I0816 15:31:17.418354  5636 solver.cpp:237]     Train net output #0: loss = 9.42871e-05 (* 1 = 9.42871e-05 loss)
I0816 15:31:17.418373  5636 sgd_solver.cpp:105] Iteration 34900, lr = 0.00324202
I0816 15:31:17.975850  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_35000.caffemodel
I0816 15:31:17.990447  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_35000.solverstate
I0816 15:31:17.993476  5636 solver.cpp:330] Iteration 35000, Testing net (#0)
I0816 15:31:18.191548  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:18.198663  5636 solver.cpp:397]     Test net output #0: loss = 0.0188742 (* 1 = 0.0188742 loss)
I0816 15:31:18.204208  5636 solver.cpp:218] Iteration 35000 (127.248 iter/s, 0.785864s/100 iters), loss = 0.000609545
I0816 15:31:18.204263  5636 solver.cpp:237]     Train net output #0: loss = 0.000609549 (* 1 = 0.000609549 loss)
I0816 15:31:18.204282  5636 sgd_solver.cpp:105] Iteration 35000, lr = 0.00323661
I0816 15:31:18.743738  5636 solver.cpp:218] Iteration 35100 (185.366 iter/s, 0.539474s/100 iters), loss = 0.000611217
I0816 15:31:18.743805  5636 solver.cpp:237]     Train net output #0: loss = 0.000611221 (* 1 = 0.000611221 loss)
I0816 15:31:18.743820  5636 sgd_solver.cpp:105] Iteration 35100, lr = 0.00323123
I0816 15:31:19.296064  5636 solver.cpp:218] Iteration 35200 (181.123 iter/s, 0.55211s/100 iters), loss = 0.00118539
I0816 15:31:19.296147  5636 solver.cpp:237]     Train net output #0: loss = 0.00118539 (* 1 = 0.00118539 loss)
I0816 15:31:19.296164  5636 sgd_solver.cpp:105] Iteration 35200, lr = 0.00322586
I0816 15:31:19.861543  5636 solver.cpp:218] Iteration 35300 (176.867 iter/s, 0.565397s/100 iters), loss = 0.000334492
I0816 15:31:19.861629  5636 solver.cpp:237]     Train net output #0: loss = 0.000334496 (* 1 = 0.000334496 loss)
I0816 15:31:19.861649  5636 sgd_solver.cpp:105] Iteration 35300, lr = 0.00322052
I0816 15:31:20.424746  5636 solver.cpp:218] Iteration 35400 (177.581 iter/s, 0.563123s/100 iters), loss = 0.000756481
I0816 15:31:20.424825  5636 solver.cpp:237]     Train net output #0: loss = 0.000756485 (* 1 = 0.000756485 loss)
I0816 15:31:20.424860  5636 sgd_solver.cpp:105] Iteration 35400, lr = 0.0032152
I0816 15:31:20.978365  5636 solver.cpp:330] Iteration 35500, Testing net (#0)
I0816 15:31:21.178059  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:21.185664  5636 solver.cpp:397]     Test net output #0: loss = 0.0187782 (* 1 = 0.0187782 loss)
I0816 15:31:21.191510  5636 solver.cpp:218] Iteration 35500 (130.43 iter/s, 0.766694s/100 iters), loss = 0.000739272
I0816 15:31:21.191566  5636 solver.cpp:237]     Train net output #0: loss = 0.000739277 (* 1 = 0.000739277 loss)
I0816 15:31:21.191586  5636 sgd_solver.cpp:105] Iteration 35500, lr = 0.0032099
I0816 15:31:21.755012  5636 solver.cpp:218] Iteration 35600 (177.49 iter/s, 0.56341s/100 iters), loss = 0.00148244
I0816 15:31:21.755100  5636 solver.cpp:237]     Train net output #0: loss = 0.00148245 (* 1 = 0.00148245 loss)
I0816 15:31:21.755117  5636 sgd_solver.cpp:105] Iteration 35600, lr = 0.00320462
I0816 15:31:21.872043  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:22.311513  5636 solver.cpp:218] Iteration 35700 (179.735 iter/s, 0.556374s/100 iters), loss = 0.00118848
I0816 15:31:22.311589  5636 solver.cpp:237]     Train net output #0: loss = 0.00118848 (* 1 = 0.00118848 loss)
I0816 15:31:22.311605  5636 sgd_solver.cpp:105] Iteration 35700, lr = 0.00319936
I0816 15:31:22.877952  5636 solver.cpp:218] Iteration 35800 (176.564 iter/s, 0.566367s/100 iters), loss = 0.00062367
I0816 15:31:22.878036  5636 solver.cpp:237]     Train net output #0: loss = 0.000623676 (* 1 = 0.000623676 loss)
I0816 15:31:22.878051  5636 sgd_solver.cpp:105] Iteration 35800, lr = 0.00319412
I0816 15:31:23.432876  5636 solver.cpp:218] Iteration 35900 (180.23 iter/s, 0.554847s/100 iters), loss = 0.00146264
I0816 15:31:23.432946  5636 solver.cpp:237]     Train net output #0: loss = 0.00146265 (* 1 = 0.00146265 loss)
I0816 15:31:23.432962  5636 sgd_solver.cpp:105] Iteration 35900, lr = 0.0031889
I0816 15:31:23.990113  5636 solver.cpp:330] Iteration 36000, Testing net (#0)
I0816 15:31:24.191095  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:24.198477  5636 solver.cpp:397]     Test net output #0: loss = 0.0193769 (* 1 = 0.0193769 loss)
I0816 15:31:24.204426  5636 solver.cpp:218] Iteration 36000 (129.62 iter/s, 0.771486s/100 iters), loss = 0.00127037
I0816 15:31:24.204484  5636 solver.cpp:237]     Train net output #0: loss = 0.00127038 (* 1 = 0.00127038 loss)
I0816 15:31:24.204504  5636 sgd_solver.cpp:105] Iteration 36000, lr = 0.0031837
I0816 15:31:24.753015  5636 solver.cpp:218] Iteration 36100 (182.302 iter/s, 0.548542s/100 iters), loss = 0.000647493
I0816 15:31:24.753105  5636 solver.cpp:237]     Train net output #0: loss = 0.000647498 (* 1 = 0.000647498 loss)
I0816 15:31:24.753121  5636 sgd_solver.cpp:105] Iteration 36100, lr = 0.00317852
I0816 15:31:25.314754  5636 solver.cpp:218] Iteration 36200 (178.064 iter/s, 0.561596s/100 iters), loss = 0.00124929
I0816 15:31:25.314895  5636 solver.cpp:237]     Train net output #0: loss = 0.0012493 (* 1 = 0.0012493 loss)
I0816 15:31:25.314934  5636 sgd_solver.cpp:105] Iteration 36200, lr = 0.00317335
I0816 15:31:25.887971  5636 solver.cpp:218] Iteration 36300 (174.496 iter/s, 0.573079s/100 iters), loss = 0.000291624
I0816 15:31:25.888075  5636 solver.cpp:237]     Train net output #0: loss = 0.00029163 (* 1 = 0.00029163 loss)
I0816 15:31:25.888103  5636 sgd_solver.cpp:105] Iteration 36300, lr = 0.00316821
I0816 15:31:26.455152  5636 solver.cpp:218] Iteration 36400 (176.341 iter/s, 0.567084s/100 iters), loss = 0.00150553
I0816 15:31:26.455227  5636 solver.cpp:237]     Train net output #0: loss = 0.00150554 (* 1 = 0.00150554 loss)
I0816 15:31:26.455243  5636 sgd_solver.cpp:105] Iteration 36400, lr = 0.00316309
I0816 15:31:27.015049  5636 solver.cpp:330] Iteration 36500, Testing net (#0)
I0816 15:31:27.218504  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:27.221293  5636 solver.cpp:397]     Test net output #0: loss = 0.0188237 (* 1 = 0.0188237 loss)
I0816 15:31:27.227098  5636 solver.cpp:218] Iteration 36500 (129.554 iter/s, 0.771877s/100 iters), loss = 0.00247389
I0816 15:31:27.227152  5636 solver.cpp:237]     Train net output #0: loss = 0.0024739 (* 1 = 0.0024739 loss)
I0816 15:31:27.227177  5636 sgd_solver.cpp:105] Iteration 36500, lr = 0.00315799
I0816 15:31:27.537609  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:27.771836  5636 solver.cpp:218] Iteration 36600 (183.592 iter/s, 0.544686s/100 iters), loss = 0.000960602
I0816 15:31:27.771911  5636 solver.cpp:237]     Train net output #0: loss = 0.000960608 (* 1 = 0.000960608 loss)
I0816 15:31:27.771935  5636 sgd_solver.cpp:105] Iteration 36600, lr = 0.0031529
I0816 15:31:28.353627  5636 solver.cpp:218] Iteration 36700 (171.914 iter/s, 0.581687s/100 iters), loss = 0.00126737
I0816 15:31:28.353703  5636 solver.cpp:237]     Train net output #0: loss = 0.00126738 (* 1 = 0.00126738 loss)
I0816 15:31:28.353726  5636 sgd_solver.cpp:105] Iteration 36700, lr = 0.00314784
I0816 15:31:28.910051  5636 solver.cpp:218] Iteration 36800 (179.754 iter/s, 0.556315s/100 iters), loss = 0.00252086
I0816 15:31:28.910141  5636 solver.cpp:237]     Train net output #0: loss = 0.00252086 (* 1 = 0.00252086 loss)
I0816 15:31:28.910162  5636 sgd_solver.cpp:105] Iteration 36800, lr = 0.00314279
I0816 15:31:29.476855  5636 solver.cpp:218] Iteration 36900 (176.456 iter/s, 0.566715s/100 iters), loss = 0.00126346
I0816 15:31:29.476936  5636 solver.cpp:237]     Train net output #0: loss = 0.00126346 (* 1 = 0.00126346 loss)
I0816 15:31:29.476956  5636 sgd_solver.cpp:105] Iteration 36900, lr = 0.00313776
I0816 15:31:30.039057  5636 solver.cpp:330] Iteration 37000, Testing net (#0)
I0816 15:31:30.279230  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:30.281339  5636 solver.cpp:397]     Test net output #0: loss = 0.0189074 (* 1 = 0.0189074 loss)
I0816 15:31:30.287017  5636 solver.cpp:218] Iteration 37000 (123.443 iter/s, 0.81009s/100 iters), loss = 0.00045279
I0816 15:31:30.287286  5636 solver.cpp:237]     Train net output #0: loss = 0.000452796 (* 1 = 0.000452796 loss)
I0816 15:31:30.287325  5636 sgd_solver.cpp:105] Iteration 37000, lr = 0.00313276
I0816 15:31:30.833003  5636 solver.cpp:218] Iteration 37100 (183.243 iter/s, 0.545724s/100 iters), loss = 0.000524733
I0816 15:31:30.833096  5636 solver.cpp:237]     Train net output #0: loss = 0.000524739 (* 1 = 0.000524739 loss)
I0816 15:31:30.833117  5636 sgd_solver.cpp:105] Iteration 37100, lr = 0.00312777
I0816 15:31:31.397716  5636 solver.cpp:218] Iteration 37200 (177.12 iter/s, 0.56459s/100 iters), loss = 0.000804119
I0816 15:31:31.397796  5636 solver.cpp:237]     Train net output #0: loss = 0.000804125 (* 1 = 0.000804125 loss)
I0816 15:31:31.397816  5636 sgd_solver.cpp:105] Iteration 37200, lr = 0.0031228
I0816 15:31:31.967404  5636 solver.cpp:218] Iteration 37300 (175.558 iter/s, 0.569613s/100 iters), loss = 0.00153243
I0816 15:31:31.967473  5636 solver.cpp:237]     Train net output #0: loss = 0.00153243 (* 1 = 0.00153243 loss)
I0816 15:31:31.967492  5636 sgd_solver.cpp:105] Iteration 37300, lr = 0.00311784
I0816 15:31:32.530923  5636 solver.cpp:218] Iteration 37400 (177.477 iter/s, 0.563452s/100 iters), loss = 0.00134952
I0816 15:31:32.531002  5636 solver.cpp:237]     Train net output #0: loss = 0.00134953 (* 1 = 0.00134953 loss)
I0816 15:31:32.531021  5636 sgd_solver.cpp:105] Iteration 37400, lr = 0.00311291
I0816 15:31:33.071020  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:33.087776  5636 solver.cpp:330] Iteration 37500, Testing net (#0)
I0816 15:31:33.287101  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:33.294677  5636 solver.cpp:397]     Test net output #0: loss = 0.0198049 (* 1 = 0.0198049 loss)
I0816 15:31:33.300881  5636 solver.cpp:218] Iteration 37500 (129.889 iter/s, 0.76989s/100 iters), loss = 0.000654657
I0816 15:31:33.300938  5636 solver.cpp:237]     Train net output #0: loss = 0.000654663 (* 1 = 0.000654663 loss)
I0816 15:31:33.300957  5636 sgd_solver.cpp:105] Iteration 37500, lr = 0.00310799
I0816 15:31:33.862721  5636 solver.cpp:218] Iteration 37600 (178.029 iter/s, 0.561705s/100 iters), loss = 0.000969002
I0816 15:31:33.862825  5636 solver.cpp:237]     Train net output #0: loss = 0.000969008 (* 1 = 0.000969008 loss)
I0816 15:31:33.862843  5636 sgd_solver.cpp:105] Iteration 37600, lr = 0.00310309
I0816 15:31:34.422530  5636 solver.cpp:218] Iteration 37700 (178.678 iter/s, 0.559665s/100 iters), loss = 0.000722269
I0816 15:31:34.422636  5636 solver.cpp:237]     Train net output #0: loss = 0.000722275 (* 1 = 0.000722275 loss)
I0816 15:31:34.422652  5636 sgd_solver.cpp:105] Iteration 37700, lr = 0.00309821
I0816 15:31:34.986956  5636 solver.cpp:218] Iteration 37800 (177.206 iter/s, 0.564316s/100 iters), loss = 0.000850521
I0816 15:31:34.987061  5636 solver.cpp:237]     Train net output #0: loss = 0.000850526 (* 1 = 0.000850526 loss)
I0816 15:31:34.987082  5636 sgd_solver.cpp:105] Iteration 37800, lr = 0.00309335
I0816 15:31:35.547401  5636 solver.cpp:218] Iteration 37900 (178.464 iter/s, 0.560337s/100 iters), loss = 0.00106945
I0816 15:31:35.547502  5636 solver.cpp:237]     Train net output #0: loss = 0.00106946 (* 1 = 0.00106946 loss)
I0816 15:31:35.547523  5636 sgd_solver.cpp:105] Iteration 37900, lr = 0.00308851
I0816 15:31:36.101140  5636 solver.cpp:330] Iteration 38000, Testing net (#0)
I0816 15:31:36.295457  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:36.302925  5636 solver.cpp:397]     Test net output #0: loss = 0.0185012 (* 1 = 0.0185012 loss)
I0816 15:31:36.308527  5636 solver.cpp:218] Iteration 38000 (131.4 iter/s, 0.761035s/100 iters), loss = 0.000628481
I0816 15:31:36.308583  5636 solver.cpp:237]     Train net output #0: loss = 0.000628487 (* 1 = 0.000628487 loss)
I0816 15:31:36.308603  5636 sgd_solver.cpp:105] Iteration 38000, lr = 0.00308368
I0816 15:31:36.850064  5636 solver.cpp:218] Iteration 38100 (184.691 iter/s, 0.541444s/100 iters), loss = 0.000574125
I0816 15:31:36.850157  5636 solver.cpp:237]     Train net output #0: loss = 0.00057413 (* 1 = 0.00057413 loss)
I0816 15:31:36.850174  5636 sgd_solver.cpp:105] Iteration 38100, lr = 0.00307887
I0816 15:31:37.405503  5636 solver.cpp:218] Iteration 38200 (180.079 iter/s, 0.555312s/100 iters), loss = 0.00113448
I0816 15:31:37.405576  5636 solver.cpp:237]     Train net output #0: loss = 0.00113448 (* 1 = 0.00113448 loss)
I0816 15:31:37.405593  5636 sgd_solver.cpp:105] Iteration 38200, lr = 0.00307408
I0816 15:31:37.970810  5636 solver.cpp:218] Iteration 38300 (176.918 iter/s, 0.565234s/100 iters), loss = 0.000604521
I0816 15:31:37.970904  5636 solver.cpp:237]     Train net output #0: loss = 0.000604526 (* 1 = 0.000604526 loss)
I0816 15:31:37.970922  5636 sgd_solver.cpp:105] Iteration 38300, lr = 0.0030693
I0816 15:31:38.540436  5636 solver.cpp:218] Iteration 38400 (175.581 iter/s, 0.569537s/100 iters), loss = 0.00109463
I0816 15:31:38.540514  5636 solver.cpp:237]     Train net output #0: loss = 0.00109464 (* 1 = 0.00109464 loss)
I0816 15:31:38.540530  5636 sgd_solver.cpp:105] Iteration 38400, lr = 0.00306454
I0816 15:31:38.725817  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:39.092293  5636 solver.cpp:330] Iteration 38500, Testing net (#0)
I0816 15:31:39.290551  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:39.298199  5636 solver.cpp:397]     Test net output #0: loss = 0.0190936 (* 1 = 0.0190936 loss)
I0816 15:31:39.303813  5636 solver.cpp:218] Iteration 38500 (131.015 iter/s, 0.763273s/100 iters), loss = 0.000515321
I0816 15:31:39.303874  5636 solver.cpp:237]     Train net output #0: loss = 0.000515327 (* 1 = 0.000515327 loss)
I0816 15:31:39.303892  5636 sgd_solver.cpp:105] Iteration 38500, lr = 0.0030598
I0816 15:31:39.845546  5636 solver.cpp:218] Iteration 38600 (184.626 iter/s, 0.541636s/100 iters), loss = 0.000325875
I0816 15:31:39.845635  5636 solver.cpp:237]     Train net output #0: loss = 0.000325881 (* 1 = 0.000325881 loss)
I0816 15:31:39.845651  5636 sgd_solver.cpp:105] Iteration 38600, lr = 0.00305508
I0816 15:31:40.394356  5636 solver.cpp:218] Iteration 38700 (182.253 iter/s, 0.548688s/100 iters), loss = 0.000406598
I0816 15:31:40.394433  5636 solver.cpp:237]     Train net output #0: loss = 0.000406604 (* 1 = 0.000406604 loss)
I0816 15:31:40.394449  5636 sgd_solver.cpp:105] Iteration 38700, lr = 0.00305038
I0816 15:31:40.963273  5636 solver.cpp:218] Iteration 38800 (175.797 iter/s, 0.568839s/100 iters), loss = 0.000688923
I0816 15:31:40.963343  5636 solver.cpp:237]     Train net output #0: loss = 0.000688928 (* 1 = 0.000688928 loss)
I0816 15:31:40.963359  5636 sgd_solver.cpp:105] Iteration 38800, lr = 0.00304569
I0816 15:31:41.543416  5636 solver.cpp:218] Iteration 38900 (172.391 iter/s, 0.580076s/100 iters), loss = 0.00032886
I0816 15:31:41.543478  5636 solver.cpp:237]     Train net output #0: loss = 0.000328865 (* 1 = 0.000328865 loss)
I0816 15:31:41.543493  5636 sgd_solver.cpp:105] Iteration 38900, lr = 0.00304101
I0816 15:31:42.105494  5636 solver.cpp:330] Iteration 39000, Testing net (#0)
I0816 15:31:42.306696  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:42.313458  5636 solver.cpp:397]     Test net output #0: loss = 0.018894 (* 1 = 0.018894 loss)
I0816 15:31:42.318743  5636 solver.cpp:218] Iteration 39000 (128.987 iter/s, 0.775273s/100 iters), loss = 0.00115121
I0816 15:31:42.318796  5636 solver.cpp:237]     Train net output #0: loss = 0.00115122 (* 1 = 0.00115122 loss)
I0816 15:31:42.318815  5636 sgd_solver.cpp:105] Iteration 39000, lr = 0.00303636
I0816 15:31:42.866925  5636 solver.cpp:218] Iteration 39100 (182.438 iter/s, 0.548133s/100 iters), loss = 0.00185903
I0816 15:31:42.867017  5636 solver.cpp:237]     Train net output #0: loss = 0.00185903 (* 1 = 0.00185903 loss)
I0816 15:31:42.867033  5636 sgd_solver.cpp:105] Iteration 39100, lr = 0.00303172
I0816 15:31:43.418324  5636 solver.cpp:218] Iteration 39200 (181.396 iter/s, 0.551279s/100 iters), loss = 0.000419815
I0816 15:31:43.418392  5636 solver.cpp:237]     Train net output #0: loss = 0.00041982 (* 1 = 0.00041982 loss)
I0816 15:31:43.418408  5636 sgd_solver.cpp:105] Iteration 39200, lr = 0.0030271
I0816 15:31:43.985702  5636 solver.cpp:218] Iteration 39300 (176.271 iter/s, 0.567309s/100 iters), loss = 0.000898162
I0816 15:31:43.985788  5636 solver.cpp:237]     Train net output #0: loss = 0.000898167 (* 1 = 0.000898167 loss)
I0816 15:31:43.985805  5636 sgd_solver.cpp:105] Iteration 39300, lr = 0.00302249
I0816 15:31:44.389204  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:44.567205  5636 solver.cpp:218] Iteration 39400 (171.993 iter/s, 0.58142s/100 iters), loss = 0.000310937
I0816 15:31:44.567597  5636 solver.cpp:237]     Train net output #0: loss = 0.000310942 (* 1 = 0.000310942 loss)
I0816 15:31:44.567665  5636 sgd_solver.cpp:105] Iteration 39400, lr = 0.0030179
I0816 15:31:45.125560  5636 solver.cpp:330] Iteration 39500, Testing net (#0)
I0816 15:31:45.328507  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:45.330726  5636 solver.cpp:397]     Test net output #0: loss = 0.0190185 (* 1 = 0.0190185 loss)
I0816 15:31:45.336709  5636 solver.cpp:218] Iteration 39500 (130.015 iter/s, 0.769144s/100 iters), loss = 0.000608729
I0816 15:31:45.336766  5636 solver.cpp:237]     Train net output #0: loss = 0.000608734 (* 1 = 0.000608734 loss)
I0816 15:31:45.336788  5636 sgd_solver.cpp:105] Iteration 39500, lr = 0.00301333
I0816 15:31:45.876246  5636 solver.cpp:218] Iteration 39600 (185.365 iter/s, 0.539477s/100 iters), loss = 0.000519687
I0816 15:31:45.876334  5636 solver.cpp:237]     Train net output #0: loss = 0.000519692 (* 1 = 0.000519692 loss)
I0816 15:31:45.876350  5636 sgd_solver.cpp:105] Iteration 39600, lr = 0.00300877
I0816 15:31:46.426126  5636 solver.cpp:218] Iteration 39700 (181.898 iter/s, 0.54976s/100 iters), loss = 0.000825574
I0816 15:31:46.426201  5636 solver.cpp:237]     Train net output #0: loss = 0.000825579 (* 1 = 0.000825579 loss)
I0816 15:31:46.426218  5636 sgd_solver.cpp:105] Iteration 39700, lr = 0.00300423
I0816 15:31:46.990756  5636 solver.cpp:218] Iteration 39800 (177.131 iter/s, 0.564553s/100 iters), loss = 0.00085241
I0816 15:31:46.990833  5636 solver.cpp:237]     Train net output #0: loss = 0.000852415 (* 1 = 0.000852415 loss)
I0816 15:31:46.990846  5636 sgd_solver.cpp:105] Iteration 39800, lr = 0.0029997
I0816 15:31:47.557502  5636 solver.cpp:218] Iteration 39900 (176.469 iter/s, 0.566672s/100 iters), loss = 0.000641379
I0816 15:31:47.557560  5636 solver.cpp:237]     Train net output #0: loss = 0.000641384 (* 1 = 0.000641384 loss)
I0816 15:31:47.557574  5636 sgd_solver.cpp:105] Iteration 39900, lr = 0.00299519
I0816 15:31:48.117696  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_40000.caffemodel
I0816 15:31:48.131961  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_40000.solverstate
I0816 15:31:48.134971  5636 solver.cpp:330] Iteration 40000, Testing net (#0)
I0816 15:31:48.335147  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:48.339509  5636 solver.cpp:397]     Test net output #0: loss = 0.0193445 (* 1 = 0.0193445 loss)
I0816 15:31:48.344780  5636 solver.cpp:218] Iteration 40000 (127.028 iter/s, 0.787227s/100 iters), loss = 0.00109248
I0816 15:31:48.344821  5636 solver.cpp:237]     Train net output #0: loss = 0.00109249 (* 1 = 0.00109249 loss)
I0816 15:31:48.344841  5636 sgd_solver.cpp:105] Iteration 40000, lr = 0.0029907
I0816 15:31:48.889935  5636 solver.cpp:218] Iteration 40100 (183.449 iter/s, 0.545111s/100 iters), loss = 0.00138277
I0816 15:31:48.890005  5636 solver.cpp:237]     Train net output #0: loss = 0.00138277 (* 1 = 0.00138277 loss)
I0816 15:31:48.890020  5636 sgd_solver.cpp:105] Iteration 40100, lr = 0.00298622
I0816 15:31:49.450902  5636 solver.cpp:218] Iteration 40200 (178.295 iter/s, 0.560867s/100 iters), loss = 0.000853774
I0816 15:31:49.450961  5636 solver.cpp:237]     Train net output #0: loss = 0.000853779 (* 1 = 0.000853779 loss)
I0816 15:31:49.450975  5636 sgd_solver.cpp:105] Iteration 40200, lr = 0.00298176
I0816 15:31:50.016682  5636 solver.cpp:218] Iteration 40300 (176.766 iter/s, 0.56572s/100 iters), loss = 0.00101475
I0816 15:31:50.016751  5636 solver.cpp:237]     Train net output #0: loss = 0.00101476 (* 1 = 0.00101476 loss)
I0816 15:31:50.016765  5636 sgd_solver.cpp:105] Iteration 40300, lr = 0.00297731
I0816 15:31:50.059705  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:50.584439  5636 solver.cpp:218] Iteration 40400 (176.152 iter/s, 0.567693s/100 iters), loss = 0.00021298
I0816 15:31:50.584507  5636 solver.cpp:237]     Train net output #0: loss = 0.000212985 (* 1 = 0.000212985 loss)
I0816 15:31:50.584555  5636 sgd_solver.cpp:105] Iteration 40400, lr = 0.00297288
I0816 15:31:51.145977  5636 solver.cpp:330] Iteration 40500, Testing net (#0)
I0816 15:31:51.347865  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:51.354545  5636 solver.cpp:397]     Test net output #0: loss = 0.0194888 (* 1 = 0.0194888 loss)
I0816 15:31:51.359920  5636 solver.cpp:218] Iteration 40500 (128.963 iter/s, 0.775419s/100 iters), loss = 0.000234568
I0816 15:31:51.359969  5636 solver.cpp:237]     Train net output #0: loss = 0.000234573 (* 1 = 0.000234573 loss)
I0816 15:31:51.359987  5636 sgd_solver.cpp:105] Iteration 40500, lr = 0.00296846
I0816 15:31:51.904259  5636 solver.cpp:218] Iteration 40600 (183.727 iter/s, 0.544285s/100 iters), loss = 0.000496025
I0816 15:31:51.904337  5636 solver.cpp:237]     Train net output #0: loss = 0.00049603 (* 1 = 0.00049603 loss)
I0816 15:31:51.904352  5636 sgd_solver.cpp:105] Iteration 40600, lr = 0.00296406
I0816 15:31:52.452389  5636 solver.cpp:218] Iteration 40700 (182.479 iter/s, 0.548007s/100 iters), loss = 0.00103204
I0816 15:31:52.452456  5636 solver.cpp:237]     Train net output #0: loss = 0.00103204 (* 1 = 0.00103204 loss)
I0816 15:31:52.452487  5636 sgd_solver.cpp:105] Iteration 40700, lr = 0.00295968
I0816 15:31:53.018548  5636 solver.cpp:218] Iteration 40800 (176.651 iter/s, 0.566089s/100 iters), loss = 0.00154475
I0816 15:31:53.018620  5636 solver.cpp:237]     Train net output #0: loss = 0.00154475 (* 1 = 0.00154475 loss)
I0816 15:31:53.018635  5636 sgd_solver.cpp:105] Iteration 40800, lr = 0.0029553
I0816 15:31:53.583047  5636 solver.cpp:218] Iteration 40900 (177.17 iter/s, 0.564431s/100 iters), loss = 0.000357545
I0816 15:31:53.583108  5636 solver.cpp:237]     Train net output #0: loss = 0.000357549 (* 1 = 0.000357549 loss)
I0816 15:31:53.583123  5636 sgd_solver.cpp:105] Iteration 40900, lr = 0.00295095
I0816 15:31:54.142895  5636 solver.cpp:330] Iteration 41000, Testing net (#0)
I0816 15:31:54.341769  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:54.349444  5636 solver.cpp:397]     Test net output #0: loss = 0.0190753 (* 1 = 0.0190753 loss)
I0816 15:31:54.355454  5636 solver.cpp:218] Iteration 41000 (129.474 iter/s, 0.772353s/100 iters), loss = 0.000985911
I0816 15:31:54.355497  5636 solver.cpp:237]     Train net output #0: loss = 0.000985915 (* 1 = 0.000985915 loss)
I0816 15:31:54.355515  5636 sgd_solver.cpp:105] Iteration 41000, lr = 0.00294661
I0816 15:31:54.892218  5636 solver.cpp:218] Iteration 41100 (186.318 iter/s, 0.536716s/100 iters), loss = 0.000853818
I0816 15:31:54.892283  5636 solver.cpp:237]     Train net output #0: loss = 0.000853822 (* 1 = 0.000853822 loss)
I0816 15:31:54.892298  5636 sgd_solver.cpp:105] Iteration 41100, lr = 0.00294228
I0816 15:31:55.448058  5636 solver.cpp:218] Iteration 41200 (179.939 iter/s, 0.555743s/100 iters), loss = 0.000541813
I0816 15:31:55.448122  5636 solver.cpp:237]     Train net output #0: loss = 0.000541817 (* 1 = 0.000541817 loss)
I0816 15:31:55.448137  5636 sgd_solver.cpp:105] Iteration 41200, lr = 0.00293797
I0816 15:31:55.703691  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:56.024204  5636 solver.cpp:218] Iteration 41300 (173.586 iter/s, 0.576084s/100 iters), loss = 0.00104924
I0816 15:31:56.024273  5636 solver.cpp:237]     Train net output #0: loss = 0.00104924 (* 1 = 0.00104924 loss)
I0816 15:31:56.024291  5636 sgd_solver.cpp:105] Iteration 41300, lr = 0.00293367
I0816 15:31:56.591881  5636 solver.cpp:218] Iteration 41400 (176.189 iter/s, 0.567572s/100 iters), loss = 0.000620705
I0816 15:31:56.591950  5636 solver.cpp:237]     Train net output #0: loss = 0.000620709 (* 1 = 0.000620709 loss)
I0816 15:31:56.591966  5636 sgd_solver.cpp:105] Iteration 41400, lr = 0.00292939
I0816 15:31:57.147534  5636 solver.cpp:330] Iteration 41500, Testing net (#0)
I0816 15:31:57.348222  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:31:57.354950  5636 solver.cpp:397]     Test net output #0: loss = 0.0199016 (* 1 = 0.0199016 loss)
I0816 15:31:57.360276  5636 solver.cpp:218] Iteration 41500 (130.152 iter/s, 0.768334s/100 iters), loss = 0.00083754
I0816 15:31:57.360332  5636 solver.cpp:237]     Train net output #0: loss = 0.000837544 (* 1 = 0.000837544 loss)
I0816 15:31:57.360350  5636 sgd_solver.cpp:105] Iteration 41500, lr = 0.00292513
I0816 15:31:57.884850  5636 solver.cpp:218] Iteration 41600 (190.651 iter/s, 0.524518s/100 iters), loss = 0.000568319
I0816 15:31:57.884934  5636 solver.cpp:237]     Train net output #0: loss = 0.000568323 (* 1 = 0.000568323 loss)
I0816 15:31:57.884951  5636 sgd_solver.cpp:105] Iteration 41600, lr = 0.00292087
I0816 15:31:58.441400  5636 solver.cpp:218] Iteration 41700 (179.716 iter/s, 0.556434s/100 iters), loss = 0.00062934
I0816 15:31:58.441470  5636 solver.cpp:237]     Train net output #0: loss = 0.000629345 (* 1 = 0.000629345 loss)
I0816 15:31:58.441485  5636 sgd_solver.cpp:105] Iteration 41700, lr = 0.00291664
I0816 15:31:59.008436  5636 solver.cpp:218] Iteration 41800 (176.377 iter/s, 0.566967s/100 iters), loss = 0.000344282
I0816 15:31:59.008517  5636 solver.cpp:237]     Train net output #0: loss = 0.000344286 (* 1 = 0.000344286 loss)
I0816 15:31:59.008558  5636 sgd_solver.cpp:105] Iteration 41800, lr = 0.00291241
I0816 15:31:59.588024  5636 solver.cpp:218] Iteration 41900 (172.559 iter/s, 0.579511s/100 iters), loss = 0.000194821
I0816 15:31:59.588099  5636 solver.cpp:237]     Train net output #0: loss = 0.000194825 (* 1 = 0.000194825 loss)
I0816 15:31:59.588116  5636 sgd_solver.cpp:105] Iteration 41900, lr = 0.0029082
I0816 15:32:00.145648  5636 solver.cpp:330] Iteration 42000, Testing net (#0)
I0816 15:32:00.346276  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:00.353368  5636 solver.cpp:397]     Test net output #0: loss = 0.0191883 (* 1 = 0.0191883 loss)
I0816 15:32:00.358950  5636 solver.cpp:218] Iteration 42000 (129.731 iter/s, 0.770825s/100 iters), loss = 0.00240959
I0816 15:32:00.359004  5636 solver.cpp:237]     Train net output #0: loss = 0.0024096 (* 1 = 0.0024096 loss)
I0816 15:32:00.359024  5636 sgd_solver.cpp:105] Iteration 42000, lr = 0.00290401
I0816 15:32:00.912168  5636 solver.cpp:218] Iteration 42100 (180.78 iter/s, 0.553158s/100 iters), loss = 0.000918365
I0816 15:32:00.912256  5636 solver.cpp:237]     Train net output #0: loss = 0.000918369 (* 1 = 0.000918369 loss)
I0816 15:32:00.912272  5636 sgd_solver.cpp:105] Iteration 42100, lr = 0.00289982
I0816 15:32:01.375854  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:01.464880  5636 solver.cpp:218] Iteration 42200 (180.965 iter/s, 0.552594s/100 iters), loss = 0.000338121
I0816 15:32:01.464944  5636 solver.cpp:237]     Train net output #0: loss = 0.000338125 (* 1 = 0.000338125 loss)
I0816 15:32:01.464959  5636 sgd_solver.cpp:105] Iteration 42200, lr = 0.00289566
I0816 15:32:02.034756  5636 solver.cpp:218] Iteration 42300 (175.497 iter/s, 0.56981s/100 iters), loss = 0.000609229
I0816 15:32:02.034847  5636 solver.cpp:237]     Train net output #0: loss = 0.000609233 (* 1 = 0.000609233 loss)
I0816 15:32:02.034878  5636 sgd_solver.cpp:105] Iteration 42300, lr = 0.0028915
I0816 15:32:02.559759  5636 solver.cpp:218] Iteration 42400 (190.507 iter/s, 0.524916s/100 iters), loss = 7.51138e-05
I0816 15:32:02.559831  5636 solver.cpp:237]     Train net output #0: loss = 7.5118e-05 (* 1 = 7.5118e-05 loss)
I0816 15:32:02.559847  5636 sgd_solver.cpp:105] Iteration 42400, lr = 0.00288736
I0816 15:32:03.122732  5636 solver.cpp:330] Iteration 42500, Testing net (#0)
I0816 15:32:03.324558  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:03.328229  5636 solver.cpp:397]     Test net output #0: loss = 0.0192207 (* 1 = 0.0192207 loss)
I0816 15:32:03.333851  5636 solver.cpp:218] Iteration 42500 (129.195 iter/s, 0.774026s/100 iters), loss = 0.000431335
I0816 15:32:03.333905  5636 solver.cpp:237]     Train net output #0: loss = 0.000431339 (* 1 = 0.000431339 loss)
I0816 15:32:03.333926  5636 sgd_solver.cpp:105] Iteration 42500, lr = 0.00288324
I0816 15:32:03.873569  5636 solver.cpp:218] Iteration 42600 (185.303 iter/s, 0.539658s/100 iters), loss = 0.000459422
I0816 15:32:03.873664  5636 solver.cpp:237]     Train net output #0: loss = 0.000459426 (* 1 = 0.000459426 loss)
I0816 15:32:03.873680  5636 sgd_solver.cpp:105] Iteration 42600, lr = 0.00287913
I0816 15:32:04.439884  5636 solver.cpp:218] Iteration 42700 (176.632 iter/s, 0.56615s/100 iters), loss = 0.000773654
I0816 15:32:04.440059  5636 solver.cpp:237]     Train net output #0: loss = 0.000773658 (* 1 = 0.000773658 loss)
I0816 15:32:04.440434  5636 sgd_solver.cpp:105] Iteration 42700, lr = 0.00287503
I0816 15:32:05.007299  5636 solver.cpp:218] Iteration 42800 (176.29 iter/s, 0.567249s/100 iters), loss = 0.000184978
I0816 15:32:05.007402  5636 solver.cpp:237]     Train net output #0: loss = 0.000184982 (* 1 = 0.000184982 loss)
I0816 15:32:05.007418  5636 sgd_solver.cpp:105] Iteration 42800, lr = 0.00287094
I0816 15:32:05.576650  5636 solver.cpp:218] Iteration 42900 (175.669 iter/s, 0.569251s/100 iters), loss = 0.000622395
I0816 15:32:05.576725  5636 solver.cpp:237]     Train net output #0: loss = 0.000622399 (* 1 = 0.000622399 loss)
I0816 15:32:05.576740  5636 sgd_solver.cpp:105] Iteration 42900, lr = 0.00286687
I0816 15:32:06.138092  5636 solver.cpp:330] Iteration 43000, Testing net (#0)
I0816 15:32:06.338276  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:06.344571  5636 solver.cpp:397]     Test net output #0: loss = 0.0191091 (* 1 = 0.0191091 loss)
I0816 15:32:06.349455  5636 solver.cpp:218] Iteration 43000 (129.41 iter/s, 0.77274s/100 iters), loss = 0.000553867
I0816 15:32:06.349514  5636 solver.cpp:237]     Train net output #0: loss = 0.000553871 (* 1 = 0.000553871 loss)
I0816 15:32:06.349534  5636 sgd_solver.cpp:105] Iteration 43000, lr = 0.00286281
I0816 15:32:06.888551  5636 solver.cpp:218] Iteration 43100 (185.513 iter/s, 0.539045s/100 iters), loss = 0.00105817
I0816 15:32:06.888629  5636 solver.cpp:237]     Train net output #0: loss = 0.00105818 (* 1 = 0.00105818 loss)
I0816 15:32:06.888646  5636 sgd_solver.cpp:105] Iteration 43100, lr = 0.00285877
I0816 15:32:07.008278  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:07.448051  5636 solver.cpp:218] Iteration 43200 (178.766 iter/s, 0.55939s/100 iters), loss = 0.000981369
I0816 15:32:07.448124  5636 solver.cpp:237]     Train net output #0: loss = 0.000981372 (* 1 = 0.000981372 loss)
I0816 15:32:07.448140  5636 sgd_solver.cpp:105] Iteration 43200, lr = 0.00285474
I0816 15:32:08.019518  5636 solver.cpp:218] Iteration 43300 (175.01 iter/s, 0.571395s/100 iters), loss = 0.000337878
I0816 15:32:08.019603  5636 solver.cpp:237]     Train net output #0: loss = 0.000337881 (* 1 = 0.000337881 loss)
I0816 15:32:08.019619  5636 sgd_solver.cpp:105] Iteration 43300, lr = 0.00285072
I0816 15:32:08.581326  5636 solver.cpp:218] Iteration 43400 (178.022 iter/s, 0.561729s/100 iters), loss = 0.00123031
I0816 15:32:08.581399  5636 solver.cpp:237]     Train net output #0: loss = 0.00123031 (* 1 = 0.00123031 loss)
I0816 15:32:08.581415  5636 sgd_solver.cpp:105] Iteration 43400, lr = 0.00284672
I0816 15:32:09.137084  5636 solver.cpp:330] Iteration 43500, Testing net (#0)
I0816 15:32:09.337873  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:09.345257  5636 solver.cpp:397]     Test net output #0: loss = 0.0196683 (* 1 = 0.0196683 loss)
I0816 15:32:09.351169  5636 solver.cpp:218] Iteration 43500 (129.908 iter/s, 0.769777s/100 iters), loss = 0.000726203
I0816 15:32:09.351225  5636 solver.cpp:237]     Train net output #0: loss = 0.000726206 (* 1 = 0.000726206 loss)
I0816 15:32:09.351245  5636 sgd_solver.cpp:105] Iteration 43500, lr = 0.00284272
I0816 15:32:09.901170  5636 solver.cpp:218] Iteration 43600 (181.838 iter/s, 0.54994s/100 iters), loss = 0.000500319
I0816 15:32:09.901259  5636 solver.cpp:237]     Train net output #0: loss = 0.000500322 (* 1 = 0.000500322 loss)
I0816 15:32:09.901276  5636 sgd_solver.cpp:105] Iteration 43600, lr = 0.00283875
I0816 15:32:10.467828  5636 solver.cpp:218] Iteration 43700 (176.512 iter/s, 0.566533s/100 iters), loss = 0.000890595
I0816 15:32:10.467924  5636 solver.cpp:237]     Train net output #0: loss = 0.000890598 (* 1 = 0.000890598 loss)
I0816 15:32:10.467941  5636 sgd_solver.cpp:105] Iteration 43700, lr = 0.00283478
I0816 15:32:11.043583  5636 solver.cpp:218] Iteration 43800 (173.714 iter/s, 0.575658s/100 iters), loss = 0.00015967
I0816 15:32:11.043653  5636 solver.cpp:237]     Train net output #0: loss = 0.000159673 (* 1 = 0.000159673 loss)
I0816 15:32:11.043668  5636 sgd_solver.cpp:105] Iteration 43800, lr = 0.00283083
I0816 15:32:11.608614  5636 solver.cpp:218] Iteration 43900 (177.003 iter/s, 0.564961s/100 iters), loss = 0.00135684
I0816 15:32:11.608695  5636 solver.cpp:237]     Train net output #0: loss = 0.00135684 (* 1 = 0.00135684 loss)
I0816 15:32:11.608711  5636 sgd_solver.cpp:105] Iteration 43900, lr = 0.00282689
I0816 15:32:12.169760  5636 solver.cpp:330] Iteration 44000, Testing net (#0)
I0816 15:32:12.368074  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:12.375366  5636 solver.cpp:397]     Test net output #0: loss = 0.0192223 (* 1 = 0.0192223 loss)
I0816 15:32:12.380378  5636 solver.cpp:218] Iteration 44000 (129.585 iter/s, 0.771695s/100 iters), loss = 0.0016609
I0816 15:32:12.380448  5636 solver.cpp:237]     Train net output #0: loss = 0.0016609 (* 1 = 0.0016609 loss)
I0816 15:32:12.380468  5636 sgd_solver.cpp:105] Iteration 44000, lr = 0.00282296
I0816 15:32:12.688868  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:12.926882  5636 solver.cpp:218] Iteration 44100 (183.005 iter/s, 0.546432s/100 iters), loss = 0.00071746
I0816 15:32:12.926980  5636 solver.cpp:237]     Train net output #0: loss = 0.000717463 (* 1 = 0.000717463 loss)
I0816 15:32:12.926997  5636 sgd_solver.cpp:105] Iteration 44100, lr = 0.00281905
I0816 15:32:13.510599  5636 solver.cpp:218] Iteration 44200 (171.358 iter/s, 0.583574s/100 iters), loss = 0.000870547
I0816 15:32:13.510694  5636 solver.cpp:237]     Train net output #0: loss = 0.00087055 (* 1 = 0.00087055 loss)
I0816 15:32:13.510710  5636 sgd_solver.cpp:105] Iteration 44200, lr = 0.00281514
I0816 15:32:14.068284  5636 solver.cpp:218] Iteration 44300 (179.354 iter/s, 0.557558s/100 iters), loss = 0.0017406
I0816 15:32:14.068369  5636 solver.cpp:237]     Train net output #0: loss = 0.0017406 (* 1 = 0.0017406 loss)
I0816 15:32:14.068385  5636 sgd_solver.cpp:105] Iteration 44300, lr = 0.00281125
I0816 15:32:14.630785  5636 solver.cpp:218] Iteration 44400 (177.803 iter/s, 0.562419s/100 iters), loss = 0.00110897
I0816 15:32:14.631141  5636 solver.cpp:237]     Train net output #0: loss = 0.00110897 (* 1 = 0.00110897 loss)
I0816 15:32:14.631161  5636 sgd_solver.cpp:105] Iteration 44400, lr = 0.00280738
I0816 15:32:15.186672  5636 solver.cpp:330] Iteration 44500, Testing net (#0)
I0816 15:32:15.386827  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:15.393837  5636 solver.cpp:397]     Test net output #0: loss = 0.0192597 (* 1 = 0.0192597 loss)
I0816 15:32:15.398968  5636 solver.cpp:218] Iteration 44500 (130.236 iter/s, 0.767838s/100 iters), loss = 0.00036302
I0816 15:32:15.399026  5636 solver.cpp:237]     Train net output #0: loss = 0.000363024 (* 1 = 0.000363024 loss)
I0816 15:32:15.399045  5636 sgd_solver.cpp:105] Iteration 44500, lr = 0.00280351
I0816 15:32:15.943840  5636 solver.cpp:218] Iteration 44600 (183.55 iter/s, 0.54481s/100 iters), loss = 0.000456622
I0816 15:32:15.943925  5636 solver.cpp:237]     Train net output #0: loss = 0.000456626 (* 1 = 0.000456626 loss)
I0816 15:32:15.943943  5636 sgd_solver.cpp:105] Iteration 44600, lr = 0.00279966
I0816 15:32:16.499279  5636 solver.cpp:218] Iteration 44700 (180.079 iter/s, 0.555312s/100 iters), loss = 0.000608468
I0816 15:32:16.499352  5636 solver.cpp:237]     Train net output #0: loss = 0.000608472 (* 1 = 0.000608472 loss)
I0816 15:32:16.499377  5636 sgd_solver.cpp:105] Iteration 44700, lr = 0.00279582
I0816 15:32:17.062906  5636 solver.cpp:218] Iteration 44800 (177.446 iter/s, 0.563552s/100 iters), loss = 0.000922221
I0816 15:32:17.062991  5636 solver.cpp:237]     Train net output #0: loss = 0.000922225 (* 1 = 0.000922225 loss)
I0816 15:32:17.063009  5636 sgd_solver.cpp:105] Iteration 44800, lr = 0.00279199
I0816 15:32:17.622539  5636 solver.cpp:218] Iteration 44900 (178.715 iter/s, 0.55955s/100 iters), loss = 0.00103394
I0816 15:32:17.622611  5636 solver.cpp:237]     Train net output #0: loss = 0.00103395 (* 1 = 0.00103395 loss)
I0816 15:32:17.622627  5636 sgd_solver.cpp:105] Iteration 44900, lr = 0.00278818
I0816 15:32:18.155629  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:18.172858  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_45000.caffemodel
I0816 15:32:18.187218  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_45000.solverstate
I0816 15:32:18.190145  5636 solver.cpp:330] Iteration 45000, Testing net (#0)
I0816 15:32:18.385812  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:18.393442  5636 solver.cpp:397]     Test net output #0: loss = 0.0200395 (* 1 = 0.0200395 loss)
I0816 15:32:18.399562  5636 solver.cpp:218] Iteration 45000 (128.707 iter/s, 0.77696s/100 iters), loss = 0.000476047
I0816 15:32:18.399619  5636 solver.cpp:237]     Train net output #0: loss = 0.000476051 (* 1 = 0.000476051 loss)
I0816 15:32:18.399638  5636 sgd_solver.cpp:105] Iteration 45000, lr = 0.00278438
I0816 15:32:18.940537  5636 solver.cpp:218] Iteration 45100 (184.87 iter/s, 0.540921s/100 iters), loss = 0.000648907
I0816 15:32:18.940619  5636 solver.cpp:237]     Train net output #0: loss = 0.000648911 (* 1 = 0.000648911 loss)
I0816 15:32:18.940636  5636 sgd_solver.cpp:105] Iteration 45100, lr = 0.00278059
I0816 15:32:19.488957  5636 solver.cpp:218] Iteration 45200 (182.379 iter/s, 0.548308s/100 iters), loss = 0.000506318
I0816 15:32:19.489030  5636 solver.cpp:237]     Train net output #0: loss = 0.000506322 (* 1 = 0.000506322 loss)
I0816 15:32:19.489047  5636 sgd_solver.cpp:105] Iteration 45200, lr = 0.00277681
I0816 15:32:20.053354  5636 solver.cpp:218] Iteration 45300 (177.202 iter/s, 0.564326s/100 iters), loss = 0.000693216
I0816 15:32:20.053409  5636 solver.cpp:237]     Train net output #0: loss = 0.000693221 (* 1 = 0.000693221 loss)
I0816 15:32:20.053424  5636 sgd_solver.cpp:105] Iteration 45300, lr = 0.00277304
I0816 15:32:20.618643  5636 solver.cpp:218] Iteration 45400 (176.916 iter/s, 0.565238s/100 iters), loss = 0.000777666
I0816 15:32:20.618705  5636 solver.cpp:237]     Train net output #0: loss = 0.00077767 (* 1 = 0.00077767 loss)
I0816 15:32:20.618741  5636 sgd_solver.cpp:105] Iteration 45400, lr = 0.00276929
I0816 15:32:21.179631  5636 solver.cpp:330] Iteration 45500, Testing net (#0)
I0816 15:32:21.379321  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:21.385771  5636 solver.cpp:397]     Test net output #0: loss = 0.018842 (* 1 = 0.018842 loss)
I0816 15:32:21.391500  5636 solver.cpp:218] Iteration 45500 (129.399 iter/s, 0.772802s/100 iters), loss = 0.000410954
I0816 15:32:21.391559  5636 solver.cpp:237]     Train net output #0: loss = 0.000410958 (* 1 = 0.000410958 loss)
I0816 15:32:21.391580  5636 sgd_solver.cpp:105] Iteration 45500, lr = 0.00276554
I0816 15:32:21.929071  5636 solver.cpp:218] Iteration 45600 (186.043 iter/s, 0.53751s/100 iters), loss = 0.000439838
I0816 15:32:21.929148  5636 solver.cpp:237]     Train net output #0: loss = 0.000439842 (* 1 = 0.000439842 loss)
I0816 15:32:21.929163  5636 sgd_solver.cpp:105] Iteration 45600, lr = 0.00276181
I0816 15:32:22.477334  5636 solver.cpp:218] Iteration 45700 (182.436 iter/s, 0.548137s/100 iters), loss = 0.000801491
I0816 15:32:22.477432  5636 solver.cpp:237]     Train net output #0: loss = 0.000801496 (* 1 = 0.000801496 loss)
I0816 15:32:22.477452  5636 sgd_solver.cpp:105] Iteration 45700, lr = 0.00275809
I0816 15:32:23.042515  5636 solver.cpp:218] Iteration 45800 (176.966 iter/s, 0.565081s/100 iters), loss = 0.00034291
I0816 15:32:23.042619  5636 solver.cpp:237]     Train net output #0: loss = 0.000342915 (* 1 = 0.000342915 loss)
I0816 15:32:23.042639  5636 sgd_solver.cpp:105] Iteration 45800, lr = 0.00275438
I0816 15:32:23.604763  5636 solver.cpp:218] Iteration 45900 (177.89 iter/s, 0.562145s/100 iters), loss = 0.000838346
I0816 15:32:23.604856  5636 solver.cpp:237]     Train net output #0: loss = 0.000838351 (* 1 = 0.000838351 loss)
I0816 15:32:23.604876  5636 sgd_solver.cpp:105] Iteration 45900, lr = 0.00275069
I0816 15:32:23.792526  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:24.161609  5636 solver.cpp:330] Iteration 46000, Testing net (#0)
I0816 15:32:24.359899  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:24.366797  5636 solver.cpp:397]     Test net output #0: loss = 0.0194716 (* 1 = 0.0194716 loss)
I0816 15:32:24.371600  5636 solver.cpp:218] Iteration 46000 (130.42 iter/s, 0.766754s/100 iters), loss = 0.000382811
I0816 15:32:24.371659  5636 solver.cpp:237]     Train net output #0: loss = 0.000382816 (* 1 = 0.000382816 loss)
I0816 15:32:24.371678  5636 sgd_solver.cpp:105] Iteration 46000, lr = 0.002747
I0816 15:32:24.915776  5636 solver.cpp:218] Iteration 46100 (183.784 iter/s, 0.544117s/100 iters), loss = 0.00018331
I0816 15:32:24.915858  5636 solver.cpp:237]     Train net output #0: loss = 0.000183315 (* 1 = 0.000183315 loss)
I0816 15:32:24.915874  5636 sgd_solver.cpp:105] Iteration 46100, lr = 0.00274333
I0816 15:32:25.468765  5636 solver.cpp:218] Iteration 46200 (180.875 iter/s, 0.552868s/100 iters), loss = 0.000352041
I0816 15:32:25.468842  5636 solver.cpp:237]     Train net output #0: loss = 0.000352046 (* 1 = 0.000352046 loss)
I0816 15:32:25.468858  5636 sgd_solver.cpp:105] Iteration 46200, lr = 0.00273967
I0816 15:32:26.035532  5636 solver.cpp:218] Iteration 46300 (176.463 iter/s, 0.56669s/100 iters), loss = 0.000441056
I0816 15:32:26.035620  5636 solver.cpp:237]     Train net output #0: loss = 0.000441061 (* 1 = 0.000441061 loss)
I0816 15:32:26.035657  5636 sgd_solver.cpp:105] Iteration 46300, lr = 0.00273602
I0816 15:32:26.610755  5636 solver.cpp:218] Iteration 46400 (173.871 iter/s, 0.57514s/100 iters), loss = 0.000231405
I0816 15:32:26.610836  5636 solver.cpp:237]     Train net output #0: loss = 0.000231411 (* 1 = 0.000231411 loss)
I0816 15:32:26.610852  5636 sgd_solver.cpp:105] Iteration 46400, lr = 0.00273238
I0816 15:32:27.180390  5636 solver.cpp:330] Iteration 46500, Testing net (#0)
I0816 15:32:27.382091  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:27.388726  5636 solver.cpp:397]     Test net output #0: loss = 0.0191611 (* 1 = 0.0191611 loss)
I0816 15:32:27.394490  5636 solver.cpp:218] Iteration 46500 (127.606 iter/s, 0.783661s/100 iters), loss = 0.000912478
I0816 15:32:27.394544  5636 solver.cpp:237]     Train net output #0: loss = 0.000912484 (* 1 = 0.000912484 loss)
I0816 15:32:27.394563  5636 sgd_solver.cpp:105] Iteration 46500, lr = 0.00272875
I0816 15:32:27.946645  5636 solver.cpp:218] Iteration 46600 (181.128 iter/s, 0.552096s/100 iters), loss = 0.0015155
I0816 15:32:27.946746  5636 solver.cpp:237]     Train net output #0: loss = 0.00151551 (* 1 = 0.00151551 loss)
I0816 15:32:27.946763  5636 sgd_solver.cpp:105] Iteration 46600, lr = 0.00272513
I0816 15:32:28.501773  5636 solver.cpp:218] Iteration 46700 (180.188 iter/s, 0.554976s/100 iters), loss = 0.000193453
I0816 15:32:28.501900  5636 solver.cpp:237]     Train net output #0: loss = 0.000193459 (* 1 = 0.000193459 loss)
I0816 15:32:28.501929  5636 sgd_solver.cpp:105] Iteration 46700, lr = 0.00272153
I0816 15:32:29.069313  5636 solver.cpp:218] Iteration 46800 (176.239 iter/s, 0.56741s/100 iters), loss = 0.000744801
I0816 15:32:29.069417  5636 solver.cpp:237]     Train net output #0: loss = 0.000744807 (* 1 = 0.000744807 loss)
I0816 15:32:29.069437  5636 sgd_solver.cpp:105] Iteration 46800, lr = 0.00271793
I0816 15:32:29.474386  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:29.648437  5636 solver.cpp:218] Iteration 46900 (172.704 iter/s, 0.579026s/100 iters), loss = 0.000192466
I0816 15:32:29.648499  5636 solver.cpp:237]     Train net output #0: loss = 0.000192473 (* 1 = 0.000192473 loss)
I0816 15:32:29.648514  5636 sgd_solver.cpp:105] Iteration 46900, lr = 0.00271435
I0816 15:32:30.216872  5636 solver.cpp:330] Iteration 47000, Testing net (#0)
I0816 15:32:30.420183  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:30.425726  5636 solver.cpp:397]     Test net output #0: loss = 0.0194498 (* 1 = 0.0194498 loss)
I0816 15:32:30.431294  5636 solver.cpp:218] Iteration 47000 (127.808 iter/s, 0.782421s/100 iters), loss = 0.000422739
I0816 15:32:30.431349  5636 solver.cpp:237]     Train net output #0: loss = 0.000422745 (* 1 = 0.000422745 loss)
I0816 15:32:30.431367  5636 sgd_solver.cpp:105] Iteration 47000, lr = 0.00271078
I0816 15:32:30.970135  5636 solver.cpp:218] Iteration 47100 (185.601 iter/s, 0.538792s/100 iters), loss = 0.000367397
I0816 15:32:30.970239  5636 solver.cpp:237]     Train net output #0: loss = 0.000367403 (* 1 = 0.000367403 loss)
I0816 15:32:30.970255  5636 sgd_solver.cpp:105] Iteration 47100, lr = 0.00270722
I0816 15:32:31.514746  5636 solver.cpp:218] Iteration 47200 (183.667 iter/s, 0.544465s/100 iters), loss = 0.00067872
I0816 15:32:31.514860  5636 solver.cpp:237]     Train net output #0: loss = 0.000678726 (* 1 = 0.000678726 loss)
I0816 15:32:31.514886  5636 sgd_solver.cpp:105] Iteration 47200, lr = 0.00270367
I0816 15:32:32.084575  5636 solver.cpp:218] Iteration 47300 (175.526 iter/s, 0.569716s/100 iters), loss = 0.000523219
I0816 15:32:32.084663  5636 solver.cpp:237]     Train net output #0: loss = 0.000523225 (* 1 = 0.000523225 loss)
I0816 15:32:32.084681  5636 sgd_solver.cpp:105] Iteration 47300, lr = 0.00270013
I0816 15:32:32.648421  5636 solver.cpp:218] Iteration 47400 (177.381 iter/s, 0.563758s/100 iters), loss = 0.000400047
I0816 15:32:32.648500  5636 solver.cpp:237]     Train net output #0: loss = 0.000400053 (* 1 = 0.000400053 loss)
I0816 15:32:32.648516  5636 sgd_solver.cpp:105] Iteration 47400, lr = 0.0026966
I0816 15:32:33.208933  5636 solver.cpp:330] Iteration 47500, Testing net (#0)
I0816 15:32:33.408016  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:33.415556  5636 solver.cpp:397]     Test net output #0: loss = 0.0196974 (* 1 = 0.0196974 loss)
I0816 15:32:33.421625  5636 solver.cpp:218] Iteration 47500 (129.344 iter/s, 0.773133s/100 iters), loss = 0.000865292
I0816 15:32:33.421685  5636 solver.cpp:237]     Train net output #0: loss = 0.000865297 (* 1 = 0.000865297 loss)
I0816 15:32:33.421705  5636 sgd_solver.cpp:105] Iteration 47500, lr = 0.00269308
I0816 15:32:33.974830  5636 solver.cpp:218] Iteration 47600 (180.786 iter/s, 0.55314s/100 iters), loss = 0.000962597
I0816 15:32:33.974915  5636 solver.cpp:237]     Train net output #0: loss = 0.000962603 (* 1 = 0.000962603 loss)
I0816 15:32:33.974936  5636 sgd_solver.cpp:105] Iteration 47600, lr = 0.00268957
I0816 15:32:34.524351  5636 solver.cpp:218] Iteration 47700 (182.016 iter/s, 0.549401s/100 iters), loss = 0.000591414
I0816 15:32:34.524425  5636 solver.cpp:237]     Train net output #0: loss = 0.00059142 (* 1 = 0.00059142 loss)
I0816 15:32:34.524441  5636 sgd_solver.cpp:105] Iteration 47700, lr = 0.00268607
I0816 15:32:35.084760  5636 solver.cpp:218] Iteration 47800 (178.465 iter/s, 0.560333s/100 iters), loss = 0.000836789
I0816 15:32:35.084846  5636 solver.cpp:237]     Train net output #0: loss = 0.000836794 (* 1 = 0.000836794 loss)
I0816 15:32:35.084862  5636 sgd_solver.cpp:105] Iteration 47800, lr = 0.00268259
I0816 15:32:35.128821  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:35.648480  5636 solver.cpp:218] Iteration 47900 (177.419 iter/s, 0.563637s/100 iters), loss = 0.000183524
I0816 15:32:35.648555  5636 solver.cpp:237]     Train net output #0: loss = 0.000183529 (* 1 = 0.000183529 loss)
I0816 15:32:35.648571  5636 sgd_solver.cpp:105] Iteration 47900, lr = 0.00267911
I0816 15:32:36.206085  5636 solver.cpp:330] Iteration 48000, Testing net (#0)
I0816 15:32:36.406132  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:36.413679  5636 solver.cpp:397]     Test net output #0: loss = 0.0198016 (* 1 = 0.0198016 loss)
I0816 15:32:36.419761  5636 solver.cpp:218] Iteration 48000 (129.666 iter/s, 0.771214s/100 iters), loss = 0.000179751
I0816 15:32:36.419821  5636 solver.cpp:237]     Train net output #0: loss = 0.000179757 (* 1 = 0.000179757 loss)
I0816 15:32:36.419841  5636 sgd_solver.cpp:105] Iteration 48000, lr = 0.00267565
I0816 15:32:36.967564  5636 solver.cpp:218] Iteration 48100 (182.568 iter/s, 0.547741s/100 iters), loss = 0.000335509
I0816 15:32:36.967641  5636 solver.cpp:237]     Train net output #0: loss = 0.000335514 (* 1 = 0.000335514 loss)
I0816 15:32:36.967658  5636 sgd_solver.cpp:105] Iteration 48100, lr = 0.00267219
I0816 15:32:37.527289  5636 solver.cpp:218] Iteration 48200 (178.693 iter/s, 0.559618s/100 iters), loss = 0.000791439
I0816 15:32:37.527350  5636 solver.cpp:237]     Train net output #0: loss = 0.000791444 (* 1 = 0.000791444 loss)
I0816 15:32:37.527366  5636 sgd_solver.cpp:105] Iteration 48200, lr = 0.00266875
I0816 15:32:38.097968  5636 solver.cpp:218] Iteration 48300 (175.249 iter/s, 0.570617s/100 iters), loss = 0.00106921
I0816 15:32:38.098062  5636 solver.cpp:237]     Train net output #0: loss = 0.00106921 (* 1 = 0.00106921 loss)
I0816 15:32:38.098078  5636 sgd_solver.cpp:105] Iteration 48300, lr = 0.00266532
I0816 15:32:38.660645  5636 solver.cpp:218] Iteration 48400 (177.751 iter/s, 0.562586s/100 iters), loss = 0.000379095
I0816 15:32:38.660733  5636 solver.cpp:237]     Train net output #0: loss = 0.0003791 (* 1 = 0.0003791 loss)
I0816 15:32:38.660749  5636 sgd_solver.cpp:105] Iteration 48400, lr = 0.00266189
I0816 15:32:39.208149  5636 solver.cpp:330] Iteration 48500, Testing net (#0)
I0816 15:32:39.403379  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:39.410905  5636 solver.cpp:397]     Test net output #0: loss = 0.019414 (* 1 = 0.019414 loss)
I0816 15:32:39.416791  5636 solver.cpp:218] Iteration 48500 (132.263 iter/s, 0.756067s/100 iters), loss = 0.000636219
I0816 15:32:39.416846  5636 solver.cpp:237]     Train net output #0: loss = 0.000636223 (* 1 = 0.000636223 loss)
I0816 15:32:39.416865  5636 sgd_solver.cpp:105] Iteration 48500, lr = 0.00265848
I0816 15:32:39.957191  5636 solver.cpp:218] Iteration 48600 (185.075 iter/s, 0.540321s/100 iters), loss = 0.000669679
I0816 15:32:39.957267  5636 solver.cpp:237]     Train net output #0: loss = 0.000669683 (* 1 = 0.000669683 loss)
I0816 15:32:39.957283  5636 sgd_solver.cpp:105] Iteration 48600, lr = 0.00265507
I0816 15:32:40.512270  5636 solver.cpp:218] Iteration 48700 (180.189 iter/s, 0.554971s/100 iters), loss = 0.000330814
I0816 15:32:40.512370  5636 solver.cpp:237]     Train net output #0: loss = 0.000330819 (* 1 = 0.000330819 loss)
I0816 15:32:40.512385  5636 sgd_solver.cpp:105] Iteration 48700, lr = 0.00265168
I0816 15:32:40.771387  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:41.095639  5636 solver.cpp:218] Iteration 48800 (171.447 iter/s, 0.583271s/100 iters), loss = 0.000849747
I0816 15:32:41.095695  5636 solver.cpp:237]     Train net output #0: loss = 0.000849751 (* 1 = 0.000849751 loss)
I0816 15:32:41.095710  5636 sgd_solver.cpp:105] Iteration 48800, lr = 0.0026483
I0816 15:32:41.658674  5636 solver.cpp:218] Iteration 48900 (177.641 iter/s, 0.562933s/100 iters), loss = 0.000573389
I0816 15:32:41.658753  5636 solver.cpp:237]     Train net output #0: loss = 0.000573394 (* 1 = 0.000573394 loss)
I0816 15:32:41.658769  5636 sgd_solver.cpp:105] Iteration 48900, lr = 0.00264493
I0816 15:32:42.217243  5636 solver.cpp:330] Iteration 49000, Testing net (#0)
I0816 15:32:42.414675  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:42.422212  5636 solver.cpp:397]     Test net output #0: loss = 0.0202812 (* 1 = 0.0202812 loss)
I0816 15:32:42.428089  5636 solver.cpp:218] Iteration 49000 (129.981 iter/s, 0.769345s/100 iters), loss = 0.000628642
I0816 15:32:42.428146  5636 solver.cpp:237]     Train net output #0: loss = 0.000628647 (* 1 = 0.000628647 loss)
I0816 15:32:42.428165  5636 sgd_solver.cpp:105] Iteration 49000, lr = 0.00264156
I0816 15:32:42.967397  5636 solver.cpp:218] Iteration 49100 (185.456 iter/s, 0.53921s/100 iters), loss = 0.000380568
I0816 15:32:42.967499  5636 solver.cpp:237]     Train net output #0: loss = 0.000380573 (* 1 = 0.000380573 loss)
I0816 15:32:42.967515  5636 sgd_solver.cpp:105] Iteration 49100, lr = 0.00263821
I0816 15:32:43.531227  5636 solver.cpp:218] Iteration 49200 (177.402 iter/s, 0.563693s/100 iters), loss = 0.000410084
I0816 15:32:43.531323  5636 solver.cpp:237]     Train net output #0: loss = 0.000410089 (* 1 = 0.000410089 loss)
I0816 15:32:43.531340  5636 sgd_solver.cpp:105] Iteration 49200, lr = 0.00263487
I0816 15:32:44.112233  5636 solver.cpp:218] Iteration 49300 (172.141 iter/s, 0.58092s/100 iters), loss = 0.000198167
I0816 15:32:44.112336  5636 solver.cpp:237]     Train net output #0: loss = 0.000198172 (* 1 = 0.000198172 loss)
I0816 15:32:44.112354  5636 sgd_solver.cpp:105] Iteration 49300, lr = 0.00263153
I0816 15:32:44.682436  5636 solver.cpp:218] Iteration 49400 (175.408 iter/s, 0.5701s/100 iters), loss = 0.000145699
I0816 15:32:44.682837  5636 solver.cpp:237]     Train net output #0: loss = 0.000145704 (* 1 = 0.000145704 loss)
I0816 15:32:44.682888  5636 sgd_solver.cpp:105] Iteration 49400, lr = 0.00262821
I0816 15:32:45.230605  5636 solver.cpp:330] Iteration 49500, Testing net (#0)
I0816 15:32:45.428998  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:45.436560  5636 solver.cpp:397]     Test net output #0: loss = 0.0195613 (* 1 = 0.0195613 loss)
I0816 15:32:45.442109  5636 solver.cpp:218] Iteration 49500 (131.703 iter/s, 0.759284s/100 iters), loss = 0.00182625
I0816 15:32:45.442170  5636 solver.cpp:237]     Train net output #0: loss = 0.00182626 (* 1 = 0.00182626 loss)
I0816 15:32:45.442189  5636 sgd_solver.cpp:105] Iteration 49500, lr = 0.0026249
I0816 15:32:45.984804  5636 solver.cpp:218] Iteration 49600 (184.299 iter/s, 0.542595s/100 iters), loss = 0.000626751
I0816 15:32:45.984902  5636 solver.cpp:237]     Train net output #0: loss = 0.000626756 (* 1 = 0.000626756 loss)
I0816 15:32:45.984920  5636 sgd_solver.cpp:105] Iteration 49600, lr = 0.00262159
I0816 15:32:46.441941  5644 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:46.530419  5636 solver.cpp:218] Iteration 49700 (183.324 iter/s, 0.545482s/100 iters), loss = 0.000289427
I0816 15:32:46.530488  5636 solver.cpp:237]     Train net output #0: loss = 0.000289432 (* 1 = 0.000289432 loss)
I0816 15:32:46.530504  5636 sgd_solver.cpp:105] Iteration 49700, lr = 0.0026183
I0816 15:32:47.085774  5636 solver.cpp:218] Iteration 49800 (180.088 iter/s, 0.555283s/100 iters), loss = 0.000436524
I0816 15:32:47.085871  5636 solver.cpp:237]     Train net output #0: loss = 0.000436529 (* 1 = 0.000436529 loss)
I0816 15:32:47.085891  5636 sgd_solver.cpp:105] Iteration 49800, lr = 0.00261501
I0816 15:32:47.621722  5636 solver.cpp:218] Iteration 49900 (186.622 iter/s, 0.535843s/100 iters), loss = 5.35015e-05
I0816 15:32:47.621850  5636 solver.cpp:237]     Train net output #0: loss = 5.35065e-05 (* 1 = 5.35065e-05 loss)
I0816 15:32:47.621889  5636 sgd_solver.cpp:105] Iteration 49900, lr = 0.00261174
I0816 15:32:48.192514  5636 solver.cpp:447] Snapshotting to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_50000.caffemodel
I0816 15:32:48.209573  5636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/bw/mnist_siamese/mnist_siamese_train_iter_50000.solverstate
I0816 15:32:48.215924  5636 solver.cpp:310] Iteration 50000, loss = 0.000291121
I0816 15:32:48.216012  5636 solver.cpp:330] Iteration 50000, Testing net (#0)
I0816 15:32:48.423707  5647 data_layer.cpp:73] Restarting data prefetching from start.
I0816 15:32:48.431316  5636 solver.cpp:397]     Test net output #0: loss = 0.0195605 (* 1 = 0.0195605 loss)
I0816 15:32:48.431357  5636 solver.cpp:315] Optimization Done.
I0816 15:32:48.431372  5636 caffe.cpp:259] Optimization Done.
